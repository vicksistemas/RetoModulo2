{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86341782",
   "metadata": {},
   "source": [
    "# Práctica 5 Automatización y Optimización Avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39121530",
   "metadata": {},
   "source": [
    "> Objetivo central: **\"Automatiza un stack CRUD completo (modelo, API, tests e infraestructura) orquestando LLMs con LangChain de forma reproducible y medible.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d44a1",
   "metadata": {},
   "source": [
    "## ¿Qué voy a lograr y por qué importa?\n",
    "En esta práctica construyes un **pipeline automatizado** que, partiendo de una configuración declarativa (YAML / Pydantic), genera:\n",
    "- Modelos Pydantic validados\n",
    "- Router FastAPI empresarial (CRUD + paginación + auth opcional)\n",
    "- Suite de tests Pytest\n",
    "- Infraestructura (Dockerfile, migración Alembic)\n",
    "- Métricas de eficiencia de la generación\n",
    "\n",
    "Esto refleja un caso real: equipos que necesitan **acelerar el scaffolding backend** manteniendo estándares de calidad. Aprenderás a usar **LangChain Expression Language (LCEL)** y `RunnableParallel` para ejecutar tareas en paralelo y encadenar dependencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738c61b",
   "metadata": {},
   "source": [
    "Problemas reales que esto resuelve:\n",
    "- Onboarding lento: crear cada CRUD manualmente tarda horas.\n",
    "- Inconsistencia entre servicios: estilos diferentes de validación / logs.\n",
    "- Falta de medición: se generan cosas con IA pero sin métricas.\n",
    "- Riesgo técnico: prompts desordenados, sin control de dependencias.\n",
    "\n",
    "Solución mostrada: un **pipeline determinista** donde cada bloque tiene una responsabilidad clara. Así escalas generación de servicios sin sacrificar mantenibilidad.\n",
    "\n",
    "Rol de las piezas:\n",
    "- `ResourceConfig` y `FieldConfig`: contrato declarativo de tu recurso.\n",
    "- Prompts especializados (model, router, tests, infra): separación de dominios (Domain Prompting).\n",
    "- `RunnableParallel`: acelera la generación base (modelo + config) y luego deriva dependientes.\n",
    "- `Structured Output`: fuerza esquemas (`InfrastructureComponents`).\n",
    "- Métricas: base para gobernanza y ROI de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14740e",
   "metadata": {},
   "source": [
    "| Concepto | Idea-faro | Analogía |\n",
    "|----------|-----------|----------|\n",
    "| LCEL | Orquesta modular | \"LEGO de flujos LLM\" |\n",
    "| `RunnableParallel` | Paralelismo declarativo | \"Carriles simultáneos\" |\n",
    "| Config → Artefactos | Infra como código pero para scaffolding | \"Terraform de tu backend\" |\n",
    "| Prompts especializados | Principio de responsabilidad única | \"Microservicios cognitivos\" |\n",
    "| Métricas | Observabilidad del pipeline | \"Tablero de control DevOps\" |\n",
    "| Structured Output | Control sintáctico | \"Molde para la arcilla del modelo\" |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204eb06",
   "metadata": {},
   "source": [
    "## Práctica paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ac3e8",
   "metadata": {},
   "source": [
    "### Parte 1: Setup del Entorno\n",
    "\n",
    "Configuraremos un entorno completo con herramientas de análisis y generación automatizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd583795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.33)\n",
      "Requirement already satisfied: langchain-community in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.29)\n",
      "Requirement already satisfied: fastapi in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.116.2)\n",
      "Requirement already satisfied: uvicorn in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.35.0)\n",
      "Requirement already satisfied: pydantic in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (2.11.7)\n",
      "Requirement already satisfied: pytest in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (8.4.1)\n",
      "Requirement already satisfied: httpx in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: jinja2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: pyyaml in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: click in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (8.2.1)\n",
      "Requirement already satisfied: rich in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (14.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-openai) (1.107.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (2.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from jinja2) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from rich) (4.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-community fastapi uvicorn pydantic pytest httpx python-dotenv jinja2 pyyaml click rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b672ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any, Literal\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from jinja2 import Template\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3e26bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API Key configurada\n",
      "🤖 Modelo listo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"⚠️  Configura OPENAI_API_KEY en tu archivo .env\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API Key configurada\")\n",
    "\n",
    "# Configurar modelo\n",
    "model = ChatOpenAI(model=\"gpt-5\", temperature=0)\n",
    "print(\"🤖 Modelo listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70343359",
   "metadata": {},
   "source": [
    "### 4.2 Modelos de Configuración\n",
    "Implementaremos un sistema avanzado de generación CRUD usando RunnableParallel y configuración YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e62086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "# Modelos de configuración\n",
    "\n",
    "class FieldConfig(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"int\", \"float\", \"str\", \"bool\"]\n",
    "    description: str = \"\"\n",
    "    constraints: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class ResourceConfig(BaseModel):\n",
    "    resource_name: str\n",
    "    class_name: str\n",
    "    fields: List[FieldConfig]\n",
    "    auth_required: bool = False\n",
    "    cache_enabled: bool = False\n",
    "    pagination: bool = True\n",
    "    soft_delete: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617119fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3788136/77762200.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  yaml.dump(sample_config.dict(), f, default_flow_style=False)\n"
     ]
    }
   ],
   "source": [
    "# 2. Crear configuración de ejemplo\n",
    "sample_config = ResourceConfig(\n",
    "    resource_name=\"product\",\n",
    "    class_name=\"Product\", \n",
    "    fields=[\n",
    "        FieldConfig(name=\"name\", type=\"str\", description=\"Nombre del producto\", \n",
    "                   constraints={\"min_length\": 1, \"max_length\": 100}),\n",
    "        FieldConfig(name=\"price\", type=\"float\", description=\"Precio en USD\",\n",
    "                   constraints={\"ge\": 0, \"le\": 999999}),\n",
    "        FieldConfig(name=\"category\", type=\"str\", required=False, description=\"Categoría\"),\n",
    "        FieldConfig(name=\"stock\", type=\"int\", description=\"Cantidad en inventario\",\n",
    "                   constraints={\"ge\": 0})\n",
    "    ],\n",
    "    auth_required=True,\n",
    "    cache_enabled=True,\n",
    "    pagination=True,\n",
    "    soft_delete=True\n",
    ")\n",
    "\n",
    "# Guardar configuración para uso posterior\n",
    "config_path = Path(\"resource_configs\") \n",
    "config_path.mkdir(exist_ok=True)\n",
    "with open(config_path / \"product_config.yaml\", \"w\") as f:\n",
    "    yaml.dump(sample_config.dict(), f, default_flow_style=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf6415",
   "metadata": {},
   "source": [
    "### Parte 3: Generadores Especializados con RunnableParallel\n",
    "\n",
    "Crearemos generadores especializados que trabajen en paralelo para máxima eficiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d228d",
   "metadata": {},
   "source": [
    "Se crean 4 generadores:\n",
    "1. `model_generator`: produce modelos Pydantic (entrada, salida, update, validaciones y validators).\n",
    "2. `router_generator`: crea router FastAPI con CRUD completo y middlewares condicionales.\n",
    "3. `tests_generator`: diseña suite Pytest (unit, integration, performance básico, edge cases).\n",
    "4. `infra_generator`: con `with_structured_output` para garantizar campos (`dockerfile`, `migration`, etc.).\n",
    "\n",
    "Diseño de prompts: cada uno declara explícitamente criterios de calidad (ej. \"nivel PRODUCCIÓN\", \"validaciones específicas\", \"logging estructurado\"). Esto reduce alucinaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5ba456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# GENERADORES ESPECIALIZADOS \n",
    "\n",
    "class GeneratedComponents(BaseModel):\n",
    "    modelo_pydantic: str = Field(description=\"Modelo Pydantic con validaciones avanzadas\")\n",
    "    router_fastapi: str = Field(description=\"Router FastAPI con CRUD completo\")\n",
    "    tests_pytest: str = Field(description=\"Suite de tests exhaustiva\")\n",
    "    alembic_migration: str = Field(description=\"Migración Alembic para base de datos\")\n",
    "    dockerfile: str = Field(description=\"Dockerfile optimizado\")\n",
    "\n",
    "\n",
    "# Templates\n",
    "model_generator =(ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres experto en Pydantic y diseño de APIs con FastAPI.\n",
    "        Genera modelos Pydantic de nivel PRODUCCIÓN con:\n",
    "        - Validaciones específicas por tipo de campo\n",
    "        - Docstrings detallados con ejemplos\n",
    "        - Field constraints apropiados\n",
    "        - Validators personalizados para lógica de negocio\n",
    "        - Modelos de entrada, salida y actualización separados\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        CONFIGURACIÓN:\n",
    "        Resource: {resource_name}\n",
    "        Class: {class_name}\n",
    "        Fields: {fields}\n",
    "        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\n",
    "\n",
    "        Genera modelos Pydantic profesionales con validaciones robustas.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7690d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres experto en Pydantic y diseño de APIs con FastAPI.\\n        Genera modelos Pydantic de nivel PRODUCCIÓN con:\\n        - Validaciones específicas por tipo de campo\\n        - Docstrings detallados con ejemplos\\n        - Field constraints apropiados\\n        - Validators personalizados para lógica de negocio\\n        - Modelos de entrada, salida y actualización separados\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, template='\\n        CONFIGURACIÓN:\\n        Resource: {resource_name}\\n        Class: {class_name}\\n        Fields: {fields}\\n        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\\n\\n        Genera modelos Pydantic profesionales con validaciones robustas.\\n        '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415d2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generador de routers FastAPI completos\n",
    "router_generator = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres arquitecto senior FastAPI especialista en APIs RESTful.\n",
    "        Genera routers de PRODUCCIÓN con:\n",
    "        - Endpoints CRUD completos (GET, POST, PUT, PATCH, DELETE)\n",
    "        - Paginación, filtrado y ordenamiento\n",
    "        - Manejo de errores HTTP consistente\n",
    "        - Documentación OpenAPI rica\n",
    "        - Middlewares de auth y cache según configuración\n",
    "        - Logging estructurado\n",
    "        - Validación de permisos\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        MODELO PYDANTIC:\n",
    "        {modelo_pydantic}\n",
    "\n",
    "        CONFIGURACIÓN:\n",
    "        {config}\n",
    "\n",
    "        Genera router FastAPI de nivel empresarial.\n",
    "    \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47973e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['config', 'modelo_pydantic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres arquitecto senior FastAPI especialista en APIs RESTful.\\n        Genera routers de PRODUCCIÓN con:\\n        - Endpoints CRUD completos (GET, POST, PUT, PATCH, DELETE)\\n        - Paginación, filtrado y ordenamiento\\n        - Manejo de errores HTTP consistente\\n        - Documentación OpenAPI rica\\n        - Middlewares de auth y cache según configuración\\n        - Logging estructurado\\n        - Validación de permisos\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['config', 'modelo_pydantic'], input_types={}, partial_variables={}, template='\\n        MODELO PYDANTIC:\\n        {modelo_pydantic}\\n\\n        CONFIGURACIÓN:\\n        {config}\\n\\n        Genera router FastAPI de nivel empresarial.\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e641756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generador de tests exhaustivos\n",
    "tests_generator = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres QA Lead especialista en testing de APIs.\n",
    "        Genera suite de tests COMPREHENSIVA con:\n",
    "        - Tests unitarios para cada endpoint\n",
    "        - Tests de integración end-to-end\n",
    "        - Tests de performance básicos\n",
    "        - Tests de seguridad (auth, validation)\n",
    "        - Tests de casos borde y error handling\n",
    "        - Fixtures y mocks apropiados\n",
    "        - Cobertura de al menos 90%\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        ROUTER FASTAPI:\n",
    "        {router_fastapi}\n",
    "\n",
    "        MODELO PYDANTIC:\n",
    "        {modelo_pydantic}\n",
    "\n",
    "        CONFIGURACIÓN:\n",
    "        {config}\n",
    "\n",
    "        Genera tests pytest de nivel empresarial.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91e2a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['config', 'modelo_pydantic', 'router_fastapi'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres QA Lead especialista en testing de APIs.\\n        Genera suite de tests COMPREHENSIVA con:\\n        - Tests unitarios para cada endpoint\\n        - Tests de integración end-to-end\\n        - Tests de performance básicos\\n        - Tests de seguridad (auth, validation)\\n        - Tests de casos borde y error handling\\n        - Fixtures y mocks apropiados\\n        - Cobertura de al menos 90%\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['config', 'modelo_pydantic', 'router_fastapi'], input_types={}, partial_variables={}, template='\\n        ROUTER FASTAPI:\\n        {router_fastapi}\\n\\n        MODELO PYDANTIC:\\n        {modelo_pydantic}\\n\\n        CONFIGURACIÓN:\\n        {config}\\n\\n        Genera tests pytest de nivel empresarial.\\n        '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "701192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Modelo para infraestructura\n",
    "class InfrastructureComponents(BaseModel):\n",
    "    dockerfile: str = Field(description=\"Dockerfile multi-stage optimizado\")\n",
    "    migration: str = Field(description=\"Migración Alembic con índices\")\n",
    "    docker_compose: str = Field(description=\"Docker-compose para desarrollo\", default=\"\")\n",
    "    deployment_script: str = Field(description=\"Script de deployment\", default=\"\")\n",
    "\n",
    "# 4. Generador de infraestructura (Docker, migrations) - corregido\n",
    "infra_generator = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Eres DevOps senior especialista en containerización y databases.\n",
    "    Genera infraestructura de PRODUCCIÓN:\n",
    "    - Dockerfile multi-stage optimizado\n",
    "    - Migración Alembic con índices apropiados\n",
    "    - Docker-compose para desarrollo\n",
    "    - Scripts de deployment\n",
    "    \"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "    CONFIGURACIÓN:\n",
    "    {config}\n",
    "\n",
    "    MODELO PYDANTIC:\n",
    "    {modelo_pydantic}\n",
    "\n",
    "    Genera infraestructura completa para producción.\n",
    "    \"\"\")\n",
    "]) | model.with_structured_output(InfrastructureComponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be747d8",
   "metadata": {},
   "source": [
    "### 4.4 Orquestación LCEL\n",
    "Función `create_advanced_crud_pipeline()`:\n",
    "- Fase base paralela: genera `modelo` y pasa `config` intacta.\n",
    "- Lambda intermedia `_generate_dependent_components`: usa salida anterior para generar router y luego en paralelo tests + infraestructura.\n",
    "- Se empaqueta todo en un `GeneratedComponents` final.\n",
    "\n",
    "Ventaja: minimiza latencia (paraleliza lo que no depende) y mantiene orden lógico de dependencias (modelo → router → tests/infra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b811db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_dependent_components(base_components):\n",
    "    config = base_components[\"config\"]\n",
    "    modelo = base_components[\"modelo\"]\n",
    "\n",
    "    router = router_generator.invoke({\n",
    "        \"modelo_pydantic\": modelo,\n",
    "        \"config\": json.dumps(config, indent=2, ensure_ascii=False)\n",
    "    })\n",
    "\n",
    "    parallel_final = RunnableParallel({\n",
    "        \"tests\": tests_generator,\n",
    "        \"infra\": infra_generator\n",
    "    })\n",
    "\n",
    "    final_components = parallel_final.invoke({\n",
    "        \"router_fastapi\": router,\n",
    "        \"modelo_pydantic\": modelo,\n",
    "        \"config\": json.dumps(config, indent=2, ensure_ascii=False)\n",
    "    })\n",
    "\n",
    "    infra = final_components[\"infra\"]\n",
    "    return GeneratedComponents(\n",
    "        modelo_pydantic=modelo,\n",
    "        router_fastapi=router,\n",
    "        tests_pytest=final_components[\"tests\"],\n",
    "        alembic_migration=infra.migration if infra else \"\",\n",
    "        dockerfile=infra.dockerfile if infra else \"\"\n",
    "    )\n",
    "\n",
    "def create_advanced_crud_pipeline():\n",
    "    parallel_base = RunnableParallel({\n",
    "        \"modelo\": model_generator,\n",
    "        \"config\": RunnableLambda(lambda x: x)\n",
    "    })\n",
    "    return parallel_base | RunnableLambda(_generate_dependent_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14cea88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  modelo: ChatPromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres experto en Pydantic y diseño de APIs con FastAPI.\\n        Genera modelos Pydantic de nivel PRODUCCIÓN con:\\n        - Validaciones específicas por tipo de campo\\n        - Docstrings detallados con ejemplos\\n        - Field constraints apropiados\\n        - Validators personalizados para lógica de negocio\\n        - Modelos de entrada, salida y actualización separados\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, template='\\n        CONFIGURACIÓN:\\n        Resource: {resource_name}\\n        Class: {class_name}\\n        Fields: {fields}\\n        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\\n\\n        Genera modelos Pydantic profesionales con validaciones robustas.\\n        '), additional_kwargs={})])\n",
       "          | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "          | StrOutputParser(),\n",
       "  config: RunnableLambda(...)\n",
       "}\n",
       "| RunnableLambda(_generate_dependent_components)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crud_pipeline = create_advanced_crud_pipeline()\n",
    "\n",
    "crud_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e4292",
   "metadata": {},
   "source": [
    "### 4.5 Ejecución + Métricas\n",
    "Se prepara input a partir de `sample_config` y se invoca `crud_pipeline.invoke(pipeline_input)`.\n",
    "\n",
    "Métricas recolectadas manualmente (se esboza callback pero no se conecta en la ejecución actual):\n",
    "- Tiempo total de generación\n",
    "- Conteo de líneas por componente\n",
    "- Número de clases, endpoints, validators, fixtures, asserts\n",
    "- Cálculo de ROI: (tiempo manual estimado / tiempo IA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa951ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INICIANDO GENERACIÓN CRUD AUTOMATIZADA...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EJECUCIÓN DEL PIPELINE CON MÉTRICAS AVANZADAS\n",
    "\n",
    "# 1. Callback para capturar métricas detalladas\n",
    "class CRUDGenerationMetrics(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"start_time\": None,\n",
    "            \"end_time\": None,\n",
    "            \"components_generated\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"llm_calls\": 0,\n",
    "            \"parallel_executions\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"component_times\": {}\n",
    "        }\n",
    "        self.current_component = None\n",
    "        self.component_start = None\n",
    "    \n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        if not self.metrics[\"start_time\"]:\n",
    "            self.metrics[\"start_time\"] = time.time()\n",
    "        self.component_start = time.time()\n",
    "    \n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        if self.component_start:\n",
    "            duration = time.time() - self.component_start\n",
    "            component_name = self.current_component or \"unknown\"\n",
    "            self.metrics[\"component_times\"][component_name] = duration\n",
    "            self.metrics[\"components_generated\"] += 1\n",
    "        \n",
    "        self.metrics[\"end_time\"] = time.time()\n",
    "    \n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        self.metrics[\"llm_calls\"] += 1\n",
    "    \n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        if hasattr(response, 'llm_output') and response.llm_output:\n",
    "            token_usage = response.llm_output.get('token_usage', {})\n",
    "            self.metrics[\"total_tokens\"] += token_usage.get('total_tokens', 0)\n",
    "    \n",
    "    def on_chain_error(self, error, **kwargs):\n",
    "        self.metrics[\"errors\"] += 1\n",
    "    \n",
    "    def get_summary(self):\n",
    "        total_time = (self.metrics[\"end_time\"] or time.time()) - (self.metrics[\"start_time\"] or time.time())\n",
    "        return {\n",
    "            **self.metrics,\n",
    "            \"total_time\": total_time,\n",
    "            \"avg_time_per_component\": total_time / max(self.metrics[\"components_generated\"], 1),\n",
    "            \"tokens_per_second\": self.metrics[\"total_tokens\"] / max(total_time, 1),\n",
    "            \"success_rate\": (self.metrics[\"components_generated\"] - self.metrics[\"errors\"]) / max(self.metrics[\"components_generated\"], 1) * 100\n",
    "        }\n",
    "\n",
    "# 2. Ejecutar generación con métricas\n",
    "print(\"🚀 INICIANDO GENERACIÓN CRUD AUTOMATIZADA...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metrics_callback = CRUDGenerationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a8d55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_config.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9e4639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3788136/4071791889.py:5: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"fields\": [f.dict() for f in sample_config.fields],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'resource_name': 'product',\n",
       " 'class_name': 'Product',\n",
       " 'fields': [{'name': 'name',\n",
       "   'type': 'str',\n",
       "   'description': 'Nombre del producto',\n",
       "   'constraints': {'min_length': 1, 'max_length': 100}},\n",
       "  {'name': 'price',\n",
       "   'type': 'float',\n",
       "   'description': 'Precio en USD',\n",
       "   'constraints': {'ge': 0, 'le': 999999}},\n",
       "  {'name': 'category',\n",
       "   'type': 'str',\n",
       "   'description': 'Categoría',\n",
       "   'constraints': None},\n",
       "  {'name': 'stock',\n",
       "   'type': 'int',\n",
       "   'description': 'Cantidad en inventario',\n",
       "   'constraints': {'ge': 0}}],\n",
       " 'auth_required': True,\n",
       " 'cache_enabled': True,\n",
       " 'soft_delete': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparar input para el pipeline\n",
    "pipeline_input = {\n",
    "    \"resource_name\": sample_config.resource_name,\n",
    "    \"class_name\": sample_config.class_name,\n",
    "    \"fields\": [f.dict() for f in sample_config.fields],\n",
    "    \"auth_required\": sample_config.auth_required,\n",
    "    \"cache_enabled\": sample_config.cache_enabled,\n",
    "    \"soft_delete\": sample_config.soft_delete\n",
    "}\n",
    "\n",
    "pipeline_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c1330cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación Completa en 446.1253263950348\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el pipeline\n",
    "start_generation = time.time()\n",
    "generated_components = crud_pipeline.invoke(pipeline_input)\n",
    "generation_time = time.time() - start_generation\n",
    "\n",
    "print(f\"Generación Completa en {generation_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "227c9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratedComponents(modelo_pydantic='from __future__ import annotations\\n\\nfrom datetime import datetime, timezone\\nfrom decimal import Decimal, ROUND_HALF_UP, InvalidOperation\\nfrom typing import Annotated, Optional\\nfrom uuid import UUID\\n\\nfrom pydantic import (\\n    BaseModel,\\n    ConfigDict,\\n    Field,\\n    StringConstraints,\\n    StrictInt,\\n    field_validator,\\n    model_validator,\\n)\\n\\n\\nNameStr = Annotated[\\n    str,\\n    StringConstraints(\\n        min_length=1,\\n        max_length=100,\\n        strip_whitespace=True,\\n    ),\\n]\\n\\nCategoryStr = Annotated[\\n    str,\\n    StringConstraints(\\n        strip_whitespace=True,\\n    ),\\n]\\n\\n\\nclass ProductBase(BaseModel):\\n    \"\"\"\\n    Modelo base del recurso Product.\\n\\n    Incluye validaciones y normalización:\\n    - name: recorta y colapsa espacios múltiples, no permite caracteres de control.\\n    - price: convierte a Decimal, redondea a 2 decimales (ROUND_HALF_UP), y valida rango.\\n    - category: recorta y colapsa espacios múltiples, no permite vacío.\\n    - stock: entero estricto, no negativo.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"name\": \"Camiseta Básica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(from_attributes=True)\\n\\n    name: NameStr = Field(\\n        ...,\\n        description=\"Nombre del producto\",\\n        examples=[\"Camiseta Básica\"],\\n    )\\n    price: Decimal = Field(\\n        ...,\\n        ge=Decimal(\"0\"),\\n        le=Decimal(\"999999.99\"),\\n        description=\"Precio en USD\",\\n        examples=[19.99, \"149.90\"],\\n    )\\n    category: CategoryStr = Field(\\n        ...,\\n        description=\"Categoría\",\\n        examples=[\"Ropa\"],\\n    )\\n    stock: StrictInt = Field(\\n        ...,\\n        ge=0,\\n        description=\"Cantidad en inventario\",\\n        examples=[150],\\n    )\\n\\n    @field_validator(\"name\")\\n    @classmethod\\n    def validate_name(cls, v: str) -> str:\\n        # Colapsar espacios y sanitizar caracteres de control\\n        compact = \" \".join(v.split())\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"El nombre contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"category\")\\n    @classmethod\\n    def validate_category(cls, v: str) -> str:\\n        # Colapsar espacios\\n        compact = \" \".join(v.split())\\n        if compact == \"\":\\n            raise ValueError(\"La categoría no puede estar vacía.\")\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"La categoría contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"price\", mode=\"before\")\\n    @classmethod\\n    def coerce_price(cls, v) -> Decimal:\\n        # Acepta str/float/int y los convierte de forma segura a Decimal\\n        if isinstance(v, Decimal):\\n            return v\\n        if isinstance(v, (int, float)):\\n            # Convertir float mediante str para evitar errores binarios\\n            v = str(v)\\n        if isinstance(v, str):\\n            s = v.strip().replace(\",\", \".\")\\n            try:\\n                return Decimal(s)\\n            except InvalidOperation:\\n                raise ValueError(\"Formato de precio inválido.\")\\n        raise TypeError(\"Tipo de dato de precio no soportado.\")\\n\\n    @field_validator(\"price\")\\n    @classmethod\\n    def normalize_and_validate_price(cls, v: Decimal) -> Decimal:\\n        # Redondeo a 2 decimales con HALF_UP\\n        quantized = v.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\\n        # Validar rango explícitamente\\n        if quantized < Decimal(\"0\") or quantized > Decimal(\"999999.99\"):\\n            raise ValueError(\"El precio debe estar entre 0 y 999,999.99 USD.\")\\n        return quantized\\n\\n\\nclass ProductCreate(ProductBase):\\n    \"\"\"\\n    Modelo de entrada (creación) para Product.\\n\\n    Notas:\\n    - Los metadatos de auditoría (created_by) y control de versiones/ETag\\n      son gestionados por el servidor, no se envían en el cuerpo de creación.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"name\": \"Camiseta Básica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(\\n        from_attributes=True,\\n        json_schema_extra={\\n            \"examples\": [\\n                {\\n                    \"name\": \"Camiseta Básica\",\\n                    \"price\": 19.99,\\n                    \"category\": \"Ropa\",\\n                    \"stock\": 150,\\n                },\\n                {\\n                    \"name\": \"Laptop Pro 14”\",\\n                    \"price\": \"1499.00\",\\n                    \"category\": \"Electrónica\",\\n                    \"stock\": 25,\\n                },\\n            ]\\n        },\\n    )\\n\\n\\nclass ProductUpdate(BaseModel):\\n    \"\"\"\\n    Modelo de entrada (actualización parcial) para Product.\\n\\n    Reglas:\\n    - Al menos un campo de negocio (name, price, category, stock) debe enviarse.\\n    - Se requiere \\'version\\' para control de concurrencia optimista.\\n    - \\'price\\' se normaliza a 2 decimales con ROUND_HALF_UP.\\n    - Las cadenas se recortan y colapsan espacios.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"price\": 17.49,\\n      \"stock\": 200,\\n      \"version\": 3\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(from_attributes=True)\\n\\n    name: Optional[NameStr] = Field(None, description=\"Nombre del producto\")\\n    price: Optional[Decimal] = Field(\\n        None,\\n        ge=Decimal(\"0\"),\\n        le=Decimal(\"999999.99\"),\\n        description=\"Precio en USD\",\\n    )\\n    category: Optional[CategoryStr] = Field(None, description=\"Categoría\")\\n    stock: Optional[StrictInt] = Field(None, ge=0, description=\"Cantidad en inventario\")\\n\\n    # Control de concurrencia (útil para ETag/If-Match y caches)\\n    version: StrictInt = Field(\\n        ...,\\n        ge=1,\\n        description=\"Versión del recurso para control de concurrencia optimista\",\\n        examples=[3],\\n    )\\n\\n    @field_validator(\"name\")\\n    @classmethod\\n    def validate_name(cls, v: Optional[str]) -> Optional[str]:\\n        if v is None:\\n            return v\\n        compact = \" \".join(v.split())\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"El nombre contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"category\")\\n    @classmethod\\n    def validate_category(cls, v: Optional[str]) -> Optional[str]:\\n        if v is None:\\n            return v\\n        compact = \" \".join(v.split())\\n        if compact == \"\":\\n            raise ValueError(\"La categoría no puede estar vacía.\")\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"La categoría contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"price\", mode=\"before\")\\n    @classmethod\\n    def coerce_price(cls, v) -> Optional[Decimal]:\\n        if v is None:\\n            return v\\n        if isinstance(v, Decimal):\\n            return v\\n        if isinstance(v, (int, float)):\\n            v = str(v)\\n        if isinstance(v, str):\\n            s = v.strip().replace(\",\", \".\")\\n            try:\\n                return Decimal(s)\\n            except InvalidOperation:\\n                raise ValueError(\"Formato de precio inválido.\")\\n        raise TypeError(\"Tipo de dato de precio no soportado.\")\\n\\n    @field_validator(\"price\")\\n    @classmethod\\n    def normalize_and_validate_price(cls, v: Optional[Decimal]) -> Optional[Decimal]:\\n        if v is None:\\n            return v\\n        quantized = v.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\\n        if quantized < Decimal(\"0\") or quantized > Decimal(\"999999.99\"):\\n            raise ValueError(\"El precio debe estar entre 0 y 999,999.99 USD.\")\\n        return quantized\\n\\n    @model_validator(mode=\"after\")\\n    def ensure_any_business_field_present(self):\\n        if (\\n            self.name is None\\n            and self.price is None\\n            and self.category is None\\n            and self.stock is None\\n        ):\\n            raise ValueError(\\n                \"Debe especificarse al menos uno de los campos: name, price, category, stock.\"\\n            )\\n        return self\\n\\n\\nclass ProductOut(ProductBase):\\n    \"\"\"\\n    Modelo de salida (lectura) para Product.\\n\\n    Incluye:\\n    - id: UUID del recurso.\\n    - created_at / updated_at: timestamps con zona horaria.\\n    - Auditoría (auth=True): created_by / updated_by (UUIDs de usuario).\\n    - soft_delete=True: is_deleted, deleted_at, deleted_reason.\\n    - cache=True: version (concurrencia) y etag (caching HTTP).\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"id\": \"5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a\",\\n      \"name\": \"Camiseta Básica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150,\\n      \"version\": 3,\\n      \"etag\": \"W/\\\\\"product-5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a-v3\\\\\"\",\\n      \"created_at\": \"2024-09-01T10:15:30+00:00\",\\n      \"updated_at\": \"2024-09-10T09:00:00+00:00\",\\n      \"created_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n      \"updated_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n      \"is_deleted\": false,\\n      \"deleted_at\": null,\\n      \"deleted_reason\": null\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(\\n        from_attributes=True,\\n        json_schema_extra={\\n            \"examples\": [\\n                {\\n                    \"id\": \"5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a\",\\n                    \"name\": \"Camiseta Básica\",\\n                    \"price\": 19.99,\\n                    \"category\": \"Ropa\",\\n                    \"stock\": 150,\\n                    \"version\": 3,\\n                    \"etag\": \\'W/\"product-5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a-v3\"\\',\\n                    \"created_at\": \"2024-09-01T10:15:30+00:00\",\\n                    \"updated_at\": \"2024-09-10T09:00:00+00:00\",\\n                    \"created_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n                    \"updated_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n                    \"is_deleted\": False,\\n                    \"deleted_at\": None,\\n                    \"deleted_reason\": None,\\n                }\\n            ]\\n        },\\n    )\\n\\n    id: UUID = Field(..., description=\"Identificador único del producto\")\\n    version: StrictInt = Field(\\n        ...,\\n        ge=1,\\n        description=\"Versión del recurso para control de concurrencia/caching\",\\n    )\\n    etag: str = Field(\\n        ...,\\n        description=\\'Entidad para caching HTTP. Ej: W/\"product-<id>-v<version>\"\\',\\n    )\\n\\n    created_at: datetime = Field(\\n        ...,\\n        description=\"Fecha de creación (timezone-aware, ISO 8601)\",\\n    )\\n    updated_at: datetime = Field(\\n        ...,\\n        description=\"Fecha de última actualización (timezone-aware, ISO 8601)\",\\n    )\\n    created_by: Optional[UUID] = Field(\\n        None, description=\"Usuario que creó el recurso (auditoría)\"\\n    )\\n    updated_by: Optional[UUID] = Field(\\n        None, description=\"Usuario que actualizó el recurso (auditoría)\"\\n    )\\n\\n    is_deleted: bool = Field(\\n        False, description=\"Indicador de eliminación lógica (soft delete)\"\\n    )\\n    deleted_at: Optional[datetime] = Field(\\n        None, description=\"Fecha de eliminación lógica (si aplica)\"\\n    )\\n    deleted_reason: Optional[str] = Field(\\n        None, description=\"Motivo de la eliminación lógica (si aplica)\"\\n    )\\n\\n    @field_validator(\"created_at\", \"updated_at\", \"deleted_at\")\\n    @classmethod\\n    def ensure_timezone_aware(cls, v: Optional[datetime]) -> Optional[datetime]:\\n        if v is None:\\n            return v\\n        if v.tzinfo is None or v.tzinfo.utcoffset(v) is None:\\n            raise ValueError(\"Los timestamps deben incluir zona horaria (timezone-aware).\")\\n        return v\\n\\n    @field_validator(\"etag\")\\n    @classmethod\\n    def validate_etag(cls, v: str) -> str:\\n        if not v or not v.strip():\\n            raise ValueError(\"ETag no puede estar vacío.\")\\n        return v.strip()\\n\\n    @model_validator(mode=\"after\")\\n    def validate_soft_delete_state(self):\\n        if self.is_deleted:\\n            if self.deleted_at is None:\\n                raise ValueError(\"deleted_at es requerido cuando is_deleted es true.\")\\n        else:\\n            if self.deleted_at is not None or self.deleted_reason is not None:\\n                raise ValueError(\\n                    \"deleted_at y deleted_reason deben ser null cuando is_deleted es false.\"\\n                )\\n        return self', router_fastapi='A continuación tienes un router FastAPI de nivel empresarial para el recurso Product, alineado con tus modelos Pydantic y la configuración (auth_required=true, cache_enabled=true, soft_delete=true). Incluye:\\n\\n- Endpoints CRUD completos (GET list, GET by id, POST, PUT, PATCH, DELETE soft), y extras restore y hard delete.\\n- Paginación, filtrado y ordenamiento.\\n- ETag/If-None-Match/If-Match (caching y concurrencia optimista).\\n- Manejo de errores consistente con payload estructurado.\\n- Validación de permisos y autenticación vía dependencias.\\n- Logging estructurado.\\n- Documentación OpenAPI rica y ejemplos.\\n\\nCopia/pega en tu proyecto y reemplaza la implementación del repositorio por tu capa de datos (SQLAlchemy, etc.).\\n\\n\\nfrom __future__ import annotations\\n\\nimport hashlib\\nimport logging\\nfrom datetime import datetime, timezone\\nfrom typing import Annotated, Iterable, Optional\\nfrom uuid import UUID, uuid4\\n\\nfrom fastapi import (\\n    APIRouter,\\n    Depends,\\n    HTTPException,\\n    Path,\\n    Query,\\n    Body,\\n    Request,\\n    Response,\\n    status,\\n)\\nfrom pydantic import BaseModel, Field, StrictInt\\n\\n# Importa tus modelos tal cual los definiste\\n# from app.models.product import ProductCreate, ProductUpdate, ProductOut\\n# Para este snippet asumimos que ya están en el scope:\\n# ProductCreate, ProductUpdate, ProductOut\\n\\n# ==============================================================================\\n# Configuración y constantes del recurso\\n# ==============================================================================\\n\\nRESOURCE_NAME = \"product\"\\nROUTE_PREFIX = \"/products\"\\nTAG = \"Products\"\\nMAX_PAGE_SIZE = 100\\nDEFAULT_PAGE_SIZE = 20\\nDEFAULT_SORT = \"-created_at\"\\nALLOWED_SORT_FIELDS = {\"name\", \"price\", \"category\", \"stock\", \"created_at\", \"updated_at\"}\\n\\nlogger = logging.getLogger(f\"api.{RESOURCE_NAME}\")\\nlogger.setLevel(logging.INFO)\\n\\n\\n# ==============================================================================\\n# Autenticación y permisos (dependencias)\\n# ==============================================================================\\n\\nclass User(BaseModel):\\n    id: UUID\\n    # Scopes de ejemplo:\\n    # - product:read\\n    # - product:read:deleted\\n    # - product:create\\n    # - product:update\\n    # - product:delete\\n    # - product:restore\\n    # - product:hard_delete\\n    scopes: set[str] = Field(default_factory=set)\\n\\n\\ndef get_current_user(request: Request) -> User:\\n    \"\"\"\\n    Placeholder de autenticación. En producción integra:\\n    - OAuth2/OIDC (Access Token), o\\n    - JWT firmado, o\\n    - Capa SSO corporativa.\\n    \"\"\"\\n    user: Optional[User] = getattr(request.state, \"user\", None)\\n    if user is None:\\n        # Para entornos de desarrollo, puedes inyectar un usuario por header:\\n        debug_user = request.headers.get(\"X-Debug-User\")\\n        if debug_user == \"admin\":\\n            return User(id=uuid4(), scopes={\\n                \"product:read\", \"product:read:deleted\", \"product:create\",\\n                \"product:update\", \"product:delete\", \"product:restore\",\\n                \"product:hard_delete\",\\n            })\\n        if debug_user == \"reader\":\\n            return User(id=uuid4(), scopes={\"product:read\"})\\n        raise HTTPException(\\n            status_code=status.HTTP_401_UNAUTHORIZED,\\n            detail={\"code\": \"auth_required\", \"message\": \"Autenticación requerida\"},\\n        )\\n    return user\\n\\n\\ndef require_scopes(*required_scopes: str):\\n    def _dep(user: User = Depends(get_current_user)) -> User:\\n        missing = [s for s in required_scopes if s not in user.scopes]\\n        if missing:\\n            raise HTTPException(\\n                status_code=status.HTTP_403_FORBIDDEN,\\n                detail={\\n                    \"code\": \"insufficient_permissions\",\\n                    \"message\": \"Permisos insuficientes\",\\n                    \"required\": required_scopes,\\n                },\\n            )\\n        return user\\n    return _dep\\n\\n\\n# ==============================================================================\\n# Repositorio/Servicio (interfaz)\\n# ==============================================================================\\n\\nclass ProductRecord(BaseModel):\\n    id: UUID\\n    name: str\\n    price: float  # se normaliza a Decimal en los modelos Pydantic de salida\\n    category: str\\n    stock: int\\n    version: StrictInt\\n    created_at: datetime\\n    updated_at: datetime\\n    created_by: Optional[UUID] = None\\n    updated_by: Optional[UUID] = None\\n    is_deleted: bool = False\\n    deleted_at: Optional[datetime] = None\\n    deleted_reason: Optional[str] = None\\n\\n    @property\\n    def etag(self) -> str:\\n        return f\\'W/\"{RESOURCE_NAME}-{self.id}-v{self.version}\"\\'\\n\\n\\nclass ListResult(BaseModel):\\n    items: list[ProductRecord]\\n    total: int\\n    # Para caching de colección\\n    max_updated_at: Optional[datetime] = None\\n    version_sum: int = 0\\n\\n\\nclass ProductRepositoryProtocol:\\n    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord: ...\\n    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]: ...\\n    async def list(\\n        self,\\n        *,\\n        page: int,\\n        size: int,\\n        filters: dict,\\n        sort: list[tuple[str, str]],\\n        include_deleted: bool,\\n    ) -> ListResult: ...\\n    async def replace(\\n        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]: ...\\n    async def patch(\\n        self, product_id: UUID, data: ProductUpdate, by: UUID\\n    ) -> Optional[ProductRecord]: ...\\n    async def soft_delete(\\n        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\\n    ) -> bool: ...\\n    async def restore(\\n        self, product_id: UUID, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]: ...\\n    async def hard_delete(self, product_id: UUID) -> bool: ...\\n\\n\\n# ==============================================================================\\n# Dependencia del repositorio (inyecta tu implementación real)\\n# ==============================================================================\\n\\nasync def get_repository() -> ProductRepositoryProtocol:\\n    \"\"\"\\n    Inyecta aquí tu implementación real (SQLAlchemy/AsyncSession).\\n    Puedes usar un contenedor o wiring con FastAPI.\\n    \"\"\"\\n    raise NotImplementedError(\"Inyecta la implementación concreta del repositorio\")\\n\\n\\n# ==============================================================================\\n# Utilidades: ordenamiento, filtros, paginación, ETag de colección\\n# ==============================================================================\\n\\ndef parse_sort(sort: Optional[str]) -> list[tuple[str, str]]:\\n    if not sort:\\n        sort = DEFAULT_SORT\\n    tokens = [t.strip() for t in sort.split(\",\") if t.strip()]\\n    out: list[tuple[str, str]] = []\\n    for t in tokens:\\n        direction = \"asc\"\\n        field = t\\n        if t.startswith(\"-\"):\\n            direction = \"desc\"\\n            field = t[1:]\\n        elif t.startswith(\"+\"):\\n            field = t[1:]\\n        if field not in ALLOWED_SORT_FIELDS:\\n            raise HTTPException(\\n                status_code=status.HTTP_400_BAD_REQUEST,\\n                detail={\\n                    \"code\": \"invalid_sort\",\\n                    \"message\": f\"Campo de ordenamiento no permitido: {field}\",\\n                    \"allowed\": sorted(ALLOWED_SORT_FIELDS),\\n                },\\n            )\\n        out.append((field, direction))\\n    return out\\n\\n\\ndef collection_etag(result: ListResult, fingerprint: str) -> str:\\n    \"\"\"\\n    ETag débil para la colección:\\n    Hash de total, max_updated_at, version_sum y un fingerprint de parámetros.\\n    \"\"\"\\n    max_ts = (\\n        result.max_updated_at.astimezone(timezone.utc).isoformat()\\n        if result.max_updated_at\\n        else \"none\"\\n    )\\n    payload = f\"{RESOURCE_NAME}:{result.total}:{max_ts}:{result.version_sum}:{fingerprint}\"\\n    h = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:16]\\n    return f\\'W/\"{RESOURCE_NAME}-collection-{h}\"\\'\\n\\n\\ndef paginated_links(base_path: str, page: int, size: int, total: int, qs: str = \"\") -> str:\\n    pages = (total + size - 1) // size if total > 0 else 1\\n    links: list[str] = []\\n    def url(p: int) -> str:\\n        return f\\'{base_path}?page={p}&size={size}{qs}\\'\\n    links.append(f\\'<{url(1)}>; rel=\"first\"\\')\\n    links.append(f\\'<{url(pages)}>; rel=\"last\"\\')\\n    if page > 1:\\n        links.append(f\\'<{url(page - 1)}>; rel=\"prev\"\\')\\n    if page < pages:\\n        links.append(f\\'<{url(page + 1)}>; rel=\"next\"\\')\\n    return \", \".join(links)\\n\\n\\ndef http_error(status_code: int, code: str, message: str, **extra):\\n    raise HTTPException(status_code=status_code, detail={\"code\": code, \"message\": message, **extra})\\n\\n\\n# ==============================================================================\\n# Router\\n# ==============================================================================\\n\\nrouter = APIRouter(prefix=ROUTE_PREFIX, tags=[TAG])\\n\\n\\n# -----------------------------\\n# GET /products (listado)\\n# -----------------------------\\n@router.get(\\n    \"\",\\n    summary=\"Listar productos\",\\n    response_model=dict,\\n    responses={\\n        200: {\"description\": \"Listado paginado de productos\"},\\n        304: {\"description\": \"No modificado (ETag coincide)\"},\\n        400: {\"description\": \"Solicitud inválida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n    },\\n)\\nasync def list_products(\\n    request: Request,\\n    response: Response,\\n    page: Annotated[int, Query(ge=1)] = 1,\\n    size: Annotated[int, Query(ge=1, le=MAX_PAGE_SIZE)] = DEFAULT_PAGE_SIZE,\\n    search: Annotated[Optional[str], Query(description=\"Búsqueda en nombre/categoría\")] = None,\\n    name: Optional[str] = Query(None, description=\"Filtro exacto por nombre\"),\\n    category: Optional[str] = Query(None, description=\"Filtro exacto por categoría\"),\\n    price_min: Optional[float] = Query(None, ge=0),\\n    price_max: Optional[float] = Query(None, ge=0),\\n    stock_min: Optional[int] = Query(None, ge=0),\\n    stock_max: Optional[int] = Query(None, ge=0),\\n    sort: Optional[str] = Query(DEFAULT_SORT, description=\"Ej: -created_at,+price\"),\\n    include_deleted: bool = Query(False, description=\"Incluir eliminados (requiere permiso)\"),\\n    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:read\")),\\n):\\n    if include_deleted and \"product:read:deleted\" not in user.scopes:\\n        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\\n\\n    order = parse_sort(sort)\\n\\n    filters = {\\n        \"search\": search,\\n        \"name\": name,\\n        \"category\": category,\\n        \"price_min\": price_min,\\n        \"price_max\": price_max,\\n        \"stock_min\": stock_min,\\n        \"stock_max\": stock_max,\\n    }\\n\\n    # Fingerprint de parámetros para el ETag de colección\\n    fp = f\"p={page}|s={size}|sort={order}|incdel={include_deleted}|f={filters}\"\\n\\n    result = await repo.list(\\n        page=page,\\n        size=size,\\n        filters=filters,\\n        sort=order,\\n        include_deleted=include_deleted,\\n    )\\n\\n    etag = collection_etag(result, fp)\\n    if if_none_match and if_none_match.strip() == etag:\\n        response.headers[\"ETag\"] = etag\\n        response.status_code = status.HTTP_304_NOT_MODIFIED\\n        return\\n\\n    # Paginated response envelope\\n    items_out = [\\n        ProductOut(\\n            id=it.id,\\n            name=it.name,\\n            price=it.price,\\n            category=it.category,\\n            stock=it.stock,\\n            version=it.version,\\n            etag=it.etag,\\n            created_at=it.created_at,\\n            updated_at=it.updated_at,\\n            created_by=it.created_by,\\n            updated_by=it.updated_by,\\n            is_deleted=it.is_deleted,\\n            deleted_at=it.deleted_at,\\n            deleted_reason=it.deleted_reason,\\n        )\\n        for it in result.items\\n    ]\\n\\n    response.headers[\"X-Total-Count\"] = str(result.total)\\n    # Link header con navegación\\n    # Conserva query string de filtros\\n    raw_qs = \"\"\\n    qparts = []\\n    if search is not None:\\n        qparts.append(f\"&search={search}\")\\n    if name is not None:\\n        qparts.append(f\"&name={name}\")\\n    if category is not None:\\n        qparts.append(f\"&category={category}\")\\n    if price_min is not None:\\n        qparts.append(f\"&price_min={price_min}\")\\n    if price_max is not None:\\n        qparts.append(f\"&price_max={price_max}\")\\n    if stock_min is not None:\\n        qparts.append(f\"&stock_min={stock_min}\")\\n    if stock_max is not None:\\n        qparts.append(f\"&stock_max={stock_max}\")\\n    if sort is not None:\\n        qparts.append(f\"&sort={sort}\")\\n    if include_deleted:\\n        qparts.append(f\"&include_deleted=true\")\\n    raw_qs = \"\".join(qparts)\\n    response.headers[\"Link\"] = paginated_links(ROUTE_PREFIX, page, size, result.total, raw_qs)\\n    response.headers[\"ETag\"] = etag\\n    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\\n\\n    logger.info(\\n        \"product_list\",\\n        extra={\\n            \"event\": \"product_list\",\\n            \"user_id\": str(user.id),\\n            \"page\": page,\\n            \"size\": size,\\n            \"total\": result.total,\\n            \"filters\": filters,\\n            \"sort\": order,\\n        },\\n    )\\n\\n    pages = (result.total + size - 1) // size if result.total > 0 else 1\\n    return {\\n        \"items\": items_out,\\n        \"page\": page,\\n        \"size\": size,\\n        \"total\": result.total,\\n        \"pages\": pages,\\n    }\\n\\n\\n# -----------------------------\\n# GET /products/{id}\\n# -----------------------------\\nfrom fastapi import Header  # placed here to avoid confusion in snippet scope\\n\\n@router.get(\\n    \"/{product_id}\",\\n    summary=\"Obtener producto por ID\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Producto encontrado\"},\\n        304: {\"description\": \"No modificado (ETag coincide)\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n    },\\n)\\nasync def get_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    include_deleted: bool = Query(False, description=\"Incluir eliminado\"),\\n    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:read\")),\\n):\\n    if include_deleted and \"product:read:deleted\" not in user.scopes:\\n        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\\n\\n    record = await repo.get(product_id, include_deleted=include_deleted)\\n    if not record or (record.is_deleted and not include_deleted):\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    if if_none_match and if_none_match.strip() == record.etag:\\n        response.headers[\"ETag\"] = record.etag\\n        response.status_code = status.HTTP_304_NOT_MODIFIED\\n        return\\n\\n    response.headers[\"ETag\"] = record.etag\\n    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\\n\\n    return ProductOut(\\n        id=record.id,\\n        name=record.name,\\n        price=record.price,\\n        category=record.category,\\n        stock=record.stock,\\n        version=record.version,\\n        etag=record.etag,\\n        created_at=record.created_at,\\n        updated_at=record.updated_at,\\n        created_by=record.created_by,\\n        updated_by=record.updated_by,\\n        is_deleted=record.is_deleted,\\n        deleted_at=record.deleted_at,\\n        deleted_reason=record.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# POST /products (crear)\\n# -----------------------------\\n@router.post(\\n    \"\",\\n    summary=\"Crear producto\",\\n    status_code=status.HTTP_201_CREATED,\\n    response_model=ProductOut,\\n    responses={\\n        201: {\"description\": \"Creado\"},\\n        400: {\"description\": \"Solicitud inválida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        409: {\"description\": \"Conflicto\"},\\n    },\\n)\\nasync def create_product(\\n    response: Response,\\n    payload: ProductCreate = Body(...),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:create\")),\\n):\\n    created = await repo.create(payload, by=user.id)\\n\\n    response.headers[\"Location\"] = f\"{ROUTE_PREFIX}/{created.id}\"\\n    response.headers[\"ETag\"] = created.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_created\",\\n        extra={\"event\": \"product_created\", \"user_id\": str(user.id), \"product_id\": str(created.id)},\\n    )\\n\\n    return ProductOut(\\n        id=created.id,\\n        name=created.name,\\n        price=created.price,\\n        category=created.category,\\n        stock=created.stock,\\n        version=created.version,\\n        etag=created.etag,\\n        created_at=created.created_at,\\n        updated_at=created.updated_at,\\n        created_by=created.created_by,\\n        updated_by=created.updated_by,\\n        is_deleted=created.is_deleted,\\n        deleted_at=created.deleted_at,\\n        deleted_reason=created.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# PUT /products/{id} (reemplazo total)\\n# Requiere If-Match con el ETag actual para concurrencia.\\n# -----------------------------\\n@router.put(\\n    \"/{product_id}\",\\n    summary=\"Reemplazar producto (PUT)\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Actualizado\"},\\n        400: {\"description\": \"Solicitud inválida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def replace_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    payload: ProductCreate = Body(...),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:update\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PUT\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto está eliminado lógicamente\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    updated = await repo.replace(product_id, payload, by=user.id, expected_version=current.version)\\n\\n    if not updated:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible reemplazar el recurso (conflicto de versión)\")\\n\\n    response.headers[\"ETag\"] = updated.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_replaced\",\\n        extra={\"event\": \"product_replaced\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=updated.id,\\n        name=updated.name,\\n        price=updated.price,\\n        category=updated.category,\\n        stock=updated.stock,\\n        version=updated.version,\\n        etag=updated.etag,\\n        created_at=updated.created_at,\\n        updated_at=updated.updated_at,\\n        created_by=updated.created_by,\\n        updated_by=updated.updated_by,\\n        is_deleted=updated.is_deleted,\\n        deleted_at=updated.deleted_at,\\n        deleted_reason=updated.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# PATCH /products/{id} (parcial)\\n# Requiere version en payload y If-Match en header.\\n# -----------------------------\\n@router.patch(\\n    \"/{product_id}\",\\n    summary=\"Actualizar parcialmente producto (PATCH)\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Actualizado\"},\\n        400: {\"description\": \"Solicitud inválida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        409: {\"description\": \"Conflicto de versión\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def patch_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    payload: ProductUpdate = Body(...),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:update\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PATCH\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto está eliminado lógicamente\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    # Validación adicional de versión (optimista)\\n    if payload.version != current.version:\\n        http_error(\\n            status.HTTP_409_CONFLICT,\\n            \"version_conflict\",\\n            f\"Versión desactualizada. Actual: {current.version}, recibida: {payload.version}\",\\n        )\\n\\n    updated = await repo.patch(product_id, payload, by=user.id)\\n    if not updated:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible actualizar el recurso\")\\n\\n    response.headers[\"ETag\"] = updated.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_patched\",\\n        extra={\"event\": \"product_patched\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=updated.id,\\n        name=updated.name,\\n        price=updated.price,\\n        category=updated.category,\\n        stock=updated.stock,\\n        version=updated.version,\\n        etag=updated.etag,\\n        created_at=updated.created_at,\\n        updated_at=updated.updated_at,\\n        created_by=updated.created_by,\\n        updated_by=updated.updated_by,\\n        is_deleted=updated.is_deleted,\\n        deleted_at=updated.deleted_at,\\n        deleted_reason=updated.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# DELETE /products/{id} (soft delete)\\n# -----------------------------\\n@router.delete(\\n    \"/{product_id}\",\\n    summary=\"Eliminar producto (soft delete)\",\\n    status_code=status.HTTP_204_NO_CONTENT,\\n    responses={\\n        204: {\"description\": \"Eliminado lógicamente\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def delete_product(\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    reason: Optional[str] = Query(None, description=\"Motivo de eliminación\"),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:delete\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para DELETE\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    ok = await repo.soft_delete(product_id, by=user.id, reason=reason, expected_version=current.version)\\n    if not ok:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible eliminar el recurso (conflicto de versión)\")\\n\\n    logger.info(\\n        \"product_soft_deleted\",\\n        extra={\"event\": \"product_soft_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id), \"reason\": reason},\\n    )\\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\\n\\n\\n# -----------------------------\\n# POST /products/{id}/restore (restaurar soft delete)\\n# -----------------------------\\n@router.post(\\n    \"/{product_id}/restore\",\\n    summary=\"Restaurar producto eliminado\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Restaurado\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        409: {\"description\": \"Conflicto\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def restore_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:restore\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para restaurar\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if not current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"not_deleted\", \"El producto no está eliminado\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    restored = await repo.restore(product_id, by=user.id, expected_version=current.version)\\n    if not restored:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible restaurar el recurso\")\\n\\n    response.headers[\"ETag\"] = restored.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_restored\",\\n        extra={\"event\": \"product_restored\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=restored.id,\\n        name=restored.name,\\n        price=restored.price,\\n        category=restored.category,\\n        stock=restored.stock,\\n        version=restored.version,\\n        etag=restored.etag,\\n        created_at=restored.created_at,\\n        updated_at=restored.updated_at,\\n        created_by=restored.created_by,\\n        updated_by=restored.updated_by,\\n        is_deleted=restored.is_deleted,\\n        deleted_at=restored.deleted_at,\\n        deleted_reason=restored.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# DELETE /products/{id}/hard (eliminación definitiva)\\n# -----------------------------\\n@router.delete(\\n    \"/{product_id}/hard\",\\n    summary=\"[ADMIN] Eliminación definitiva (hard delete)\",\\n    status_code=status.HTTP_204_NO_CONTENT,\\n    responses={\\n        204: {\"description\": \"Eliminado definitivamente\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n    },\\n)\\nasync def hard_delete_product(\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:hard_delete\")),\\n):\\n    ok = await repo.hard_delete(product_id)\\n    if not ok:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    logger.warning(\\n        \"product_hard_deleted\",\\n        extra={\"event\": \"product_hard_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\\n\\n\\n# ==============================================================================\\n# Notas para la implementación del repositorio\\n# ==============================================================================\\n\\n# - create:\\n#   - version = 1\\n#   - created_at = updated_at = datetime.now(timezone.utc)\\n#   - created_by = updated_by = user_id\\n#   - is_deleted = False\\n# - replace:\\n#   - Validar expected_version (si no coincide => conflicto)\\n#   - Actualizar todos los campos de negocio; version += 1; updated_at = now; updated_by = user_id\\n# - patch:\\n#   - Validar que el recurso no esté eliminado\\n#   - Validar que payload.version coincida con current.version\\n#   - Aplicar cambios parciales; version += 1; updated_at = now; updated_by\\n# - soft_delete:\\n#   - Validar expected_version\\n#   - Si ya is_deleted == True => idempotente (retornar True)\\n#   - Marcar is_deleted=True, deleted_at=now, deleted_reason=reason, version += 1\\n# - restore:\\n#   - Validar expected_version\\n#   - Si no is_deleted => conflicto\\n#   - Revertir is_deleted, limpiar deleted_at/reason, version += 1\\n# - list:\\n#   - Aplicar filtros:\\n#       - search: LIKE sobre name/category\\n#       - price_min/max, stock_min/max\\n#   - Excluir eliminados por defecto; incluir si include_deleted=True\\n#   - Ordenamiento múltiple\\n#   - Retornar total, items page/size\\n#   - max_updated_at = MAX(updated_at) del result set\\n#   - version_sum = SUM(version) del result set (para ETag colección)\\n# - get:\\n#   - Permitir include_deleted=True para operaciones administrativas\\n\\n# ==============================================================================\\n# Fin del router\\n# ==============================================================================\\n\\nExplicación breve de concurrencia y cache:\\n- GET con If-None-Match: si el ETag coincide con el estado actual, se retorna 304 sin cuerpo.\\n- PUT/PATCH/DELETE/RESTORE requieren If-Match. Si no coincide, 412 Precondition Failed.\\n- PATCH también requiere version en el cuerpo (control optimista adicional).\\n- ETag por recurso: W/\"product-<id>-v<version>\" (coincide con tu ProductOut).\\n- ETag de colección: hash débil del total, max_updated_at, suma de versiones y fingerprint de parámetros.\\n\\nSeguridad y permisos:\\n- require_scopes valida permisos granulares.\\n- Ajusta los scopes según tu modelo de seguridad real.\\n\\nLogging:\\n- Eventos clave con logger.info/logger.warning y campos estructurados en extra. Integra con tu stack (ELK/Datadog).\\n\\nDocumentación:\\n- Los endpoints incluyen summaries, responses y modelos. Puedes extender con OpenAPI callbacks o ejemplos adicionales si lo requieres.', tests_pytest='A continuación tienes una suite de tests pytest integral para tu router de Products en FastAPI. Incluye:\\n\\n- Fixtures y un repositorio en memoria que implementa ProductRepositoryProtocol (mocks).\\n- Tests unitarios por endpoint (CRUD + extras).\\n- Tests E2E de flujo completo.\\n- Tests de seguridad/autorización y validaciones.\\n- Tests de ETag/If-None-Match/If-Match (caching y concurrencia).\\n- Tests de paginación/filtrado/ordenamiento.\\n- Tests de casos borde y manejo de errores.\\n- Tests de performance básicos.\\n\\nAjusta los imports del router y modelos según tu estructura real (marcados con TODO en el código).\\n\\nEstructura sugerida:\\n- tests/conftest.py\\n- tests/test_products_unit.py\\n- tests/test_products_integration.py\\n- tests/test_products_security.py\\n- tests/test_products_performance.py\\n\\nComandos:\\n- Ejecutar: pytest -q\\n- Cobertura: pytest --maxfail=1 --disable-warnings --cov=. --cov-report=term-missing\\n\\ntests/conftest.py\\n```python\\nimport asyncio\\nfrom datetime import datetime, timezone\\nfrom decimal import Decimal\\nfrom typing import Optional, Iterable\\nfrom uuid import UUID, uuid4\\n\\nimport pytest\\nfrom fastapi import FastAPI\\nfrom fastapi.testclient import TestClient\\n\\n# TODO: Ajusta estos imports a tu proyecto real:\\n# from app.api.products import router, get_repository, ProductRecord, ListResult, ProductRepositoryProtocol, User\\n# from app.models.product import ProductCreate, ProductUpdate, ProductOut\\n\\n# Fallback de ejemplo si usas un módulo distinto:\\ntry:\\n    from app.api.products import (\\n        router,\\n        get_repository,\\n        ProductRecord,\\n        ListResult,\\n        ProductRepositoryProtocol,\\n        User,\\n    )\\n    from app.models.product import ProductCreate, ProductUpdate, ProductOut\\nexcept Exception:\\n    # Si el import falla, intenta con un módulo alterno. AJÚSTALO a tu proyecto.\\n    from products_router import (\\n        router,\\n        get_repository,\\n        ProductRecord,\\n        ListResult,\\n        ProductRepositoryProtocol,\\n        User,\\n    )\\n    from product_models import ProductCreate, ProductUpdate, ProductOut  # noqa\\n\\n\\nclass InMemoryProductRepo(ProductRepositoryProtocol):\\n    def __init__(self):\\n        self._items: dict[UUID, ProductRecord] = {}\\n\\n    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord:\\n        now = datetime.now(timezone.utc)\\n        pid = uuid4()\\n        rec = ProductRecord(\\n            id=pid,\\n            name=data.name,\\n            price=float(Decimal(data.price)),\\n            category=data.category,\\n            stock=int(data.stock),\\n            version=1,\\n            created_at=now,\\n            updated_at=now,\\n            created_by=by,\\n            updated_by=by,\\n            is_deleted=False,\\n            deleted_at=None,\\n            deleted_reason=None,\\n        )\\n        self._items[pid] = rec\\n        return rec\\n\\n    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        return rec\\n\\n    async def list(\\n        self,\\n        *,\\n        page: int,\\n        size: int,\\n        filters: dict,\\n        sort: list[tuple[str, str]],\\n        include_deleted: bool,\\n    ) -> ListResult:\\n        def apply_filters(items: Iterable[ProductRecord]) -> list[ProductRecord]:\\n            out = []\\n            search = (filters.get(\"search\") or \"\").strip().lower() or None\\n            name_exact = filters.get(\"name\")\\n            category_exact = filters.get(\"category\")\\n            price_min = filters.get(\"price_min\")\\n            price_max = filters.get(\"price_max\")\\n            stock_min = filters.get(\"stock_min\")\\n            stock_max = filters.get(\"stock_max\")\\n\\n            for it in items:\\n                if not include_deleted and it.is_deleted:\\n                    continue\\n                if search:\\n                    if search not in it.name.lower() and search not in it.category.lower():\\n                        continue\\n                if name_exact is not None and it.name != name_exact:\\n                    continue\\n                if category_exact is not None and it.category != category_exact:\\n                    continue\\n                if price_min is not None and float(it.price) < float(price_min):\\n                    continue\\n                if price_max is not None and float(it.price) > float(price_max):\\n                    continue\\n                if stock_min is not None and it.stock < int(stock_min):\\n                    continue\\n                if stock_max is not None and it.stock > int(stock_max):\\n                    continue\\n                out.append(it)\\n            return out\\n\\n        filtered = apply_filters(self._items.values())\\n\\n        # Ordenamiento múltiple\\n        def sort_key(it: ProductRecord, field: str):\\n            return getattr(it, field)\\n\\n        for field, direction in reversed(sort):\\n            reverse = direction == \"desc\"\\n            filtered.sort(key=lambda x, f=field: sort_key(x, f), reverse=reverse)\\n\\n        total = len(filtered)\\n        start = (page - 1) * size\\n        end = start + size\\n        page_items = filtered[start:end]\\n\\n        max_updated_at = max((it.updated_at for it in page_items), default=None)\\n        version_sum = sum((it.version for it in page_items), start=0)\\n\\n        return ListResult(items=page_items, total=total, max_updated_at=max_updated_at, version_sum=version_sum)\\n\\n    async def replace(\\n        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if expected_version is not None and rec.version != expected_version:\\n            return None\\n        if rec.is_deleted:\\n            # El router ya valida esto; devolvemos None para simular conflicto\\n            return None\\n        now = datetime.now(timezone.utc)\\n        rec.name = data.name\\n        rec.price = float(Decimal(data.price))\\n        rec.category = data.category\\n        rec.stock = int(data.stock)\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def patch(self, product_id: UUID, data: ProductUpdate, by: UUID) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if rec.is_deleted:\\n            return None\\n        now = datetime.now(timezone.utc)\\n        if data.name is not None:\\n            rec.name = data.name\\n        if data.price is not None:\\n            rec.price = float(Decimal(data.price))\\n        if data.category is not None:\\n            rec.category = data.category\\n        if data.stock is not None:\\n            rec.stock = int(data.stock)\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def soft_delete(\\n        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\\n    ) -> bool:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return False\\n        if rec.is_deleted:\\n            return True  # idempotente\\n        if expected_version is not None and rec.version != expected_version:\\n            return False\\n        now = datetime.now(timezone.utc)\\n        rec.is_deleted = True\\n        rec.deleted_at = now\\n        rec.deleted_reason = reason\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return True\\n\\n    async def restore(\\n        self, product_id: UUID, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if expected_version is not None and rec.version != expected_version:\\n            return None\\n        if not rec.is_deleted:\\n            return None\\n        now = datetime.now(timezone.utc)\\n        rec.is_deleted = False\\n        rec.deleted_at = None\\n        rec.deleted_reason = None\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def hard_delete(self, product_id: UUID) -> bool:\\n        return self._items.pop(product_id, None) is not None\\n\\n\\n@pytest.fixture()\\ndef repo() -> InMemoryProductRepo:\\n    return InMemoryProductRepo()\\n\\n\\n@pytest.fixture()\\ndef app(repo: InMemoryProductRepo) -> FastAPI:\\n    app = FastAPI()\\n    app.include_router(router)\\n\\n    async def override_repo():\\n        return repo\\n\\n    app.dependency_overrides[get_repository] = override_repo\\n    return app\\n\\n\\n@pytest.fixture()\\ndef client(app: FastAPI) -> TestClient:\\n    return TestClient(app)\\n\\n\\n@pytest.fixture()\\ndef admin_headers():\\n    # Usa autenticación debug integrada en el router\\n    return {\"X-Debug-User\": \"admin\"}\\n\\n\\n@pytest.fixture()\\ndef reader_headers():\\n    return {\"X-Debug-User\": \"reader\"}\\n\\n\\nasync def _create_product_async(client: TestClient, headers, payload: dict) -> dict:\\n    res = client.post(\"/products\", json=payload, headers=headers)\\n    assert res.status_code == 201, res.text\\n    return res.json()\\n\\n\\n@pytest.fixture()\\ndef sample_payload():\\n    return {\"name\": \"Camiseta Básica\", \"price\": 19.99, \"category\": \"Ropa\", \"stock\": 150}\\n\\n\\n@pytest.fixture()\\ndef another_payload():\\n    return {\"name\": \"Laptop Pro 14”\", \"price\": \"1499.00\", \"category\": \"Electrónica\", \"stock\": 25}\\n\\n\\n@pytest.fixture()\\ndef many_products(client: TestClient, admin_headers):\\n    # Crea un conjunto de productos para pruebas de lista/paginación/filtrado\\n    items = []\\n    for i in range(35):\\n        payload = {\\n            \"name\": f\"Item {i}\",\\n            \"price\": float(10 + i),\\n            \"category\": \"CatA\" if i % 2 == 0 else \"CatB\",\\n            \"stock\": i * 3,\\n        }\\n        res = client.post(\"/products\", json=payload, headers=admin_headers)\\n        assert res.status_code == 201, res.text\\n        items.append(res.json())\\n    return items\\n```\\n\\ntests/test_products_unit.py\\n```python\\nfrom time import sleep\\n\\nimport pytest\\n\\n\\ndef test_create_product(client, admin_headers, sample_payload):\\n    res = client.post(\"/products\", json=sample_payload, headers=admin_headers)\\n    assert res.status_code == 201, res.text\\n    body = res.json()\\n    assert body[\"id\"]\\n    assert body[\"name\"] == \"Camiseta Básica\"\\n    assert body[\"price\"] == 19.99\\n    assert body[\"version\"] == 1\\n    assert \"etag\" in res.headers\\n    assert res.headers[\"Cache-Control\"] == \"no-cache\"\\n    assert res.headers[\"Location\"].endswith(f\\'/products/{body[\"id\"]}\\')\\n\\n\\ndef test_get_product_by_id_and_etag_304(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    # GET normal\\n    res = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res.status_code == 200\\n    etag = res.headers.get(\"ETag\")\\n    assert etag\\n\\n    # GET con If-None-Match -> 304\\n    res2 = client.get(f\"/products/{pid}\", headers={**admin_headers, \"If-None-Match\": etag})\\n    assert res2.status_code == 304\\n    assert res2.headers.get(\"ETag\") == etag\\n\\n\\ndef test_list_products_pagination_filter_sort_and_etag(client, admin_headers, many_products):\\n    # Página 1\\n    res = client.get(\"/products?page=1&size=20&sort=-created_at\", headers=admin_headers)\\n    assert res.status_code == 200\\n    etag1 = res.headers.get(\"ETag\")\\n    assert etag1\\n    assert res.headers.get(\"X-Total-Count\") == \"35\"\\n    assert \\'rel=\"next\"\\' in res.headers.get(\"Link\", \"\")\\n    body = res.json()\\n    assert body[\"page\"] == 1 and body[\"size\"] == 20 and body[\"total\"] == 35 and body[\"pages\"] == 2\\n    assert len(body[\"items\"]) == 20\\n\\n    # If-None-Match -> 304\\n    res_304 = client.get(\\n        \"/products?page=1&size=20&sort=-created_at\",\\n        headers={**admin_headers, \"If-None-Match\": etag1},\\n    )\\n    assert res_304.status_code == 304\\n\\n    # Filtro por categoría y rango de precio\\n    res2 = client.get(\"/products?category=CatA&price_min=20&price_max=30\", headers=admin_headers)\\n    assert res2.status_code == 200\\n    items = res2.json()[\"items\"]\\n    assert all(it[\"category\"] == \"CatA\" for it in items)\\n    assert all(20 <= float(it[\"price\"]) <= 30 for it in items)\\n\\n    # Ordenamiento y validación de sort inválido\\n    res3 = client.get(\"/products?sort=+name,-price\", headers=admin_headers)\\n    assert res3.status_code == 200\\n    res_bad = client.get(\"/products?sort=-invalid_field\", headers=admin_headers)\\n    assert res_bad.status_code == 400\\n    assert res_bad.json()[\"detail\"][\"code\"] == \"invalid_sort\"\\n\\n\\ndef test_patch_requires_if_match_and_version(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    # Missing If-Match -> 428\\n    res = client.patch(f\"/products/{pid}\", json={\"price\": 17.49, \"version\": 1}, headers=admin_headers)\\n    assert res.status_code == 428\\n\\n    # Get current ETag\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    etag = res_get.headers[\"ETag\"]\\n\\n    # Version conflict -> 409\\n    res_conflict = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"price\": 17.49, \"version\": 999},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_conflict.status_code == 409\\n    assert res_conflict.json()[\"detail\"][\"code\"] in (\"version_conflict\", \"conflict\")\\n\\n    # Correct patch\\n    res_ok = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"price\": 17.49, \"version\": created[\"version\"]},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_ok.status_code == 200\\n    assert float(res_ok.json()[\"price\"]) == 17.49\\n    assert res_ok.headers[\"ETag\"] != etag  # ETag cambió\\n\\n\\ndef test_put_requires_if_match_and_replaces(client, admin_headers, sample_payload, another_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n\\n    # Missing If-Match -> 428\\n    res_428 = client.put(f\"/products/{pid}\", json=another_payload, headers=admin_headers)\\n    assert res_428.status_code == 428\\n\\n    # Wrong If-Match -> 412\\n    res_412 = client.put(\\n        f\"/products/{pid}\", json=another_payload, headers={**admin_headers, \"If-Match\": \\'W/\"wrong\"\\'}\\n    )\\n    assert res_412.status_code == 412\\n\\n    # Correct replace\\n    res_ok = client.put(\\n        f\"/products/{pid}\", json=another_payload, headers={**admin_headers, \"If-Match\": etag}\\n    )\\n    assert res_ok.status_code == 200\\n    body = res_ok.json()\\n    assert body[\"name\"] == another_payload[\"name\"]\\n    assert float(body[\"price\"]) == float(another_payload[\"price\"])\\n\\n\\ndef test_delete_soft_and_restore_flow(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n\\n    # Soft delete requires If-Match\\n    res_428 = client.delete(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_428.status_code == 428\\n\\n    # Wrong ETag -> 412\\n    res_412 = client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": \\'W/\"bad\"\\'})\\n    assert res_412.status_code == 412\\n\\n    # Correct soft delete\\n    res_del = client.delete(\\n        f\"/products/{pid}?reason=sin stock\", headers={**admin_headers, \"If-Match\": etag}\\n    )\\n    assert res_del.status_code == 204\\n\\n    # Get sin include_deleted -> 404\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_get.status_code == 404\\n\\n    # Get con include_deleted -> 200 y is_deleted True\\n    res_get2 = client.get(f\"/products/{pid}?include_deleted=true\", headers=admin_headers)\\n    assert res_get2.status_code == 200\\n    assert res_get2.json()[\"is_deleted\"] is True\\n    etag_deleted = res_get2.headers[\"ETag\"]\\n\\n    # Restore requires If-Match\\n    res_r_428 = client.post(f\"/products/{pid}/restore\", headers=admin_headers)\\n    assert res_r_428.status_code == 428\\n\\n    # Restore ok\\n    res_restore = client.post(\\n        f\"/products/{pid}/restore\", headers={**admin_headers, \"If-Match\": etag_deleted}\\n    )\\n    assert res_restore.status_code == 200\\n    assert res_restore.json()[\"is_deleted\"] is False\\n\\n\\ndef test_hard_delete(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    res_hd = client.delete(f\"/products/{pid}/hard\", headers=admin_headers)\\n    assert res_hd.status_code == 204\\n\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_get.status_code == 404\\n\\n\\ndef test_list_collection_etag_changes_on_update(client, admin_headers, many_products):\\n    res1 = client.get(\"/products?page=1&size=10\", headers=admin_headers)\\n    assert res1.status_code == 200\\n    etag1 = res1.headers[\"ETag\"]\\n    first_id = res1.json()[\"items\"][0][\"id\"]\\n\\n    etag_item = client.get(f\"/products/{first_id}\", headers=admin_headers).headers[\"ETag\"]\\n    # PATCH cambia version_sum y max_updated_at de la página\\n    res_patch = client.patch(\\n        f\"/products/{first_id}\",\\n        json={\"stock\": 999, \"version\": 1},\\n        headers={**admin_headers, \"If-Match\": etag_item},\\n    )\\n    assert res_patch.status_code == 200\\n\\n    res2 = client.get(\"/products?page=1&size=10\", headers=admin_headers)\\n    assert res2.status_code == 200\\n    etag2 = res2.headers[\"ETag\"]\\n    assert etag1 != etag2\\n\\n\\ndef test_validation_errors_422(client, admin_headers):\\n    # price inválido\\n    bad_payload = {\"name\": \"X\", \"price\": \"abc\", \"category\": \"C\", \"stock\": 1}\\n    res = client.post(\"/products\", json=bad_payload, headers=admin_headers)\\n    assert res.status_code == 422\\n\\n    # name con control chars\\n    bad_payload2 = {\"name\": \"Bad\\\\x07Name\", \"price\": 10, \"category\": \"C\", \"stock\": 1}\\n    res2 = client.post(\"/products\", json=bad_payload2, headers=admin_headers)\\n    assert res2.status_code == 422\\n\\n    # PATCH sin campos de negocio\\n    res3 = client.post(\"/products\", json={\"name\": \"Ok\", \"price\": 1, \"category\": \"C\", \"stock\": 1}, headers=admin_headers)\\n    pid = res3.json()[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n    bad_patch = {\"version\": 1}\\n    res4 = client.patch(f\"/products/{pid}\", json=bad_patch, headers={**admin_headers, \"If-Match\": etag})\\n    assert res4.status_code == 422\\n```\\n\\ntests/test_products_integration.py\\n```python\\ndef test_e2e_flow_crud_soft_restore_hard(client, admin_headers):\\n    # Crear\\n    payload = {\"name\": \"Cámara 4K\", \"price\": \"499.90\", \"category\": \"Electrónica\", \"stock\": 10}\\n    res_c = client.post(\"/products\", json=payload, headers=admin_headers)\\n    assert res_c.status_code == 201\\n    p = res_c.json()\\n    pid = p[\"id\"]\\n\\n    # Listar y verificar aparece\\n    res_l = client.get(\"/products\", headers=admin_headers)\\n    assert res_l.status_code == 200\\n    assert any(it[\"id\"] == pid for it in res_l.json()[\"items\"])\\n\\n    # Obtener y cache 304\\n    res_g = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_g.status_code == 200\\n    etag = res_g.headers[\"ETag\"]\\n    res_304 = client.get(f\"/products/{pid}\", headers={**admin_headers, \"If-None-Match\": etag})\\n    assert res_304.status_code == 304\\n\\n    # PATCH stock\\n    res_p = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"stock\": 15, \"version\": 1},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_p.status_code == 200\\n    etag2 = res_p.headers[\"ETag\"]\\n\\n    # PUT reemplazo total\\n    new_payload = {\"name\": \"Cámara Pro\", \"price\": 599.99, \"category\": \"Electrónica\", \"stock\": 5}\\n    res_put = client.put(\\n        f\"/products/{pid}\",\\n        json=new_payload,\\n        headers={**admin_headers, \"If-Match\": etag2},\\n    )\\n    assert res_put.status_code == 200\\n    etag3 = res_put.headers[\"ETag\"]\\n\\n    # Soft delete\\n    res_d = client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": etag3})\\n    assert res_d.status_code == 204\\n\\n    # Restore\\n    etag_del = client.get(f\"/products/{pid}?include_deleted=true\", headers=admin_headers).headers[\"ETag\"]\\n    res_r = client.post(f\"/products/{pid}/restore\", headers={**admin_headers, \"If-Match\": etag_del})\\n    assert res_r.status_code == 200\\n\\n    # Hard delete\\n    res_hd = client.delete(f\"/products/{pid}/hard\", headers=admin_headers)\\n    assert res_hd.status_code == 204\\n\\n    # Get -> 404\\n    res_g2 = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_g2.status_code == 404\\n```\\n\\ntests/test_products_security.py\\n```python\\ndef test_auth_required(client):\\n    # Sin header -> 401\\n    res = client.get(\"/products\")\\n    assert res.status_code == 401\\n    assert res.json()[\"detail\"][\"code\"] == \"auth_required\"\\n\\n\\ndef test_reader_can_read_but_not_write(client, reader_headers):\\n    # List -> 200\\n    res = client.get(\"/products\", headers=reader_headers)\\n    assert res.status_code == 200\\n\\n    # POST -> 403\\n    payload = {\"name\": \"ReadOnly\", \"price\": 1, \"category\": \"X\", \"stock\": 0}\\n    res_post = client.post(\"/products\", json=payload, headers=reader_headers)\\n    assert res_post.status_code == 403\\n    assert res_post.json()[\"detail\"][\"code\"] == \"insufficient_permissions\"\\n\\n\\ndef test_include_deleted_requires_scope(client, admin_headers, reader_headers):\\n    # Crear y eliminar con admin\\n    p = client.post(\\n        \"/products\", json={\"name\": \"Del\", \"price\": 1, \"category\": \"X\", \"stock\": 0}, headers=admin_headers\\n    ).json()\\n    pid = p[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n    client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": etag})\\n\\n    # Reader intenta include_deleted -> 403\\n    res = client.get(f\"/products/{pid}?include_deleted=true\", headers=reader_headers)\\n    assert res.status_code == 403\\n    assert res.json()[\"detail\"][\"code\"] == \"insufficient_permissions\"\\n```\\n\\ntests/test_products_performance.py\\n```python\\nimport time\\n\\n\\ndef test_basic_performance_get_list(client, admin_headers, many_products):\\n    # Warm-up\\n    client.get(\"/products\", headers=admin_headers)\\n\\n    start = time.perf_counter()\\n    N = 50\\n    for _ in range(N):\\n        res = client.get(\"/products?page=1&size=20&sort=-created_at\", headers=admin_headers)\\n        assert res.status_code == 200\\n    elapsed = time.perf_counter() - start\\n    avg_ms = (elapsed / N) * 1000\\n    # Umbral básico y relajado para CI\\n    assert avg_ms < 50.0, f\"Promedio {avg_ms:.2f}ms demasiado alto\"\\n\\n\\ndef test_basic_performance_get_by_id(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    # Warm-up\\n    client.get(f\"/products/{pid}\", headers=admin_headers)\\n\\n    start = time.perf_counter()\\n    N = 100\\n    for _ in range(N):\\n        res = client.get(f\"/products/{pid}\", headers=admin_headers)\\n        assert res.status_code == 200\\n    elapsed = time.perf_counter() - start\\n    avg_ms = (elapsed / N) * 1000\\n    assert avg_ms < 30.0, f\"Promedio {avg_ms:.2f}ms demasiado alto\"\\n```\\n\\nCobertura esperada y notas:\\n- Estos tests ejercitan:\\n  - Autenticación: 401, 403 y scopes específicos.\\n  - Validaciones de payload: 422, normalización de price/name/category.\\n  - Filtros: search/category/price_min/price_max/stock_min/stock_max.\\n  - Ordenamiento: campos válidos e inválidos (400).\\n  - Paginación: headers X-Total-Count y Link.\\n  - Caching: ETag en recursos y colección; 304 con If-None-Match.\\n  - Concurrencia optimista: If-Match requerido (428), mismatch (412), version_conflict (409).\\n  - Soft delete/restore/hard delete y estados 404/409 correspondientes.\\n  - Performance básica con umbrales relajados.\\n\\nConsejos:\\n- Ajusta los imports a tu módulo real.\\n- Si cambias el cálculo de ETag de colección o los headers, actualiza las aserciones.\\n- Ejecuta con cobertura: pytest --cov=. --cov-report=term-missing y apunta a ≥90%. Si alguno de tus handlers personalizados de errores modifica códigos/formatos, adapta los asserts.', alembic_migration='\"\"\"\\nAlembic migration: products table + índices y constraints\\n- price: NUMERIC(8,2) [0 .. 999999.99]\\n- validación de soft delete\\n- índices parciales para not deleted\\n- trigram para búsquedas por nombre/categoría (pg_trgm)\\n- trigger updated_at\\n\\nRequiere permisos para CREATE EXTENSION (pgcrypto, pg_trgm). Si tu PG gestionado no lo permite,\\n- quita las líneas CREATE EXTENSION y genera UUID en la app.\\n\"\"\"\\nfrom alembic import op\\nimport sqlalchemy as sa\\nfrom sqlalchemy.dialects import postgresql\\n\\n# Revisiones\\nrevision = \\'d9b8a3e51c1e\\'\\ndown_revision = None\\nbranch_labels = None\\ndepends_on = None\\n\\ndef upgrade() -> None:\\n    # Extensiones necesarias\\n    op.execute(\"CREATE EXTENSION IF NOT EXISTS pgcrypto;\")\\n    op.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm;\")\\n\\n    # Tabla products\\n    op.create_table(\\n        \\'products\\',\\n        sa.Column(\\'id\\', postgresql.UUID(as_uuid=True), primary_key=True, nullable=False, server_default=sa.text(\\'gen_random_uuid()\\')),\\n        sa.Column(\\'name\\', sa.String(length=100), nullable=False),\\n        sa.Column(\\'price\\', sa.Numeric(8, 2), nullable=False),\\n        sa.Column(\\'category\\', sa.Text(), nullable=False),\\n        sa.Column(\\'stock\\', sa.Integer(), nullable=False),\\n        sa.Column(\\'version\\', sa.Integer(), nullable=False, server_default=\\'1\\'),\\n        sa.Column(\\'created_at\\', sa.TIMESTAMP(timezone=True), nullable=False, server_default=sa.text(\"timezone(\\'utc\\', now())\")),\\n        sa.Column(\\'updated_at\\', sa.TIMESTAMP(timezone=True), nullable=False, server_default=sa.text(\"timezone(\\'utc\\', now())\")),\\n        sa.Column(\\'created_by\\', postgresql.UUID(as_uuid=True), nullable=True),\\n        sa.Column(\\'updated_by\\', postgresql.UUID(as_uuid=True), nullable=True),\\n        sa.Column(\\'is_deleted\\', sa.Boolean(), nullable=False, server_default=sa.text(\\'false\\')),\\n        sa.Column(\\'deleted_at\\', sa.TIMESTAMP(timezone=True), nullable=True),\\n        sa.Column(\\'deleted_reason\\', sa.Text(), nullable=True),\\n        sa.CheckConstraint(\"char_length(btrim(name)) >= 1\", name=\"ck_products_name_min_length\"),\\n        sa.CheckConstraint(\"price >= 0::numeric AND price <= 999999.99\", name=\"ck_products_price_range\"),\\n        sa.CheckConstraint(\"char_length(btrim(category)) >= 1\", name=\"ck_products_category_not_empty\"),\\n        sa.CheckConstraint(\"stock >= 0\", name=\"ck_products_stock_non_negative\"),\\n        sa.CheckConstraint(\"version >= 1\", name=\"ck_products_version_min\"),\\n        sa.CheckConstraint(\\n            \"(NOT is_deleted AND deleted_at IS NULL AND deleted_reason IS NULL) OR (is_deleted AND deleted_at IS NOT NULL)\",\\n            name=\"ck_products_soft_delete_consistency\",\\n        ),\\n    )\\n\\n    # Índices BTREE parciales (not deleted)\\n    op.create_index(\\n        \\'ix_products_category_not_deleted\\',\\n        \\'products\\',\\n        [\\'category\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\n        \\'ix_products_updated_at_not_deleted\\',\\n        \\'products\\',\\n        [\\'updated_at\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\n        \\'ix_products_stock_not_deleted\\',\\n        \\'products\\',\\n        [\\'stock\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\'ix_products_version\\', \\'products\\', [\\'version\\'], unique=False)\\n\\n    # Índices GIN con trigram para búsquedas ILIKE por nombre/categoría\\n    op.execute(\"\"\"\\n        CREATE INDEX IF NOT EXISTS ix_products_name_trgm\\n        ON products USING gin (lower(name) gin_trgm_ops);\\n    \"\"\")\\n    op.execute(\"\"\"\\n        CREATE INDEX IF NOT EXISTS ix_products_category_trgm\\n        ON products USING gin (lower(category) gin_trgm_ops);\\n    \"\"\")\\n\\n    # Trigger para mantener updated_at en UTC\\n    op.execute(\\n        \"\"\"\\n        CREATE OR REPLACE FUNCTION set_updated_at()\\n        RETURNS trigger AS $$\\n        BEGIN\\n            NEW.updated_at = timezone(\\'utc\\', now());\\n            RETURN NEW;\\n        END;\\n        $$ LANGUAGE plpgsql;\\n        \"\"\"\\n    )\\n    op.execute(\\n        \"\"\"\\n        CREATE TRIGGER trg_products_set_updated_at\\n        BEFORE UPDATE ON products\\n        FOR EACH ROW\\n        EXECUTE PROCEDURE set_updated_at();\\n        \"\"\"\\n    )\\n\\n\\ndef downgrade() -> None:\\n    op.execute(\"DROP TRIGGER IF EXISTS trg_products_set_updated_at ON products;\")\\n    op.execute(\"DROP FUNCTION IF EXISTS set_updated_at();\")\\n    op.execute(\"DROP INDEX IF EXISTS ix_products_category_trgm;\")\\n    op.execute(\"DROP INDEX IF EXISTS ix_products_name_trgm;\")\\n    op.drop_index(\\'ix_products_version\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_stock_not_deleted\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_updated_at_not_deleted\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_category_not_deleted\\', table_name=\\'products\\')\\n    op.drop_table(\\'products\\')\\n    op.execute(\"DROP EXTENSION IF EXISTS pg_trgm;\")\\n    op.execute(\"DROP EXTENSION IF EXISTS pgcrypto;\")\\n', dockerfile='# syntax=docker/dockerfile:1\\n\\n# Imagen multi-stage optimizada para producción (FastAPI/SQLAlchemy/Alembic)\\nARG PYTHON_VERSION=3.12-slim\\n\\nFROM python:${PYTHON_VERSION} AS builder\\nENV PIP_DISABLE_PIP_VERSION_CHECK=1 \\\\\\n    PIP_NO_CACHE_DIR=1 \\\\\\n    PYTHONDONTWRITEBYTECODE=1\\n\\n# Dependencias de compilación (psycopg/libpq)\\nRUN apt-get update && apt-get install -y --no-install-recommends \\\\\\n    build-essential gcc libpq-dev \\\\\\n  && rm -rf /var/lib/apt/lists/*\\n\\nWORKDIR /app\\n\\n# Copiar requirements (usa requirements.txt o constraints.txt)\\nCOPY requirements.txt /app/requirements.txt\\n\\n# Crear venv y compilar ruedas offline\\nRUN python -m venv /opt/venv \\\\\\n  && . /opt/venv/bin/activate \\\\\\n  && pip install --upgrade pip wheel \\\\\\n  && pip wheel --wheel-dir=/wheels -r /app/requirements.txt\\n\\n\\nFROM python:${PYTHON_VERSION} AS runtime\\nENV PYTHONDONTWRITEBYTECODE=1 \\\\\\n    PYTHONUNBUFFERED=1 \\\\\\n    PIP_DISABLE_PIP_VERSION_CHECK=1 \\\\\\n    PATH=\"/opt/venv/bin:$PATH\" \\\\\\n    TZ=UTC\\n\\n# Dependencias de runtime mínimas\\nRUN apt-get update && apt-get install -y --no-install-recommends \\\\\\n    libpq5 ca-certificates curl \\\\\\n  && rm -rf /var/lib/apt/lists/*\\n\\nWORKDIR /app\\n\\n# Instalar dependencias desde ruedas offline\\nCOPY --from=builder /opt/venv /opt/venv\\nCOPY --from=builder /wheels /wheels\\nCOPY requirements.txt /app/requirements.txt\\nRUN pip install --no-index --find-links=/wheels -r /app/requirements.txt \\\\\\n  && rm -rf /wheels\\n\\n# Copiar código de la aplicación\\nCOPY . /app\\n\\n# Crear usuario no root\\nRUN addgroup --system app && adduser --system --ingroup app app \\\\\\n  && chown -R app:app /app\\nUSER app\\n\\nEXPOSE 8000\\n\\n# Configuración por defecto de Gunicorn\\nENV RUN_DB_MIGRATIONS=false \\\\\\n    GUNICORN_WORKERS=2 \\\\\\n    GUNICORN_THREADS=8 \\\\\\n    GUNICORN_TIMEOUT=60\\n\\n# Entrypoint: opcionalmente ejecuta migraciones Alembic y arranca Gunicorn\\n# Variables esperadas: DATABASE_URL (SQLAlchemy, ej: postgresql+psycopg://user:pass@db:5432/app)\\nCMD [\"/bin/sh\", \"-c\", \"if [ \\\\\"$RUN_DB_MIGRATIONS\\\\\" = \\\\\"true\\\\\" ]; then alembic upgrade head; fi; exec gunicorn -k uvicorn.workers.UvicornWorker -w ${GUNICORN_WORKERS} --threads ${GUNICORN_THREADS} --timeout ${GUNICORN_TIMEOUT} -b 0.0.0.0:8000 app.main:app\"]\\n')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a71709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📊 ANÁLISIS DE COMPONENTES GENERADOS\n",
      "============================================================\n",
      "\n",
      "🔍 MODELO:\n",
      "  • Lines: 387\n",
      "  • Classes: 4\n",
      "  • Validations: 19\n",
      "  • Validators: 0\n",
      "\n",
      "🔍 ROUTER:\n",
      "  • Lines: 838\n",
      "  • Endpoints: 0\n",
      "  • Error Handling: 5\n",
      "  • Documentation: 8\n",
      "\n",
      "🔍 TESTS:\n",
      "  • Lines: 674\n",
      "  • Test Functions: 15\n",
      "  • Assertions: 78\n",
      "  • Fixtures: 8\n"
     ]
    }
   ],
   "source": [
    "# 3. Análisis de los componentes generados\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 ANÁLISIS DE COMPONENTES GENERADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "components_analysis = {\n",
    "    \"modelo\": {\n",
    "        \"lines\": generated_components.modelo_pydantic.count('\\n'),\n",
    "        \"classes\": generated_components.modelo_pydantic.count('class '),\n",
    "        \"validations\": generated_components.modelo_pydantic.count('Field('),\n",
    "        \"validators\": generated_components.modelo_pydantic.count('@validator')\n",
    "    },\n",
    "    \"router\": {\n",
    "        \"lines\": generated_components.router_fastapi.count('\\n'),\n",
    "        \"endpoints\": len([x for x in ['@app.get', '@app.post', '@app.put', '@app.delete'] \n",
    "                        if x in generated_components.router_fastapi]),\n",
    "        \"error_handling\": generated_components.router_fastapi.count('HTTPException'),\n",
    "        \"documentation\": generated_components.router_fastapi.count('summary=')\n",
    "    },\n",
    "    \"tests\": {\n",
    "        \"lines\": generated_components.tests_pytest.count('\\n'),\n",
    "        \"test_functions\": generated_components.tests_pytest.count('def test_'),\n",
    "        \"assertions\": generated_components.tests_pytest.count('assert '),\n",
    "        \"fixtures\": generated_components.tests_pytest.count('@pytest.fixture')\n",
    "    }\n",
    "}\n",
    "\n",
    "for component, analysis in components_analysis.items():\n",
    "    print(f\"\\n🔍 {component.upper()}:\")\n",
    "    for metric, value in analysis.items():\n",
    "        print(f\"  • {metric.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca3ddc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuación tienes un router FastAPI de nivel empresarial para el recurso Product, alineado con tus modelos Pydantic y la configuración (auth_required=true, cache_enabled=true, soft_delete=true). Incluye:\n",
      "\n",
      "- Endpoints CRUD completos (GET list, GET by id, POST, PUT, PATCH, DELETE soft), y extras restore y hard delete.\n",
      "- Paginación, filtrado y ordenamiento.\n",
      "- ETag/If-None-Match/If-Match (caching y concurrencia optimista).\n",
      "- Manejo de errores consistente con payload estructurado.\n",
      "- Validación de permisos y autenticación vía dependencias.\n",
      "- Logging estructurado.\n",
      "- Documentación OpenAPI rica y ejemplos.\n",
      "\n",
      "Copia/pega en tu proyecto y reemplaza la implementación del repositorio por tu capa de datos (SQLAlchemy, etc.).\n",
      "\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "import hashlib\n",
      "import logging\n",
      "from datetime import datetime, timezone\n",
      "from typing import Annotated, Iterable, Optional\n",
      "from uuid import UUID, uuid4\n",
      "\n",
      "from fastapi import (\n",
      "    APIRouter,\n",
      "    Depends,\n",
      "    HTTPException,\n",
      "    Path,\n",
      "    Query,\n",
      "    Body,\n",
      "    Request,\n",
      "    Response,\n",
      "    status,\n",
      ")\n",
      "from pydantic import BaseModel, Field, StrictInt\n",
      "\n",
      "# Importa tus modelos tal cual los definiste\n",
      "# from app.models.product import ProductCreate, ProductUpdate, ProductOut\n",
      "# Para este snippet asumimos que ya están en el scope:\n",
      "# ProductCreate, ProductUpdate, ProductOut\n",
      "\n",
      "# ==============================================================================\n",
      "# Configuración y constantes del recurso\n",
      "# ==============================================================================\n",
      "\n",
      "RESOURCE_NAME = \"product\"\n",
      "ROUTE_PREFIX = \"/products\"\n",
      "TAG = \"Products\"\n",
      "MAX_PAGE_SIZE = 100\n",
      "DEFAULT_PAGE_SIZE = 20\n",
      "DEFAULT_SORT = \"-created_at\"\n",
      "ALLOWED_SORT_FIELDS = {\"name\", \"price\", \"category\", \"stock\", \"created_at\", \"updated_at\"}\n",
      "\n",
      "logger = logging.getLogger(f\"api.{RESOURCE_NAME}\")\n",
      "logger.setLevel(logging.INFO)\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Autenticación y permisos (dependencias)\n",
      "# ==============================================================================\n",
      "\n",
      "class User(BaseModel):\n",
      "    id: UUID\n",
      "    # Scopes de ejemplo:\n",
      "    # - product:read\n",
      "    # - product:read:deleted\n",
      "    # - product:create\n",
      "    # - product:update\n",
      "    # - product:delete\n",
      "    # - product:restore\n",
      "    # - product:hard_delete\n",
      "    scopes: set[str] = Field(default_factory=set)\n",
      "\n",
      "\n",
      "def get_current_user(request: Request) -> User:\n",
      "    \"\"\"\n",
      "    Placeholder de autenticación. En producción integra:\n",
      "    - OAuth2/OIDC (Access Token), o\n",
      "    - JWT firmado, o\n",
      "    - Capa SSO corporativa.\n",
      "    \"\"\"\n",
      "    user: Optional[User] = getattr(request.state, \"user\", None)\n",
      "    if user is None:\n",
      "        # Para entornos de desarrollo, puedes inyectar un usuario por header:\n",
      "        debug_user = request.headers.get(\"X-Debug-User\")\n",
      "        if debug_user == \"admin\":\n",
      "            return User(id=uuid4(), scopes={\n",
      "                \"product:read\", \"product:read:deleted\", \"product:create\",\n",
      "                \"product:update\", \"product:delete\", \"product:restore\",\n",
      "                \"product:hard_delete\",\n",
      "            })\n",
      "        if debug_user == \"reader\":\n",
      "            return User(id=uuid4(), scopes={\"product:read\"})\n",
      "        raise HTTPException(\n",
      "            status_code=status.HTTP_401_UNAUTHORIZED,\n",
      "            detail={\"code\": \"auth_required\", \"message\": \"Autenticación requerida\"},\n",
      "        )\n",
      "    return user\n",
      "\n",
      "\n",
      "def require_scopes(*required_scopes: str):\n",
      "    def _dep(user: User = Depends(get_current_user)) -> User:\n",
      "        missing = [s for s in required_scopes if s not in user.scopes]\n",
      "        if missing:\n",
      "            raise HTTPException(\n",
      "                status_code=status.HTTP_403_FORBIDDEN,\n",
      "                detail={\n",
      "                    \"code\": \"insufficient_permissions\",\n",
      "                    \"message\": \"Permisos insuficientes\",\n",
      "                    \"required\": required_scopes,\n",
      "                },\n",
      "            )\n",
      "        return user\n",
      "    return _dep\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Repositorio/Servicio (interfaz)\n",
      "# ==============================================================================\n",
      "\n",
      "class ProductRecord(BaseModel):\n",
      "    id: UUID\n",
      "    name: str\n",
      "    price: float  # se normaliza a Decimal en los modelos Pydantic de salida\n",
      "    category: str\n",
      "    stock: int\n",
      "    version: StrictInt\n",
      "    created_at: datetime\n",
      "    updated_at: datetime\n",
      "    created_by: Optional[UUID] = None\n",
      "    updated_by: Optional[UUID] = None\n",
      "    is_deleted: bool = False\n",
      "    deleted_at: Optional[datetime] = None\n",
      "    deleted_reason: Optional[str] = None\n",
      "\n",
      "    @property\n",
      "    def etag(self) -> str:\n",
      "        return f'W/\"{RESOURCE_NAME}-{self.id}-v{self.version}\"'\n",
      "\n",
      "\n",
      "class ListResult(BaseModel):\n",
      "    items: list[ProductRecord]\n",
      "    total: int\n",
      "    # Para caching de colección\n",
      "    max_updated_at: Optional[datetime] = None\n",
      "    version_sum: int = 0\n",
      "\n",
      "\n",
      "class ProductRepositoryProtocol:\n",
      "    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord: ...\n",
      "    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]: ...\n",
      "    async def list(\n",
      "        self,\n",
      "        *,\n",
      "        page: int,\n",
      "        size: int,\n",
      "        filters: dict,\n",
      "        sort: list[tuple[str, str]],\n",
      "        include_deleted: bool,\n",
      "    ) -> ListResult: ...\n",
      "    async def replace(\n",
      "        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def patch(\n",
      "        self, product_id: UUID, data: ProductUpdate, by: UUID\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def soft_delete(\n",
      "        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\n",
      "    ) -> bool: ...\n",
      "    async def restore(\n",
      "        self, product_id: UUID, by: UUID, expected_version: Optional[int]\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def hard_delete(self, product_id: UUID) -> bool: ...\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Dependencia del repositorio (inyecta tu implementación real)\n",
      "# ==============================================================================\n",
      "\n",
      "async def get_repository() -> ProductRepositoryProtocol:\n",
      "    \"\"\"\n",
      "    Inyecta aquí tu implementación real (SQLAlchemy/AsyncSession).\n",
      "    Puedes usar un contenedor o wiring con FastAPI.\n",
      "    \"\"\"\n",
      "    raise NotImplementedError(\"Inyecta la implementación concreta del repositorio\")\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Utilidades: ordenamiento, filtros, paginación, ETag de colección\n",
      "# ==============================================================================\n",
      "\n",
      "def parse_sort(sort: Optional[str]) -> list[tuple[str, str]]:\n",
      "    if not sort:\n",
      "        sort = DEFAULT_SORT\n",
      "    tokens = [t.strip() for t in sort.split(\",\") if t.strip()]\n",
      "    out: list[tuple[str, str]] = []\n",
      "    for t in tokens:\n",
      "        direction = \"asc\"\n",
      "        field = t\n",
      "        if t.startswith(\"-\"):\n",
      "            direction = \"desc\"\n",
      "            field = t[1:]\n",
      "        elif t.startswith(\"+\"):\n",
      "            field = t[1:]\n",
      "        if field not in ALLOWED_SORT_FIELDS:\n",
      "            raise HTTPException(\n",
      "                status_code=status.HTTP_400_BAD_REQUEST,\n",
      "                detail={\n",
      "                    \"code\": \"invalid_sort\",\n",
      "                    \"message\": f\"Campo de ordenamiento no permitido: {field}\",\n",
      "                    \"allowed\": sorted(ALLOWED_SORT_FIELDS),\n",
      "                },\n",
      "            )\n",
      "        out.append((field, direction))\n",
      "    return out\n",
      "\n",
      "\n",
      "def collection_etag(result: ListResult, fingerprint: str) -> str:\n",
      "    \"\"\"\n",
      "    ETag débil para la colección:\n",
      "    Hash de total, max_updated_at, version_sum y un fingerprint de parámetros.\n",
      "    \"\"\"\n",
      "    max_ts = (\n",
      "        result.max_updated_at.astimezone(timezone.utc).isoformat()\n",
      "        if result.max_updated_at\n",
      "        else \"none\"\n",
      "    )\n",
      "    payload = f\"{RESOURCE_NAME}:{result.total}:{max_ts}:{result.version_sum}:{fingerprint}\"\n",
      "    h = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:16]\n",
      "    return f'W/\"{RESOURCE_NAME}-collection-{h}\"'\n",
      "\n",
      "\n",
      "def paginated_links(base_path: str, page: int, size: int, total: int, qs: str = \"\") -> str:\n",
      "    pages = (total + size - 1) // size if total > 0 else 1\n",
      "    links: list[str] = []\n",
      "    def url(p: int) -> str:\n",
      "        return f'{base_path}?page={p}&size={size}{qs}'\n",
      "    links.append(f'<{url(1)}>; rel=\"first\"')\n",
      "    links.append(f'<{url(pages)}>; rel=\"last\"')\n",
      "    if page > 1:\n",
      "        links.append(f'<{url(page - 1)}>; rel=\"prev\"')\n",
      "    if page < pages:\n",
      "        links.append(f'<{url(page + 1)}>; rel=\"next\"')\n",
      "    return \", \".join(links)\n",
      "\n",
      "\n",
      "def http_error(status_code: int, code: str, message: str, **extra):\n",
      "    raise HTTPException(status_code=status_code, detail={\"code\": code, \"message\": message, **extra})\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Router\n",
      "# ==============================================================================\n",
      "\n",
      "router = APIRouter(prefix=ROUTE_PREFIX, tags=[TAG])\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# GET /products (listado)\n",
      "# -----------------------------\n",
      "@router.get(\n",
      "    \"\",\n",
      "    summary=\"Listar productos\",\n",
      "    response_model=dict,\n",
      "    responses={\n",
      "        200: {\"description\": \"Listado paginado de productos\"},\n",
      "        304: {\"description\": \"No modificado (ETag coincide)\"},\n",
      "        400: {\"description\": \"Solicitud inválida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "    },\n",
      ")\n",
      "async def list_products(\n",
      "    request: Request,\n",
      "    response: Response,\n",
      "    page: Annotated[int, Query(ge=1)] = 1,\n",
      "    size: Annotated[int, Query(ge=1, le=MAX_PAGE_SIZE)] = DEFAULT_PAGE_SIZE,\n",
      "    search: Annotated[Optional[str], Query(description=\"Búsqueda en nombre/categoría\")] = None,\n",
      "    name: Optional[str] = Query(None, description=\"Filtro exacto por nombre\"),\n",
      "    category: Optional[str] = Query(None, description=\"Filtro exacto por categoría\"),\n",
      "    price_min: Optional[float] = Query(None, ge=0),\n",
      "    price_max: Optional[float] = Query(None, ge=0),\n",
      "    stock_min: Optional[int] = Query(None, ge=0),\n",
      "    stock_max: Optional[int] = Query(None, ge=0),\n",
      "    sort: Optional[str] = Query(DEFAULT_SORT, description=\"Ej: -created_at,+price\"),\n",
      "    include_deleted: bool = Query(False, description=\"Incluir eliminados (requiere permiso)\"),\n",
      "    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:read\")),\n",
      "):\n",
      "    if include_deleted and \"product:read:deleted\" not in user.scopes:\n",
      "        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\n",
      "\n",
      "    order = parse_sort(sort)\n",
      "\n",
      "    filters = {\n",
      "        \"search\": search,\n",
      "        \"name\": name,\n",
      "        \"category\": category,\n",
      "        \"price_min\": price_min,\n",
      "        \"price_max\": price_max,\n",
      "        \"stock_min\": stock_min,\n",
      "        \"stock_max\": stock_max,\n",
      "    }\n",
      "\n",
      "    # Fingerprint de parámetros para el ETag de colección\n",
      "    fp = f\"p={page}|s={size}|sort={order}|incdel={include_deleted}|f={filters}\"\n",
      "\n",
      "    result = await repo.list(\n",
      "        page=page,\n",
      "        size=size,\n",
      "        filters=filters,\n",
      "        sort=order,\n",
      "        include_deleted=include_deleted,\n",
      "    )\n",
      "\n",
      "    etag = collection_etag(result, fp)\n",
      "    if if_none_match and if_none_match.strip() == etag:\n",
      "        response.headers[\"ETag\"] = etag\n",
      "        response.status_code = status.HTTP_304_NOT_MODIFIED\n",
      "        return\n",
      "\n",
      "    # Paginated response envelope\n",
      "    items_out = [\n",
      "        ProductOut(\n",
      "            id=it.id,\n",
      "            name=it.name,\n",
      "            price=it.price,\n",
      "            category=it.category,\n",
      "            stock=it.stock,\n",
      "            version=it.version,\n",
      "            etag=it.etag,\n",
      "            created_at=it.created_at,\n",
      "            updated_at=it.updated_at,\n",
      "            created_by=it.created_by,\n",
      "            updated_by=it.updated_by,\n",
      "            is_deleted=it.is_deleted,\n",
      "            deleted_at=it.deleted_at,\n",
      "            deleted_reason=it.deleted_reason,\n",
      "        )\n",
      "        for it in result.items\n",
      "    ]\n",
      "\n",
      "    response.headers[\"X-Total-Count\"] = str(result.total)\n",
      "    # Link header con navegación\n",
      "    # Conserva query string de filtros\n",
      "    raw_qs = \"\"\n",
      "    qparts = []\n",
      "    if search is not None:\n",
      "        qparts.append(f\"&search={search}\")\n",
      "    if name is not None:\n",
      "        qparts.append(f\"&name={name}\")\n",
      "    if category is not None:\n",
      "        qparts.append(f\"&category={category}\")\n",
      "    if price_min is not None:\n",
      "        qparts.append(f\"&price_min={price_min}\")\n",
      "    if price_max is not None:\n",
      "        qparts.append(f\"&price_max={price_max}\")\n",
      "    if stock_min is not None:\n",
      "        qparts.append(f\"&stock_min={stock_min}\")\n",
      "    if stock_max is not None:\n",
      "        qparts.append(f\"&stock_max={stock_max}\")\n",
      "    if sort is not None:\n",
      "        qparts.append(f\"&sort={sort}\")\n",
      "    if include_deleted:\n",
      "        qparts.append(f\"&include_deleted=true\")\n",
      "    raw_qs = \"\".join(qparts)\n",
      "    response.headers[\"Link\"] = paginated_links(ROUTE_PREFIX, page, size, result.total, raw_qs)\n",
      "    response.headers[\"ETag\"] = etag\n",
      "    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_list\",\n",
      "        extra={\n",
      "            \"event\": \"product_list\",\n",
      "            \"user_id\": str(user.id),\n",
      "            \"page\": page,\n",
      "            \"size\": size,\n",
      "            \"total\": result.total,\n",
      "            \"filters\": filters,\n",
      "            \"sort\": order,\n",
      "        },\n",
      "    )\n",
      "\n",
      "    pages = (result.total + size - 1) // size if result.total > 0 else 1\n",
      "    return {\n",
      "        \"items\": items_out,\n",
      "        \"page\": page,\n",
      "        \"size\": size,\n",
      "        \"total\": result.total,\n",
      "        \"pages\": pages,\n",
      "    }\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# GET /products/{id}\n",
      "# -----------------------------\n",
      "from fastapi import Header  # placed here to avoid confusion in snippet scope\n",
      "\n",
      "@router.get(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Obtener producto por ID\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Producto encontrado\"},\n",
      "        304: {\"description\": \"No modificado (ETag coincide)\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "    },\n",
      ")\n",
      "async def get_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    include_deleted: bool = Query(False, description=\"Incluir eliminado\"),\n",
      "    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:read\")),\n",
      "):\n",
      "    if include_deleted and \"product:read:deleted\" not in user.scopes:\n",
      "        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\n",
      "\n",
      "    record = await repo.get(product_id, include_deleted=include_deleted)\n",
      "    if not record or (record.is_deleted and not include_deleted):\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    if if_none_match and if_none_match.strip() == record.etag:\n",
      "        response.headers[\"ETag\"] = record.etag\n",
      "        response.status_code = status.HTTP_304_NOT_MODIFIED\n",
      "        return\n",
      "\n",
      "    response.headers[\"ETag\"] = record.etag\n",
      "    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\n",
      "\n",
      "    return ProductOut(\n",
      "        id=record.id,\n",
      "        name=record.name,\n",
      "        price=record.price,\n",
      "        category=record.category,\n",
      "        stock=record.stock,\n",
      "        version=record.version,\n",
      "        etag=record.etag,\n",
      "        created_at=record.created_at,\n",
      "        updated_at=record.updated_at,\n",
      "        created_by=record.created_by,\n",
      "        updated_by=record.updated_by,\n",
      "        is_deleted=record.is_deleted,\n",
      "        deleted_at=record.deleted_at,\n",
      "        deleted_reason=record.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# POST /products (crear)\n",
      "# -----------------------------\n",
      "@router.post(\n",
      "    \"\",\n",
      "    summary=\"Crear producto\",\n",
      "    status_code=status.HTTP_201_CREATED,\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        201: {\"description\": \"Creado\"},\n",
      "        400: {\"description\": \"Solicitud inválida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        409: {\"description\": \"Conflicto\"},\n",
      "    },\n",
      ")\n",
      "async def create_product(\n",
      "    response: Response,\n",
      "    payload: ProductCreate = Body(...),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:create\")),\n",
      "):\n",
      "    created = await repo.create(payload, by=user.id)\n",
      "\n",
      "    response.headers[\"Location\"] = f\"{ROUTE_PREFIX}/{created.id}\"\n",
      "    response.headers[\"ETag\"] = created.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_created\",\n",
      "        extra={\"event\": \"product_created\", \"user_id\": str(user.id), \"product_id\": str(created.id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=created.id,\n",
      "        name=created.name,\n",
      "        price=created.price,\n",
      "        category=created.category,\n",
      "        stock=created.stock,\n",
      "        version=created.version,\n",
      "        etag=created.etag,\n",
      "        created_at=created.created_at,\n",
      "        updated_at=created.updated_at,\n",
      "        created_by=created.created_by,\n",
      "        updated_by=created.updated_by,\n",
      "        is_deleted=created.is_deleted,\n",
      "        deleted_at=created.deleted_at,\n",
      "        deleted_reason=created.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# PUT /products/{id} (reemplazo total)\n",
      "# Requiere If-Match con el ETag actual para concurrencia.\n",
      "# -----------------------------\n",
      "@router.put(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Reemplazar producto (PUT)\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Actualizado\"},\n",
      "        400: {\"description\": \"Solicitud inválida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def replace_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    payload: ProductCreate = Body(...),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:update\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PUT\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto está eliminado lógicamente\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    updated = await repo.replace(product_id, payload, by=user.id, expected_version=current.version)\n",
      "\n",
      "    if not updated:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible reemplazar el recurso (conflicto de versión)\")\n",
      "\n",
      "    response.headers[\"ETag\"] = updated.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_replaced\",\n",
      "        extra={\"event\": \"product_replaced\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=updated.id,\n",
      "        name=updated.name,\n",
      "        price=updated.price,\n",
      "        category=updated.category,\n",
      "        stock=updated.stock,\n",
      "        version=updated.version,\n",
      "        etag=updated.etag,\n",
      "        created_at=updated.created_at,\n",
      "        updated_at=updated.updated_at,\n",
      "        created_by=updated.created_by,\n",
      "        updated_by=updated.updated_by,\n",
      "        is_deleted=updated.is_deleted,\n",
      "        deleted_at=updated.deleted_at,\n",
      "        deleted_reason=updated.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# PATCH /products/{id} (parcial)\n",
      "# Requiere version en payload y If-Match en header.\n",
      "# -----------------------------\n",
      "@router.patch(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Actualizar parcialmente producto (PATCH)\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Actualizado\"},\n",
      "        400: {\"description\": \"Solicitud inválida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        409: {\"description\": \"Conflicto de versión\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def patch_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    payload: ProductUpdate = Body(...),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:update\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PATCH\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto está eliminado lógicamente\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    # Validación adicional de versión (optimista)\n",
      "    if payload.version != current.version:\n",
      "        http_error(\n",
      "            status.HTTP_409_CONFLICT,\n",
      "            \"version_conflict\",\n",
      "            f\"Versión desactualizada. Actual: {current.version}, recibida: {payload.version}\",\n",
      "        )\n",
      "\n",
      "    updated = await repo.patch(product_id, payload, by=user.id)\n",
      "    if not updated:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible actualizar el recurso\")\n",
      "\n",
      "    response.headers[\"ETag\"] = updated.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_patched\",\n",
      "        extra={\"event\": \"product_patched\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=updated.id,\n",
      "        name=updated.name,\n",
      "        price=updated.price,\n",
      "        category=updated.category,\n",
      "        stock=updated.stock,\n",
      "        version=updated.version,\n",
      "        etag=updated.etag,\n",
      "        created_at=updated.created_at,\n",
      "        updated_at=updated.updated_at,\n",
      "        created_by=updated.created_by,\n",
      "        updated_by=updated.updated_by,\n",
      "        is_deleted=updated.is_deleted,\n",
      "        deleted_at=updated.deleted_at,\n",
      "        deleted_reason=updated.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# DELETE /products/{id} (soft delete)\n",
      "# -----------------------------\n",
      "@router.delete(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Eliminar producto (soft delete)\",\n",
      "    status_code=status.HTTP_204_NO_CONTENT,\n",
      "    responses={\n",
      "        204: {\"description\": \"Eliminado lógicamente\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def delete_product(\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    reason: Optional[str] = Query(None, description=\"Motivo de eliminación\"),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:delete\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para DELETE\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    ok = await repo.soft_delete(product_id, by=user.id, reason=reason, expected_version=current.version)\n",
      "    if not ok:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible eliminar el recurso (conflicto de versión)\")\n",
      "\n",
      "    logger.info(\n",
      "        \"product_soft_deleted\",\n",
      "        extra={\"event\": \"product_soft_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id), \"reason\": reason},\n",
      "    )\n",
      "    return Response(status_code=status.HTTP_204_NO_CONTENT)\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# POST /products/{id}/restore (restaurar soft delete)\n",
      "# -----------------------------\n",
      "@router.post(\n",
      "    \"/{product_id}/restore\",\n",
      "    summary=\"Restaurar producto eliminado\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Restaurado\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        409: {\"description\": \"Conflicto\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def restore_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:restore\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para restaurar\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if not current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"not_deleted\", \"El producto no está eliminado\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    restored = await repo.restore(product_id, by=user.id, expected_version=current.version)\n",
      "    if not restored:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible restaurar el recurso\")\n",
      "\n",
      "    response.headers[\"ETag\"] = restored.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_restored\",\n",
      "        extra={\"event\": \"product_restored\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=restored.id,\n",
      "        name=restored.name,\n",
      "        price=restored.price,\n",
      "        category=restored.category,\n",
      "        stock=restored.stock,\n",
      "        version=restored.version,\n",
      "        etag=restored.etag,\n",
      "        created_at=restored.created_at,\n",
      "        updated_at=restored.updated_at,\n",
      "        created_by=restored.created_by,\n",
      "        updated_by=restored.updated_by,\n",
      "        is_deleted=restored.is_deleted,\n",
      "        deleted_at=restored.deleted_at,\n",
      "        deleted_reason=restored.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# DELETE /products/{id}/hard (eliminación definitiva)\n",
      "# -----------------------------\n",
      "@router.delete(\n",
      "    \"/{product_id}/hard\",\n",
      "    summary=\"[ADMIN] Eliminación definitiva (hard delete)\",\n",
      "    status_code=status.HTTP_204_NO_CONTENT,\n",
      "    responses={\n",
      "        204: {\"description\": \"Eliminado definitivamente\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "    },\n",
      ")\n",
      "async def hard_delete_product(\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:hard_delete\")),\n",
      "):\n",
      "    ok = await repo.hard_delete(product_id)\n",
      "    if not ok:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    logger.warning(\n",
      "        \"product_hard_deleted\",\n",
      "        extra={\"event\": \"product_hard_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "    return Response(status_code=status.HTTP_204_NO_CONTENT)\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Notas para la implementación del repositorio\n",
      "# ==============================================================================\n",
      "\n",
      "# - create:\n",
      "#   - version = 1\n",
      "#   - created_at = updated_at = datetime.now(timezone.utc)\n",
      "#   - created_by = updated_by = user_id\n",
      "#   - is_deleted = False\n",
      "# - replace:\n",
      "#   - Validar expected_version (si no coincide => conflicto)\n",
      "#   - Actualizar todos los campos de negocio; version += 1; updated_at = now; updated_by = user_id\n",
      "# - patch:\n",
      "#   - Validar que el recurso no esté eliminado\n",
      "#   - Validar que payload.version coincida con current.version\n",
      "#   - Aplicar cambios parciales; version += 1; updated_at = now; updated_by\n",
      "# - soft_delete:\n",
      "#   - Validar expected_version\n",
      "#   - Si ya is_deleted == True => idempotente (retornar True)\n",
      "#   - Marcar is_deleted=True, deleted_at=now, deleted_reason=reason, version += 1\n",
      "# - restore:\n",
      "#   - Validar expected_version\n",
      "#   - Si no is_deleted => conflicto\n",
      "#   - Revertir is_deleted, limpiar deleted_at/reason, version += 1\n",
      "# - list:\n",
      "#   - Aplicar filtros:\n",
      "#       - search: LIKE sobre name/category\n",
      "#       - price_min/max, stock_min/max\n",
      "#   - Excluir eliminados por defecto; incluir si include_deleted=True\n",
      "#   - Ordenamiento múltiple\n",
      "#   - Retornar total, items page/size\n",
      "#   - max_updated_at = MAX(updated_at) del result set\n",
      "#   - version_sum = SUM(version) del result set (para ETag colección)\n",
      "# - get:\n",
      "#   - Permitir include_deleted=True para operaciones administrativas\n",
      "\n",
      "# ==============================================================================\n",
      "# Fin del router\n",
      "# ==============================================================================\n",
      "\n",
      "Explicación breve de concurrencia y cache:\n",
      "- GET con If-None-Match: si el ETag coincide con el estado actual, se retorna 304 sin cuerpo.\n",
      "- PUT/PATCH/DELETE/RESTORE requieren If-Match. Si no coincide, 412 Precondition Failed.\n",
      "- PATCH también requiere version en el cuerpo (control optimista adicional).\n",
      "- ETag por recurso: W/\"product-<id>-v<version>\" (coincide con tu ProductOut).\n",
      "- ETag de colección: hash débil del total, max_updated_at, suma de versiones y fingerprint de parámetros.\n",
      "\n",
      "Seguridad y permisos:\n",
      "- require_scopes valida permisos granulares.\n",
      "- Ajusta los scopes según tu modelo de seguridad real.\n",
      "\n",
      "Logging:\n",
      "- Eventos clave con logger.info/logger.warning y campos estructurados en extra. Integra con tu stack (ELK/Datadog).\n",
      "\n",
      "Documentación:\n",
      "- Los endpoints incluyen summaries, responses y modelos. Puedes extender con OpenAPI callbacks o ejemplos adicionales si lo requieres.\n"
     ]
    }
   ],
   "source": [
    "print(generated_components.router_fastapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d511b7e",
   "metadata": {},
   "source": [
    "### 4.6 Persistencia de Artefactos\n",
    "Escribe a carpeta `generated_product_api/` solo archivos con contenido.\n",
    "- `models.py`\n",
    "- `routes.py`\n",
    "- `test_api.py`\n",
    "- `Dockerfile`\n",
    "- `migration.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50765fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Archivos generados en: generated_product_api\n",
      "📁 Total archivos: 5\n"
     ]
    }
   ],
   "source": [
    "# 4. Guardar componentes generados\n",
    "output_dir = Path(f\"generated_{sample_config.resource_name}_api\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "files_created = {\n",
    "    \"models.py\": generated_components.modelo_pydantic,\n",
    "    \"routes.py\": generated_components.router_fastapi,\n",
    "    \"test_api.py\": generated_components.tests_pytest,\n",
    "    \"Dockerfile\": generated_components.dockerfile,\n",
    "    \"migration.py\": generated_components.alembic_migration\n",
    "}\n",
    "\n",
    "for filename, content in files_created.items():\n",
    "    if content.strip():  # Solo crear archivos con contenido\n",
    "        file_path = output_dir / filename\n",
    "        file_path.write_text(content)\n",
    "\n",
    "print(f\"\\n💾 Archivos generados en: {output_dir}\")\n",
    "print(f\"📁 Total archivos: {len([f for f in files_created.values() if f.strip()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f013136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9733348",
   "metadata": {},
   "source": [
    "Si venías de:\n",
    "- Prompt Engineering básico → ahora formalizas prompts como componentes reutilizables.\n",
    "- FastAPI manual → ahora generas scaffolding consistente.\n",
    "- DevOps / Infra → introduces IaC-like patterns para artefactos de backend.\n",
    "\n",
    "Idea principal para recordar: **\"Estandariza y paraleliza lo generable; reserva tu tiempo humano para lo verdaderamente diferencial.\"**\n",
    "\n",
    "Checklist mental (READY):\n",
    "- ¿Tengo config declarativa? ✅\n",
    "- ¿Prompts con criterios explícitos? ✅\n",
    "- ¿Control de dependencias y orden? ✅\n",
    "- ¿Métricas de eficiencia? ✅\n",
    "- ¿Artefactos persistidos y reutilizables? ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f2d5f",
   "metadata": {},
   "source": [
    "Si venías de:\n",
    "- Prompt Engineering básico → ahora formalizas prompts como componentes reutilizables.\n",
    "- FastAPI manual → ahora generas scaffolding consistente.\n",
    "- DevOps / Infra → introduces IaC-like patterns para artefactos de backend.\n",
    "\n",
    "Idea principal para recordar: **\"Estandariza y paraleliza lo generable; reserva tu tiempo humano para lo verdaderamente diferencial.\"**\n",
    "\n",
    "Checklist mental (READY):\n",
    "- ¿Tengo config declarativa? ✅\n",
    "- ¿Prompts con criterios explícitos? ✅\n",
    "- ¿Control de dependencias y orden? ✅\n",
    "- ¿Métricas de eficiencia? ✅\n",
    "- ¿Artefactos persistidos y reutilizables? ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891ae20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d76946",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce640bde",
   "metadata": {},
   "source": [
    "## Parte 1: Pipeline de Refactoring Inteligente\n",
    "\n",
    "Implementaremos un sistema que analiza código existente y propone mejoras automáticas basadas en métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a89ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# PIPELINE DE REFACTORING INTELIGENTE\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c15b57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefactoringAnalysis(BaseModel):\n",
    "    \"\"\"Análisis integral para refactoring\"\"\"\n",
    "    code_issues: List[str] = Field(description=\"Lista de problemas detectados en el código\")\n",
    "    refactoring_priority: str = Field(description=\"Alta/Media/Baja prioridad de refactoring\")\n",
    "    improvement_suggestions: List[str] = Field(description=\"Sugerencias específicas de mejora\")\n",
    "    estimated_effort: str = Field(description=\"Estimación de esfuerzo: Bajo/Medio/Alto\")\n",
    "    maintainability_score: int = Field(description=\"Puntuación de mantenibilidad (1-10)\")\n",
    "\n",
    "class RefactoredCode(BaseModel):\n",
    "    \"\"\"Código refactorizado con mejoras\"\"\"\n",
    "    improved_code: str = Field(description=\"Código mejorado y refactorizado\")\n",
    "    changes_summary: List[str] = Field(description=\"Resumen de cambios realizados\")\n",
    "    performance_improvements: List[str] = Field(description=\"Mejoras de rendimiento aplicadas\")\n",
    "    code_style_fixes: List[str] = Field(description=\"Correcciones de estilo de código\")\n",
    "\n",
    "# Parsers\n",
    "analysis_parser = PydanticOutputParser(pydantic_object=RefactoringAnalysis)\n",
    "refactoring_parser = PydanticOutputParser(pydantic_object=RefactoredCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "172a677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Pipeline de refactoring inteligente creado\n",
      "  • Análisis técnico automático\n",
      "  • Refactoring basado en métricas\n",
      "  • Optimización de código paralela\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de análisis y refactoring\n",
    "def create_refactoring_pipeline():\n",
    "    \"\"\"Crear pipeline inteligente de refactoring\"\"\"\n",
    "    \n",
    "    # Análisis técnico\n",
    "    technical_analysis = RunnableLambda(\n",
    "        lambda x: f\"\"\"\n",
    "        Analiza el siguiente código y proporciona un análisis técnico detallado:\n",
    "\n",
    "        CÓDIGO:\n",
    "        {x['code']}\n",
    "\n",
    "        MÉTRICAS DETECTADAS:\n",
    "        {x['metrics']}\n",
    "\n",
    "        PATRONES DETECTADOS:\n",
    "        {x['patterns']}\n",
    "\n",
    "        Proporciona un análisis integral considerando:\n",
    "        1. Problemas de complejidad y mantenibilidad\n",
    "        2. Anti-patrones detectados\n",
    "        3. Oportunidades de mejora\n",
    "        4. Priorización de refactoring\n",
    "\n",
    "        {analysis_parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "    ) | model | analysis_parser\n",
    "\n",
    "    # Refactoring inteligente\n",
    "    intelligent_refactoring = RunnableLambda(\n",
    "        lambda x: f\"\"\"\n",
    "        Refactoriza el siguiente código basándote en el análisis técnico:\n",
    "\n",
    "        CÓDIGO ORIGINAL:\n",
    "        {x['code']}\n",
    "\n",
    "        ANÁLISIS TÉCNICO:\n",
    "        {x['analysis']}\n",
    "\n",
    "        DIRECTRICES DE REFACTORING:\n",
    "        1. Reducir complejidad ciclomática manteniendo funcionalidad\n",
    "        2. Aplicar principios SOLID y clean code\n",
    "        3. Mejorar legibilidad y mantenibilidad\n",
    "        4. Optimizar rendimiento donde sea posible\n",
    "        5. Mantener compatibilidad con APIs existentes\n",
    "        6. Agregar documentación y tipado donde falte\n",
    "\n",
    "        IMPORTANTE: El código debe seguir mejores prácticas de FastAPI y Pydantic.\n",
    "\n",
    "        {refactoring_parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "    ) | model | refactoring_parser\n",
    "\n",
    "    # Pipeline paralelo\n",
    "    refactoring_pipeline = RunnableParallel({\n",
    "        \"analysis\": technical_analysis,\n",
    "        \"code\": RunnableLambda(lambda x: x[\"code\"]),\n",
    "        \"metrics\": RunnableLambda(lambda x: x[\"metrics\"]),\n",
    "        \"patterns\": RunnableLambda(lambda x: x[\"patterns\"])\n",
    "    }) | RunnableLambda(\n",
    "        lambda x: {\n",
    "            \"code\": x[\"code\"],\n",
    "            \"analysis\": x[\"analysis\"],\n",
    "            \"metrics\": x[\"metrics\"],\n",
    "            \"patterns\": x[\"patterns\"]\n",
    "        }\n",
    "    ) | RunnableParallel({\n",
    "        \"original\": RunnableLambda(lambda x: x),\n",
    "        \"refactored\": intelligent_refactoring\n",
    "    })\n",
    "\n",
    "    return refactoring_pipeline\n",
    "\n",
    "# Crear pipeline\n",
    "refactoring_system = create_refactoring_pipeline()\n",
    "\n",
    "print(\"🚀 Pipeline de refactoring inteligente creado\")\n",
    "print(\"  • Análisis técnico automático\")\n",
    "print(\"  • Refactoring basado en métricas\")\n",
    "print(\"  • Optimización de código paralela\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f03d3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  analysis: RunnableLambda(lambda x: f\"\\nAnaliza el siguiente código y proporciona un análisis técnico detallado:\\n\\nCÓDIGO:\\n{x['code']}\\n\\nMÉTRICAS DETECTADAS:\\n{x['metrics']}\\n\\nPATRONES DETECTADOS:\\n{x['patterns']}\\n\\nProporciona un análisis integral considerando:\\n1. Problemas de complejidad y mantenibilidad\\n2. Anti-patrones detectados\\n3. Oportunidades de mejora\\n4. Priorización de refactoring\\n\\n{analysis_parser.get_format_instructions()}\\n\")\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | PydanticOutputParser(pydantic_object=<class '__main__.RefactoringAnalysis'>),\n",
       "  code: RunnableLambda(...),\n",
       "  metrics: RunnableLambda(...),\n",
       "  patterns: RunnableLambda(...)\n",
       "}\n",
       "| RunnableLambda(lambda x: {'code': x['code'], 'analysis': x['analysis'], 'metrics': x['metrics'], 'patterns': x['patterns']})\n",
       "| {\n",
       "    original: RunnableLambda(...),\n",
       "    refactored: RunnableLambda(lambda x: f\"\\nRefactoriza el siguiente código basándote en el análisis técnico:\\n\\nCÓDIGO ORIGINAL:\\n{x['code']}\\n\\nANÁLISIS TÉCNICO:\\n{x['analysis']}\\n\\nDIRECTRICES DE REFACTORING:\\n1. Reducir complejidad ciclomática manteniendo funcionalidad\\n2. Aplicar principios SOLID y clean code\\n3. Mejorar legibilidad y mantenibilidad\\n4. Optimizar rendimiento donde sea posible\\n5. Mantener compatibilidad con APIs existentes\\n6. Agregar documentación y tipado donde falte\\n\\nIMPORTANTE: El código debe seguir mejores prácticas de FastAPI y Pydantic.\\n\\n{refactoring_parser.get_format_instructions()}\\n\")\n",
       "                | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "                | PydanticOutputParser(pydantic_object=<class '__main__.RefactoredCode'>)\n",
       "  }"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refactoring_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a6ae5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Código legacy de ejemplo cargado\n",
      "Problemas visibles:\n",
      "  • Función muy larga y compleja\n",
      "  • Lógica de negocio anidada\n",
      "  • TODOs sin resolver\n",
      "  • Uso excesivo de print\n",
      "  • Falta de validaciones\n"
     ]
    }
   ],
   "source": [
    "# DEMOSTRACIÓN: Refactoring inteligente de código legacy\n",
    "import time\n",
    "\n",
    "# Código de ejemplo con problemas detectables\n",
    "sample_legacy_code = '''\n",
    "def process_user_data(data):\n",
    "    print(\"Processing user data...\")\n",
    "    result = []\n",
    "    \n",
    "    # TODO: Add input validation\n",
    "    for item in data:\n",
    "        print(f\"Processing item: {item}\")\n",
    "        \n",
    "        if item[\"age\"] > 18 and item[\"status\"] == \"active\":\n",
    "            processed = {}\n",
    "            processed[\"id\"] = item[\"id\"]\n",
    "            processed[\"name\"] = item[\"name\"] \n",
    "            processed[\"email\"] = item[\"email\"]\n",
    "            processed[\"age\"] = item[\"age\"]\n",
    "            processed[\"processed_at\"] = time.time()\n",
    "            \n",
    "            # Complex business logic\n",
    "            if item[\"subscription\"] == \"premium\":\n",
    "                if item[\"region\"] == \"US\":\n",
    "                    processed[\"discount\"] = 0.1\n",
    "                    if item[\"loyalty_years\"] > 5:\n",
    "                        processed[\"discount\"] = 0.15\n",
    "                        if item[\"referrals\"] > 10:\n",
    "                            processed[\"discount\"] = 0.2\n",
    "                elif item[\"region\"] == \"EU\":\n",
    "                    processed[\"discount\"] = 0.08\n",
    "                    if item[\"loyalty_years\"] > 3:\n",
    "                        processed[\"discount\"] = 0.12\n",
    "                else:\n",
    "                    processed[\"discount\"] = 0.05\n",
    "            else:\n",
    "                processed[\"discount\"] = 0.0\n",
    "            \n",
    "            result.append(processed)\n",
    "            print(f\"Processed user: {processed['name']}\")\n",
    "    \n",
    "    print(f\"Total processed: {len(result)}\")\n",
    "    return result\n",
    "'''\n",
    "\n",
    "print(\"📋 Código legacy de ejemplo cargado\")\n",
    "print(\"Problemas visibles:\")\n",
    "print(\"  • Función muy larga y compleja\")\n",
    "print(\"  • Lógica de negocio anidada\")\n",
    "print(\"  • TODOs sin resolver\")\n",
    "print(\"  • Uso excesivo de print\")\n",
    "print(\"  • Falta de validaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5df69ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de análisis de código agregadas:\n"
     ]
    }
   ],
   "source": [
    "# FUNCIONES DE ANÁLISIS DE CÓDIGO (faltantes)\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "def analyze_code_complexity(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analizar complejidad del código usando AST\"\"\"\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        \n",
    "        complexity_score = 0\n",
    "        functions = []\n",
    "        issues = []\n",
    "        \n",
    "        # Analizar nodos del AST\n",
    "        for node in ast.walk(tree):\n",
    "            # Contar estructuras de control (aumentan complejidad)\n",
    "            if isinstance(node, (ast.If, ast.For, ast.While, ast.With)):\n",
    "                complexity_score += 1\n",
    "            # Contar funciones\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                functions.append(node.name)\n",
    "                # Calcular complejidad de la función\n",
    "                func_complexity = sum(1 for n in ast.walk(node) \n",
    "                                    if isinstance(n, (ast.If, ast.For, ast.While, ast.With)))\n",
    "                if func_complexity > 5:\n",
    "                    issues.append(f\"Función '{node.name}' muy compleja ({func_complexity} puntos)\")\n",
    "        \n",
    "        # Métricas básicas\n",
    "        lines = len([line for line in code.split('\\n') if line.strip()])\n",
    "        code_lines = len([line for line in code.split('\\n') \n",
    "                         if line.strip() and not line.strip().startswith('#')])\n",
    "        \n",
    "        # Calcular índice de mantenibilidad (escala 0-100)\n",
    "        maintainability_index = max(0, 100 - complexity_score * 2 - (code_lines / 10))\n",
    "        \n",
    "        # Detectar problemas adicionales\n",
    "        if 'TODO' in code:\n",
    "            issues.append(\"TODOs pendientes en el código\")\n",
    "        if code.count('print(') > 3:\n",
    "            issues.append(\"Uso excesivo de print statements\")\n",
    "        if len(functions) == 0:\n",
    "            issues.append(\"No hay funciones definidas\")\n",
    "        \n",
    "        return {\n",
    "            \"complexity_score\": complexity_score,\n",
    "            \"average_complexity\": complexity_score / max(len(functions), 1),\n",
    "            \"maintainability_index\": maintainability_index,\n",
    "            \"code_lines\": code_lines,\n",
    "            \"total_lines\": lines,\n",
    "            \"functions_count\": len(functions),\n",
    "            \"complex_functions\": [f for f in functions if f in [issue.split(\"'\")[1] for issue in issues if \"muy compleja\" in issue]],\n",
    "            \"issues\": issues\n",
    "        }\n",
    "        \n",
    "    except SyntaxError as e:\n",
    "        return {\n",
    "            \"complexity_score\": 100,  # Código con errores de sintaxis = alta complejidad\n",
    "            \"average_complexity\": 100,\n",
    "            \"maintainability_index\": 0,\n",
    "            \"code_lines\": 0,\n",
    "            \"total_lines\": len(code.split('\\n')),\n",
    "            \"functions_count\": 0,\n",
    "            \"complex_functions\": [],\n",
    "            \"issues\": [f\"Error de sintaxis: {str(e)}\"]\n",
    "        }\n",
    "\n",
    "def analyze_code_patterns(code: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Analizar patrones y anti-patrones en el código\"\"\"\n",
    "    good_patterns = []\n",
    "    anti_patterns = []\n",
    "    suggestions = []\n",
    "    \n",
    "    # Detectar patrones positivos\n",
    "    if 'def ' in code:\n",
    "        good_patterns.append(\"Funciones definidas (modularidad)\")\n",
    "    if '\"\"\"' in code or \"'''\" in code:\n",
    "        good_patterns.append(\"Documentación con docstrings\")\n",
    "    if 'try:' in code and 'except' in code:\n",
    "        good_patterns.append(\"Manejo de errores implementado\")\n",
    "    if 'class ' in code:\n",
    "        good_patterns.append(\"Uso de clases (OOP)\")\n",
    "    if 'import ' in code:\n",
    "        good_patterns.append(\"Imports organizados\")\n",
    "    \n",
    "    # Detectar anti-patrones\n",
    "    if code.count('if ') > 5 and 'elif' not in code:\n",
    "        anti_patterns.append(\"Múltiples if anidados (considerar elif)\")\n",
    "    if 'print(' in code and code.count('print(') > 2:\n",
    "        anti_patterns.append(\"Uso excesivo de print (usar logging)\")\n",
    "    if 'TODO' in code:\n",
    "        anti_patterns.append(\"TODOs sin resolver\")\n",
    "    if len([line for line in code.split('\\n') if len(line) > 100]) > 0:\n",
    "        anti_patterns.append(\"Líneas muy largas (>100 caracteres)\")\n",
    "    \n",
    "    # Contar niveles de indentación\n",
    "    max_indent = max([len(line) - len(line.lstrip()) for line in code.split('\\n')] + [0])\n",
    "    if max_indent > 16:  # >4 niveles de indentación\n",
    "        anti_patterns.append(f\"Anidamiento profundo ({max_indent//4} niveles)\")\n",
    "    \n",
    "    # Generar sugerencias\n",
    "    if 'TODO' in code:\n",
    "        suggestions.append(\"Resolver TODOs pendientes\")\n",
    "    if anti_patterns:\n",
    "        suggestions.append(\"Refactorizar para reducir complejidad\")\n",
    "    if 'print(' in code:\n",
    "        suggestions.append(\"Reemplazar prints con logging estructurado\")\n",
    "    if max_indent > 12:\n",
    "        suggestions.append(\"Extraer funciones para reducir anidamiento\")\n",
    "    if code.count('def ') == 0:\n",
    "        suggestions.append(\"Dividir código en funciones reutilizables\")\n",
    "    \n",
    "    return {\n",
    "        \"good_patterns\": good_patterns,\n",
    "        \"anti_patterns\": anti_patterns,\n",
    "        \"suggestions\": suggestions,\n",
    "        \"complexity_indicators\": {\n",
    "            \"max_indentation\": max_indent,\n",
    "            \"function_count\": code.count('def '),\n",
    "            \"print_statements\": code.count('print('),\n",
    "            \"todo_count\": code.count('TODO')\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"✅ Funciones de análisis de código agregadas:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f24b88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Iniciando análisis automático del código legacy...\n",
      "\n",
      "📊 ANÁLISIS DE COMPLEJIDAD:\n",
      "  • Complejidad máxima: 8\n",
      "  • Complejidad promedio: 8.0\n",
      "  • Índice mantenibilidad: 80.9\n",
      "  • Líneas de código: 31\n",
      "  • Funciones complejas: ['process_user_data']\n",
      "  ⚠️  PROBLEMAS DETECTADOS:\n",
      "      - Función 'process_user_data' muy compleja (8 puntos)\n",
      "      - TODOs pendientes en el código\n",
      "      - Uso excesivo de print statements\n",
      "\n",
      "🔍 ANÁLISIS DE PATRONES:\n",
      "  ✅ Patrones positivos:\n",
      "      - Funciones definidas (modularidad)\n",
      "  ❌ Anti-patrones detectados:\n",
      "      - Uso excesivo de print (usar logging)\n",
      "      - TODOs sin resolver\n",
      "      - Anidamiento profundo (7 niveles)\n",
      "  💡 Sugerencias de mejora:\n",
      "      - Resolver TODOs pendientes\n",
      "      - Refactorizar para reducir complejidad\n",
      "      - Reemplazar prints con logging estructurado\n",
      "      - Extraer funciones para reducir anidamiento\n",
      "\n",
      "✅ Análisis completo - Datos preparados para refactoring\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS AUTOMÁTICO DEL CÓDIGO LEGACY\n",
    "import asyncio\n",
    "\n",
    "async def analyze_legacy_code():\n",
    "    \"\"\"Ejecutar análisis completo del código legacy\"\"\"\n",
    "    print(\"🔍 Iniciando análisis automático del código legacy...\")\n",
    "    \n",
    "    # 1. Análisis de complejidad\n",
    "    complexity_analysis = analyze_code_complexity(sample_legacy_code)\n",
    "    print(f\"\\n📊 ANÁLISIS DE COMPLEJIDAD:\")\n",
    "    print(f\"  • Complejidad máxima: {complexity_analysis.get('complexity_score', 'N/A')}\")\n",
    "    print(f\"  • Complejidad promedio: {complexity_analysis.get('average_complexity', 'N/A'):.1f}\")\n",
    "    print(f\"  • Índice mantenibilidad: {complexity_analysis.get('maintainability_index', 'N/A'):.1f}\")\n",
    "    print(f\"  • Líneas de código: {complexity_analysis.get('code_lines', 'N/A')}\")\n",
    "    print(f\"  • Funciones complejas: {complexity_analysis.get('complex_functions', [])}\")\n",
    "    \n",
    "    if complexity_analysis.get('issues'):\n",
    "        print(f\"  ⚠️  PROBLEMAS DETECTADOS:\")\n",
    "        for issue in complexity_analysis['issues']:\n",
    "            print(f\"      - {issue}\")\n",
    "    \n",
    "    # 2. Análisis de patrones\n",
    "    pattern_analysis = analyze_code_patterns(sample_legacy_code)\n",
    "    print(f\"\\n🔍 ANÁLISIS DE PATRONES:\")\n",
    "    \n",
    "    if pattern_analysis['good_patterns']:\n",
    "        print(f\"  ✅ Patrones positivos:\")\n",
    "        for pattern in pattern_analysis['good_patterns']:\n",
    "            print(f\"      - {pattern}\")\n",
    "    \n",
    "    if pattern_analysis['anti_patterns']:\n",
    "        print(f\"  ❌ Anti-patrones detectados:\")\n",
    "        for anti_pattern in pattern_analysis['anti_patterns']:\n",
    "            print(f\"      - {anti_pattern}\")\n",
    "    \n",
    "    if pattern_analysis['suggestions']:\n",
    "        print(f\"  💡 Sugerencias de mejora:\")\n",
    "        for suggestion in pattern_analysis['suggestions']:\n",
    "            print(f\"      - {suggestion}\")\n",
    "    \n",
    "    # 3. Preparar datos para pipeline\n",
    "    analysis_data = {\n",
    "        \"code\": sample_legacy_code,\n",
    "        \"metrics\": complexity_analysis,\n",
    "        \"patterns\": pattern_analysis\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ Análisis completo - Datos preparados para refactoring\")\n",
    "    return analysis_data\n",
    "\n",
    "# Ejecutar análisis\n",
    "legacy_analysis = await analyze_legacy_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59ea935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de refactoring...\n"
     ]
    }
   ],
   "source": [
    "# EJECUCIÓN DEL REFACTORING INTELIGENTE\n",
    "async def execute_intelligent_refactoring():\n",
    "    \"\"\"Ejecutar el pipeline completo de refactoring\"\"\"\n",
    "    print(\"🚀 Ejecutando pipeline de refactoring inteligente...\")\n",
    "    \n",
    "\n",
    "    # Ejecutar pipeline con análisis previo\n",
    "    refactoring_result = await refactoring_system.ainvoke(legacy_analysis)\n",
    "    \n",
    "    # Mostrar análisis técnico\n",
    "    analysis = refactoring_result['original']['analysis']\n",
    "    print(f\"\\n📋 ANÁLISIS TÉCNICO:\")\n",
    "    print(f\"  • Prioridad de refactoring: {analysis.refactoring_priority}\")\n",
    "    print(f\"  • Esfuerzo estimado: {analysis.estimated_effort}\")\n",
    "    print(f\"  • Puntuación mantenibilidad: {analysis.maintainability_score}/10\")\n",
    "    \n",
    "    print(f\"\\n⚠️  PROBLEMAS IDENTIFICADOS:\")\n",
    "    for issue in analysis.code_issues:\n",
    "        print(f\"    - {issue}\")\n",
    "    \n",
    "    print(f\"\\n💡 SUGERENCIAS DE MEJORA:\")\n",
    "    for suggestion in analysis.improvement_suggestions:\n",
    "        print(f\"    - {suggestion}\")\n",
    "    \n",
    "    # Mostrar código refactorizado\n",
    "    refactored = refactoring_result['refactored']\n",
    "    print(f\"\\n✨ CÓDIGO REFACTORIZADO:\")\n",
    "    print(\"=\"*60)\n",
    "    print(refactored.improved_code)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n📝 RESUMEN DE CAMBIOS:\")\n",
    "    for change in refactored.changes_summary:\n",
    "        print(f\"    ✓ {change}\")\n",
    "    \n",
    "    if refactored.performance_improvements:\n",
    "        print(f\"\\n⚡ MEJORAS DE RENDIMIENTO:\")\n",
    "        for improvement in refactored.performance_improvements:\n",
    "            print(f\"    ⚡ {improvement}\")\n",
    "    \n",
    "    if refactored.code_style_fixes:\n",
    "        print(f\"\\n🎨 CORRECCIONES DE ESTILO:\")\n",
    "        for fix in refactored.code_style_fixes:\n",
    "            print(f\"    🎨 {fix}\")\n",
    "    \n",
    "    return refactoring_result\n",
    "    \n",
    "\n",
    "# Ejecutar refactoring\n",
    "print(\"Iniciando proceso de refactoring...\")\n",
    "refactoring_results = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c40415f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ejecutando pipeline de refactoring inteligente...\n",
      "\n",
      "📋 ANÁLISIS TÉCNICO:\n",
      "  • Prioridad de refactoring: Alta\n",
      "  • Esfuerzo estimado: Medio\n",
      "  • Puntuación mantenibilidad: 7/10\n",
      "\n",
      "⚠️  PROBLEMAS IDENTIFICADOS:\n",
      "    - Condicionales anidadas profundas en la lógica de descuentos (hasta 7 niveles)\n",
      "    - TODO de validación de entrada sin resolver (riesgo de KeyError/TypeError)\n",
      "    - Uso de print para registro de eventos (acopla E/S con lógica, dificulta observabilidad)\n",
      "    - Fuga potencial de PII en logs (name/email)\n",
      "    - Import faltante de 'time' (NameError en tiempo de ejecución)\n",
      "    - Falta de tipado y docstring (disminuye legibilidad y herramientas estáticas)\n",
      "    - Valores mágicos y cadenas hardcodeadas (umbrales, regiones, estados)\n",
      "    - Uso de time.time() sin zona horaria (marca de tiempo no trazable/ambigua)\n",
      "    - Función con múltiples responsabilidades (procesa datos y reporta progreso)\n",
      "    - Duplicación de asignaciones en el dict 'processed' (verbosidad y riesgo de errores)\n",
      "    - Sin manejo de errores ni validación de tipos (p.ej., age no numérico)\n",
      "    - Reglas de negocio codificadas y frágiles (difícil de extender/probar)\n",
      "    - Condición de edad estricta (> 18) podría ser inconsistente con requisitos (¿>= 18?)\n",
      "    - Falta de pruebas unitarias para la lógica de descuentos y filtros\n",
      "\n",
      "💡 SUGERENCIAS DE MEJORA:\n",
      "    - Introducir validación de entrada (pydantic/marshmallow o validaciones manuales) para tipos y presencia de claves requeridas\n",
      "    - Reemplazar print por logging estructurado (logging stdlib) con niveles y mascarado de PII; evitar registrar email completo\n",
      "    - Extraer la lógica de descuentos a una función dedicada (compute_discount) y preferir un enfoque data-driven (tablas/reglas) sobre if-else anidados\n",
      "    - Aplicar guard clauses (continue tempranos) para reducir anidamiento en el bucle\n",
      "    - Definir constantes/enums para estados, regiones, y umbrales; eliminar valores mágicos\n",
      "    - Usar timestamps con zona horaria y formato ISO 8601 (datetime.now(timezone.utc).isoformat())\n",
      "    - Añadir type hints y docstring; considerar dataclasses o TypedDict para esquematizar los items\n",
      "    - Separar responsabilidades: una función pura que procese y otra que reporte/progrese (o aceptar un logger inyectable)\n",
      "    - Simplificar la construcción de 'processed' con un dict literal y minimizar accesos repetidos a item con variables locales\n",
      "    - Manejar errores explícitamente (try/except controlado) y reportar entradas inválidas sin abortar todo el procesamiento\n",
      "    - Cubrir con pruebas unitarias y de límites (regiones, años de lealtad, referrals, borde de edad, suscripción no premium)\n",
      "    - Documentar reglas de negocio y justificar umbrales; parametrizarlos vía configuración\n",
      "    - Evaluar rendimiento y legibilidad: filtrar primero (if no cumple, continue) y luego construir el resultado\n",
      "    - Importar correctamente los módulos necesarios o migrar a datetime para coherencia temporal\n",
      "\n",
      "✨ CÓDIGO REFACTORIZADO:\n",
      "============================================================\n",
      "from typing import Any, Dict, List, Sequence, Union\n",
      "from datetime import datetime, timezone\n",
      "import logging\n",
      "\n",
      "from pydantic import BaseModel, EmailStr, Field, ValidationError, field_validator\n",
      "\n",
      "# Module-level logger (injectable through logging configuration in FastAPI app)\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "# -------------------- Constants / Configuration --------------------\n",
      "STATUS_ACTIVE = \"active\"\n",
      "SUBSCRIPTION_PREMIUM = \"premium\"\n",
      "REGION_US = \"US\"\n",
      "REGION_EU = \"EU\"\n",
      "\n",
      "AGE_THRESHOLD_EXCLUSIVE = 18  # Maintain original semantics: age must be > 18\n",
      "\n",
      "# -------------------- Data Models --------------------\n",
      "class UserInput(BaseModel):\n",
      "    \"\"\"Validated input schema for user items.\n",
      "\n",
      "    Extra keys are ignored to maintain forward compatibility with upstream payloads.\n",
      "    Strings are normalized to consistent cases to simplify business rules.\n",
      "    \"\"\"\n",
      "\n",
      "    id: Union[int, str]\n",
      "    name: str = Field(min_length=1, max_length=200)\n",
      "    email: EmailStr\n",
      "    age: int = Field(ge=0, le=150)\n",
      "    status: str\n",
      "    subscription: str\n",
      "    region: str\n",
      "    loyalty_years: int = Field(default=0, ge=0, le=100)\n",
      "    referrals: int = Field(default=0, ge=0, le=100_000)\n",
      "\n",
      "    @field_validator(\"status\")\n",
      "    @classmethod\n",
      "    def _normalize_status(cls, v: str) -> str:\n",
      "        return v.strip().lower()\n",
      "\n",
      "    @field_validator(\"subscription\")\n",
      "    @classmethod\n",
      "    def _normalize_subscription(cls, v: str) -> str:\n",
      "        return v.strip().lower()\n",
      "\n",
      "    @field_validator(\"region\")\n",
      "    @classmethod\n",
      "    def _normalize_region(cls, v: str) -> str:\n",
      "        return v.strip().upper()\n",
      "\n",
      "    class Config:\n",
      "        extra = \"ignore\"\n",
      "\n",
      "\n",
      "# -------------------- Business Logic --------------------\n",
      "def compute_discount(user: UserInput) -> float:\n",
      "    \"\"\"Compute discount according to business rules.\n",
      "\n",
      "    Mirrors original logic while reducing nesting:\n",
      "      - Non-premium => 0.0\n",
      "      - Premium + US => 0.10, >5 loyalty => 0.15, and if referrals >10 => 0.20\n",
      "      - Premium + EU => 0.08, >3 loyalty => 0.12\n",
      "      - Premium + other regions => 0.05\n",
      "    \"\"\"\n",
      "    if user.subscription != SUBSCRIPTION_PREMIUM:\n",
      "        return 0.0\n",
      "\n",
      "    if user.region == REGION_US:\n",
      "        discount = 0.10\n",
      "        if user.loyalty_years > 5:\n",
      "            discount = 0.15\n",
      "            if user.referrals > 10:\n",
      "                discount = 0.20\n",
      "        return discount\n",
      "\n",
      "    if user.region == REGION_EU:\n",
      "        return 0.12 if user.loyalty_years > 3 else 0.08\n",
      "\n",
      "    return 0.05\n",
      "\n",
      "\n",
      "# -------------------- Public API --------------------\n",
      "def process_user_data(data: Sequence[Union[Dict[str, Any], UserInput]]) -> List[Dict[str, Any]]:\n",
      "    \"\"\"Process a batch of user items and return processed entries.\n",
      "\n",
      "    - Input validation with Pydantic ensures required keys and types.\n",
      "    - Filters: age must be > 18 and status must be 'active' (maintains original semantics).\n",
      "    - Computes discount via a dedicated function.\n",
      "    - Uses timezone-aware ISO 8601 timestamps.\n",
      "    - Uses structured logging without leaking PII (logs use user id only).\n",
      "\n",
      "    Args:\n",
      "        data: Sequence of dictionaries (raw payload) or validated UserInput objects.\n",
      "\n",
      "    Returns:\n",
      "        List of processed user dictionaries with keys: id, name, email, age, processed_at, discount.\n",
      "    \"\"\"\n",
      "    result: List[Dict[str, Any]] = []\n",
      "\n",
      "    try:\n",
      "        batch_size = len(data)  # type: ignore[arg-type]\n",
      "    except Exception:\n",
      "        batch_size = None\n",
      "\n",
      "    logger.info(\"Processing user data batch\", extra={\"batch_size\": batch_size})\n",
      "\n",
      "    for idx, raw in enumerate(data):\n",
      "        try:\n",
      "            user = raw if isinstance(raw, UserInput) else UserInput.model_validate(raw)\n",
      "        except ValidationError as exc:\n",
      "            logger.warning(\n",
      "                \"Skipping invalid item\",\n",
      "                extra={\"index\": idx, \"error\": exc.errors() if hasattr(exc, \"errors\") else str(exc)},\n",
      "            )\n",
      "            continue\n",
      "        except Exception as exc:  # Defensive: unforeseen input shape\n",
      "            logger.exception(\"Unexpected error validating item\", extra={\"index\": idx, \"error\": str(exc)})\n",
      "            continue\n",
      "\n",
      "        # Guard clauses for filters (maintain original semantics)\n",
      "        if not (user.age > AGE_THRESHOLD_EXCLUSIVE):\n",
      "            logger.debug(\"User filtered by age\", extra={\"index\": idx, \"user_id\": user.id, \"age\": user.age})\n",
      "            continue\n",
      "        if user.status != STATUS_ACTIVE:\n",
      "            logger.debug(\"User filtered by status\", extra={\"index\": idx, \"user_id\": user.id, \"status\": user.status})\n",
      "            continue\n",
      "\n",
      "        discount = compute_discount(user)\n",
      "\n",
      "        processed = {\n",
      "            \"id\": user.id,\n",
      "            \"name\": user.name,\n",
      "            \"email\": user.email,\n",
      "            \"age\": user.age,\n",
      "            \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
      "            \"discount\": discount,\n",
      "        }\n",
      "\n",
      "        result.append(processed)\n",
      "        logger.debug(\"Processed user\", extra={\"index\": idx, \"user_id\": user.id, \"discount\": discount})\n",
      "\n",
      "    logger.info(\"Processing completed\", extra={\"total_processed\": len(result)})\n",
      "    return result\n",
      "\n",
      "============================================================\n",
      "\n",
      "📝 RESUMEN DE CAMBIOS:\n",
      "    ✓ Sustituido print por logging estructurado (stdlib) con niveles y sin exponer PII; se registran ids y metadatos.\n",
      "    ✓ Añadida validación de entrada con Pydantic (UserInput) incluyendo normalización de cadenas y límites de valores.\n",
      "    ✓ Extraída la lógica de descuentos a una función dedicada compute_discount para reducir anidamiento y facilitar pruebas.\n",
      "    ✓ Introducidas constantes para estados, regiones y umbrales (eliminación de valores mágicos).\n",
      "    ✓ Uso de timestamp con zona horaria (UTC) y formato ISO 8601 en processed_at.\n",
      "    ✓ Aplicados type hints completos y docstrings para mejorar legibilidad y tooling.\n",
      "    ✓ Aplicadas guard clauses para reducir complejidad ciclomática dentro del bucle.\n",
      "    ✓ Manejo explícito de errores de validación (se omiten entradas inválidas sin interrumpir el procesamiento).\n",
      "    ✓ Se mantiene la firma y la forma de salida de process_user_data para compatibilidad.\n",
      "    ✓ Simplificación de la construcción del dict resultante y acceso a campos mediante modelo validado.\n",
      "    ✓ Se ignoran claves extra del input para mayor robustez frente a cambios futuros.\n",
      "\n",
      "⚡ MEJORAS DE RENDIMIENTO:\n",
      "    ⚡ Filtrado temprano por edad y estado (guard clauses) evitando cómputo innecesario de descuentos.\n",
      "    ⚡ Menor overhead de logging al usar niveles adecuados (debug para detalle por usuario, info para resumen).\n",
      "    ⚡ Acceso a atributos tipados del modelo Pydantic en lugar de múltiples accesos a diccionario reduciendo lookups repetidos.\n",
      "    ⚡ Normalización de strings en validación (una vez) en vez de normalizar repetidamente durante la lógica.\n",
      "\n",
      "🎨 CORRECCIONES DE ESTILO:\n",
      "    🎨 Cumplimiento PEP 8: nombres constantes en mayúsculas, funciones y variables descriptivas.\n",
      "    🎨 Eliminación de prints y uso de logging estándar.\n",
      "    🎨 Documentación mediante docstrings y tipado estático en funciones y modelos.\n",
      "    🎨 Separación de responsabilidades: función pura de cálculo de descuento y función de orquestación/procesamiento.\n",
      "    🎨 Eliminación de condicionales anidados profundos; uso de guard clauses.\n",
      "    🎨 Remoción de valores mágicos sustituidos por constantes semánticas.\n",
      "    🎨 Timestamp coherente y trazable con datetime y timezone UTC.\n",
      "    🎨 Validación explícita de entrada y manejo de errores con Pydantic y excepciones controladas.\n"
     ]
    }
   ],
   "source": [
    "refactoring_results = await execute_intelligent_refactoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33fada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb783b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
