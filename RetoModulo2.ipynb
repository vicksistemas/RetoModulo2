{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86341782",
   "metadata": {},
   "source": [
    "# Pr√°ctica 5 Automatizaci√≥n y Optimizaci√≥n Avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39121530",
   "metadata": {},
   "source": [
    "> Objetivo central: **\"Automatiza un stack CRUD completo (modelo, API, tests e infraestructura) orquestando LLMs con LangChain de forma reproducible y medible.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d44a1",
   "metadata": {},
   "source": [
    "## ¬øQu√© voy a lograr y por qu√© importa?\n",
    "En esta pr√°ctica construyes un **pipeline automatizado** que, partiendo de una configuraci√≥n declarativa (YAML / Pydantic), genera:\n",
    "- Modelos Pydantic validados\n",
    "- Router FastAPI empresarial (CRUD + paginaci√≥n + auth opcional)\n",
    "- Suite de tests Pytest\n",
    "- Infraestructura (Dockerfile, migraci√≥n Alembic)\n",
    "- M√©tricas de eficiencia de la generaci√≥n\n",
    "\n",
    "Esto refleja un caso real: equipos que necesitan **acelerar el scaffolding backend** manteniendo est√°ndares de calidad. Aprender√°s a usar **LangChain Expression Language (LCEL)** y `RunnableParallel` para ejecutar tareas en paralelo y encadenar dependencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738c61b",
   "metadata": {},
   "source": [
    "Problemas reales que esto resuelve:\n",
    "- Onboarding lento: crear cada CRUD manualmente tarda horas.\n",
    "- Inconsistencia entre servicios: estilos diferentes de validaci√≥n / logs.\n",
    "- Falta de medici√≥n: se generan cosas con IA pero sin m√©tricas.\n",
    "- Riesgo t√©cnico: prompts desordenados, sin control de dependencias.\n",
    "\n",
    "Soluci√≥n mostrada: un **pipeline determinista** donde cada bloque tiene una responsabilidad clara. As√≠ escalas generaci√≥n de servicios sin sacrificar mantenibilidad.\n",
    "\n",
    "Rol de las piezas:\n",
    "- `ResourceConfig` y `FieldConfig`: contrato declarativo de tu recurso.\n",
    "- Prompts especializados (model, router, tests, infra): separaci√≥n de dominios (Domain Prompting).\n",
    "- `RunnableParallel`: acelera la generaci√≥n base (modelo + config) y luego deriva dependientes.\n",
    "- `Structured Output`: fuerza esquemas (`InfrastructureComponents`).\n",
    "- M√©tricas: base para gobernanza y ROI de IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14740e",
   "metadata": {},
   "source": [
    "| Concepto | Idea-faro | Analog√≠a |\n",
    "|----------|-----------|----------|\n",
    "| LCEL | Orquesta modular | \"LEGO de flujos LLM\" |\n",
    "| `RunnableParallel` | Paralelismo declarativo | \"Carriles simult√°neos\" |\n",
    "| Config ‚Üí Artefactos | Infra como c√≥digo pero para scaffolding | \"Terraform de tu backend\" |\n",
    "| Prompts especializados | Principio de responsabilidad √∫nica | \"Microservicios cognitivos\" |\n",
    "| M√©tricas | Observabilidad del pipeline | \"Tablero de control DevOps\" |\n",
    "| Structured Output | Control sint√°ctico | \"Molde para la arcilla del modelo\" |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204eb06",
   "metadata": {},
   "source": [
    "## Pr√°ctica paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ac3e8",
   "metadata": {},
   "source": [
    "### Parte 1: Setup del Entorno\n",
    "\n",
    "Configuraremos un entorno completo con herramientas de an√°lisis y generaci√≥n automatizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd583795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.33)\n",
      "Requirement already satisfied: langchain-community in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.3.29)\n",
      "Requirement already satisfied: fastapi in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.116.2)\n",
      "Requirement already satisfied: uvicorn in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.35.0)\n",
      "Requirement already satisfied: pydantic in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (2.11.7)\n",
      "Requirement already satisfied: pytest in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (8.4.1)\n",
      "Requirement already satisfied: httpx in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: jinja2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: pyyaml in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: click in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (8.2.1)\n",
      "Requirement already satisfied: rich in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (14.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-openai) (1.107.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from pytest) (2.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from jinja2) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from rich) (4.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /localdisk/jafraust/envs/intro/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-community fastapi uvicorn pydantic pytest httpx python-dotenv jinja2 pyyaml click rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b672ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any, Literal\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from jinja2 import Template\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3e26bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API Key configurada\n",
      "ü§ñ Modelo listo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  Configura OPENAI_API_KEY en tu archivo .env\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API Key configurada\")\n",
    "\n",
    "# Configurar modelo\n",
    "model = ChatOpenAI(model=\"gpt-5\", temperature=0)\n",
    "print(\"ü§ñ Modelo listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70343359",
   "metadata": {},
   "source": [
    "### 4.2 Modelos de Configuraci√≥n\n",
    "Implementaremos un sistema avanzado de generaci√≥n CRUD usando RunnableParallel y configuraci√≥n YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e62086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "# Modelos de configuraci√≥n\n",
    "\n",
    "class FieldConfig(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"int\", \"float\", \"str\", \"bool\"]\n",
    "    description: str = \"\"\n",
    "    constraints: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class ResourceConfig(BaseModel):\n",
    "    resource_name: str\n",
    "    class_name: str\n",
    "    fields: List[FieldConfig]\n",
    "    auth_required: bool = False\n",
    "    cache_enabled: bool = False\n",
    "    pagination: bool = True\n",
    "    soft_delete: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617119fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3788136/77762200.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  yaml.dump(sample_config.dict(), f, default_flow_style=False)\n"
     ]
    }
   ],
   "source": [
    "# 2. Crear configuraci√≥n de ejemplo\n",
    "sample_config = ResourceConfig(\n",
    "    resource_name=\"product\",\n",
    "    class_name=\"Product\", \n",
    "    fields=[\n",
    "        FieldConfig(name=\"name\", type=\"str\", description=\"Nombre del producto\", \n",
    "                   constraints={\"min_length\": 1, \"max_length\": 100}),\n",
    "        FieldConfig(name=\"price\", type=\"float\", description=\"Precio en USD\",\n",
    "                   constraints={\"ge\": 0, \"le\": 999999}),\n",
    "        FieldConfig(name=\"category\", type=\"str\", required=False, description=\"Categor√≠a\"),\n",
    "        FieldConfig(name=\"stock\", type=\"int\", description=\"Cantidad en inventario\",\n",
    "                   constraints={\"ge\": 0})\n",
    "    ],\n",
    "    auth_required=True,\n",
    "    cache_enabled=True,\n",
    "    pagination=True,\n",
    "    soft_delete=True\n",
    ")\n",
    "\n",
    "# Guardar configuraci√≥n para uso posterior\n",
    "config_path = Path(\"resource_configs\") \n",
    "config_path.mkdir(exist_ok=True)\n",
    "with open(config_path / \"product_config.yaml\", \"w\") as f:\n",
    "    yaml.dump(sample_config.dict(), f, default_flow_style=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf6415",
   "metadata": {},
   "source": [
    "### Parte 3: Generadores Especializados con RunnableParallel\n",
    "\n",
    "Crearemos generadores especializados que trabajen en paralelo para m√°xima eficiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d228d",
   "metadata": {},
   "source": [
    "Se crean 4 generadores:\n",
    "1. `model_generator`: produce modelos Pydantic (entrada, salida, update, validaciones y validators).\n",
    "2. `router_generator`: crea router FastAPI con CRUD completo y middlewares condicionales.\n",
    "3. `tests_generator`: dise√±a suite Pytest (unit, integration, performance b√°sico, edge cases).\n",
    "4. `infra_generator`: con `with_structured_output` para garantizar campos (`dockerfile`, `migration`, etc.).\n",
    "\n",
    "Dise√±o de prompts: cada uno declara expl√≠citamente criterios de calidad (ej. \"nivel PRODUCCI√ìN\", \"validaciones espec√≠ficas\", \"logging estructurado\"). Esto reduce alucinaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5ba456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# GENERADORES ESPECIALIZADOS \n",
    "\n",
    "class GeneratedComponents(BaseModel):\n",
    "    modelo_pydantic: str = Field(description=\"Modelo Pydantic con validaciones avanzadas\")\n",
    "    router_fastapi: str = Field(description=\"Router FastAPI con CRUD completo\")\n",
    "    tests_pytest: str = Field(description=\"Suite de tests exhaustiva\")\n",
    "    alembic_migration: str = Field(description=\"Migraci√≥n Alembic para base de datos\")\n",
    "    dockerfile: str = Field(description=\"Dockerfile optimizado\")\n",
    "\n",
    "\n",
    "# Templates\n",
    "model_generator =(ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres experto en Pydantic y dise√±o de APIs con FastAPI.\n",
    "        Genera modelos Pydantic de nivel PRODUCCI√ìN con:\n",
    "        - Validaciones espec√≠ficas por tipo de campo\n",
    "        - Docstrings detallados con ejemplos\n",
    "        - Field constraints apropiados\n",
    "        - Validators personalizados para l√≥gica de negocio\n",
    "        - Modelos de entrada, salida y actualizaci√≥n separados\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        CONFIGURACI√ìN:\n",
    "        Resource: {resource_name}\n",
    "        Class: {class_name}\n",
    "        Fields: {fields}\n",
    "        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\n",
    "\n",
    "        Genera modelos Pydantic profesionales con validaciones robustas.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7690d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres experto en Pydantic y dise√±o de APIs con FastAPI.\\n        Genera modelos Pydantic de nivel PRODUCCI√ìN con:\\n        - Validaciones espec√≠ficas por tipo de campo\\n        - Docstrings detallados con ejemplos\\n        - Field constraints apropiados\\n        - Validators personalizados para l√≥gica de negocio\\n        - Modelos de entrada, salida y actualizaci√≥n separados\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, template='\\n        CONFIGURACI√ìN:\\n        Resource: {resource_name}\\n        Class: {class_name}\\n        Fields: {fields}\\n        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\\n\\n        Genera modelos Pydantic profesionales con validaciones robustas.\\n        '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415d2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generador de routers FastAPI completos\n",
    "router_generator = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres arquitecto senior FastAPI especialista en APIs RESTful.\n",
    "        Genera routers de PRODUCCI√ìN con:\n",
    "        - Endpoints CRUD completos (GET, POST, PUT, PATCH, DELETE)\n",
    "        - Paginaci√≥n, filtrado y ordenamiento\n",
    "        - Manejo de errores HTTP consistente\n",
    "        - Documentaci√≥n OpenAPI rica\n",
    "        - Middlewares de auth y cache seg√∫n configuraci√≥n\n",
    "        - Logging estructurado\n",
    "        - Validaci√≥n de permisos\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        MODELO PYDANTIC:\n",
    "        {modelo_pydantic}\n",
    "\n",
    "        CONFIGURACI√ìN:\n",
    "        {config}\n",
    "\n",
    "        Genera router FastAPI de nivel empresarial.\n",
    "    \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47973e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['config', 'modelo_pydantic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres arquitecto senior FastAPI especialista en APIs RESTful.\\n        Genera routers de PRODUCCI√ìN con:\\n        - Endpoints CRUD completos (GET, POST, PUT, PATCH, DELETE)\\n        - Paginaci√≥n, filtrado y ordenamiento\\n        - Manejo de errores HTTP consistente\\n        - Documentaci√≥n OpenAPI rica\\n        - Middlewares de auth y cache seg√∫n configuraci√≥n\\n        - Logging estructurado\\n        - Validaci√≥n de permisos\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['config', 'modelo_pydantic'], input_types={}, partial_variables={}, template='\\n        MODELO PYDANTIC:\\n        {modelo_pydantic}\\n\\n        CONFIGURACI√ìN:\\n        {config}\\n\\n        Genera router FastAPI de nivel empresarial.\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e641756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generador de tests exhaustivos\n",
    "tests_generator = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Eres QA Lead especialista en testing de APIs.\n",
    "        Genera suite de tests COMPREHENSIVA con:\n",
    "        - Tests unitarios para cada endpoint\n",
    "        - Tests de integraci√≥n end-to-end\n",
    "        - Tests de performance b√°sicos\n",
    "        - Tests de seguridad (auth, validation)\n",
    "        - Tests de casos borde y error handling\n",
    "        - Fixtures y mocks apropiados\n",
    "        - Cobertura de al menos 90%\n",
    "        \"\"\"),\n",
    "                (\"human\", \"\"\"\n",
    "        ROUTER FASTAPI:\n",
    "        {router_fastapi}\n",
    "\n",
    "        MODELO PYDANTIC:\n",
    "        {modelo_pydantic}\n",
    "\n",
    "        CONFIGURACI√ìN:\n",
    "        {config}\n",
    "\n",
    "        Genera tests pytest de nivel empresarial.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91e2a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['config', 'modelo_pydantic', 'router_fastapi'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres QA Lead especialista en testing de APIs.\\n        Genera suite de tests COMPREHENSIVA con:\\n        - Tests unitarios para cada endpoint\\n        - Tests de integraci√≥n end-to-end\\n        - Tests de performance b√°sicos\\n        - Tests de seguridad (auth, validation)\\n        - Tests de casos borde y error handling\\n        - Fixtures y mocks apropiados\\n        - Cobertura de al menos 90%\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['config', 'modelo_pydantic', 'router_fastapi'], input_types={}, partial_variables={}, template='\\n        ROUTER FASTAPI:\\n        {router_fastapi}\\n\\n        MODELO PYDANTIC:\\n        {modelo_pydantic}\\n\\n        CONFIGURACI√ìN:\\n        {config}\\n\\n        Genera tests pytest de nivel empresarial.\\n        '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "701192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Modelo para infraestructura\n",
    "class InfrastructureComponents(BaseModel):\n",
    "    dockerfile: str = Field(description=\"Dockerfile multi-stage optimizado\")\n",
    "    migration: str = Field(description=\"Migraci√≥n Alembic con √≠ndices\")\n",
    "    docker_compose: str = Field(description=\"Docker-compose para desarrollo\", default=\"\")\n",
    "    deployment_script: str = Field(description=\"Script de deployment\", default=\"\")\n",
    "\n",
    "# 4. Generador de infraestructura (Docker, migrations) - corregido\n",
    "infra_generator = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Eres DevOps senior especialista en containerizaci√≥n y databases.\n",
    "    Genera infraestructura de PRODUCCI√ìN:\n",
    "    - Dockerfile multi-stage optimizado\n",
    "    - Migraci√≥n Alembic con √≠ndices apropiados\n",
    "    - Docker-compose para desarrollo\n",
    "    - Scripts de deployment\n",
    "    \"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "    CONFIGURACI√ìN:\n",
    "    {config}\n",
    "\n",
    "    MODELO PYDANTIC:\n",
    "    {modelo_pydantic}\n",
    "\n",
    "    Genera infraestructura completa para producci√≥n.\n",
    "    \"\"\")\n",
    "]) | model.with_structured_output(InfrastructureComponents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be747d8",
   "metadata": {},
   "source": [
    "### 4.4 Orquestaci√≥n LCEL\n",
    "Funci√≥n `create_advanced_crud_pipeline()`:\n",
    "- Fase base paralela: genera `modelo` y pasa `config` intacta.\n",
    "- Lambda intermedia `_generate_dependent_components`: usa salida anterior para generar router y luego en paralelo tests + infraestructura.\n",
    "- Se empaqueta todo en un `GeneratedComponents` final.\n",
    "\n",
    "Ventaja: minimiza latencia (paraleliza lo que no depende) y mantiene orden l√≥gico de dependencias (modelo ‚Üí router ‚Üí tests/infra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b811db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_dependent_components(base_components):\n",
    "    config = base_components[\"config\"]\n",
    "    modelo = base_components[\"modelo\"]\n",
    "\n",
    "    router = router_generator.invoke({\n",
    "        \"modelo_pydantic\": modelo,\n",
    "        \"config\": json.dumps(config, indent=2, ensure_ascii=False)\n",
    "    })\n",
    "\n",
    "    parallel_final = RunnableParallel({\n",
    "        \"tests\": tests_generator,\n",
    "        \"infra\": infra_generator\n",
    "    })\n",
    "\n",
    "    final_components = parallel_final.invoke({\n",
    "        \"router_fastapi\": router,\n",
    "        \"modelo_pydantic\": modelo,\n",
    "        \"config\": json.dumps(config, indent=2, ensure_ascii=False)\n",
    "    })\n",
    "\n",
    "    infra = final_components[\"infra\"]\n",
    "    return GeneratedComponents(\n",
    "        modelo_pydantic=modelo,\n",
    "        router_fastapi=router,\n",
    "        tests_pytest=final_components[\"tests\"],\n",
    "        alembic_migration=infra.migration if infra else \"\",\n",
    "        dockerfile=infra.dockerfile if infra else \"\"\n",
    "    )\n",
    "\n",
    "def create_advanced_crud_pipeline():\n",
    "    parallel_base = RunnableParallel({\n",
    "        \"modelo\": model_generator,\n",
    "        \"config\": RunnableLambda(lambda x: x)\n",
    "    })\n",
    "    return parallel_base | RunnableLambda(_generate_dependent_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14cea88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  modelo: ChatPromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Eres experto en Pydantic y dise√±o de APIs con FastAPI.\\n        Genera modelos Pydantic de nivel PRODUCCI√ìN con:\\n        - Validaciones espec√≠ficas por tipo de campo\\n        - Docstrings detallados con ejemplos\\n        - Field constraints apropiados\\n        - Validators personalizados para l√≥gica de negocio\\n        - Modelos de entrada, salida y actualizaci√≥n separados\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['auth_required', 'cache_enabled', 'class_name', 'fields', 'resource_name', 'soft_delete'], input_types={}, partial_variables={}, template='\\n        CONFIGURACI√ìN:\\n        Resource: {resource_name}\\n        Class: {class_name}\\n        Fields: {fields}\\n        Features: auth={auth_required}, cache={cache_enabled}, soft_delete={soft_delete}\\n\\n        Genera modelos Pydantic profesionales con validaciones robustas.\\n        '), additional_kwargs={})])\n",
       "          | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "          | StrOutputParser(),\n",
       "  config: RunnableLambda(...)\n",
       "}\n",
       "| RunnableLambda(_generate_dependent_components)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crud_pipeline = create_advanced_crud_pipeline()\n",
    "\n",
    "crud_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e4292",
   "metadata": {},
   "source": [
    "### 4.5 Ejecuci√≥n + M√©tricas\n",
    "Se prepara input a partir de `sample_config` y se invoca `crud_pipeline.invoke(pipeline_input)`.\n",
    "\n",
    "M√©tricas recolectadas manualmente (se esboza callback pero no se conecta en la ejecuci√≥n actual):\n",
    "- Tiempo total de generaci√≥n\n",
    "- Conteo de l√≠neas por componente\n",
    "- N√∫mero de clases, endpoints, validators, fixtures, asserts\n",
    "- C√°lculo de ROI: (tiempo manual estimado / tiempo IA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa951ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO GENERACI√ìN CRUD AUTOMATIZADA...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EJECUCI√ìN DEL PIPELINE CON M√âTRICAS AVANZADAS\n",
    "\n",
    "# 1. Callback para capturar m√©tricas detalladas\n",
    "class CRUDGenerationMetrics(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"start_time\": None,\n",
    "            \"end_time\": None,\n",
    "            \"components_generated\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"llm_calls\": 0,\n",
    "            \"parallel_executions\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"component_times\": {}\n",
    "        }\n",
    "        self.current_component = None\n",
    "        self.component_start = None\n",
    "    \n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        if not self.metrics[\"start_time\"]:\n",
    "            self.metrics[\"start_time\"] = time.time()\n",
    "        self.component_start = time.time()\n",
    "    \n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        if self.component_start:\n",
    "            duration = time.time() - self.component_start\n",
    "            component_name = self.current_component or \"unknown\"\n",
    "            self.metrics[\"component_times\"][component_name] = duration\n",
    "            self.metrics[\"components_generated\"] += 1\n",
    "        \n",
    "        self.metrics[\"end_time\"] = time.time()\n",
    "    \n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        self.metrics[\"llm_calls\"] += 1\n",
    "    \n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        if hasattr(response, 'llm_output') and response.llm_output:\n",
    "            token_usage = response.llm_output.get('token_usage', {})\n",
    "            self.metrics[\"total_tokens\"] += token_usage.get('total_tokens', 0)\n",
    "    \n",
    "    def on_chain_error(self, error, **kwargs):\n",
    "        self.metrics[\"errors\"] += 1\n",
    "    \n",
    "    def get_summary(self):\n",
    "        total_time = (self.metrics[\"end_time\"] or time.time()) - (self.metrics[\"start_time\"] or time.time())\n",
    "        return {\n",
    "            **self.metrics,\n",
    "            \"total_time\": total_time,\n",
    "            \"avg_time_per_component\": total_time / max(self.metrics[\"components_generated\"], 1),\n",
    "            \"tokens_per_second\": self.metrics[\"total_tokens\"] / max(total_time, 1),\n",
    "            \"success_rate\": (self.metrics[\"components_generated\"] - self.metrics[\"errors\"]) / max(self.metrics[\"components_generated\"], 1) * 100\n",
    "        }\n",
    "\n",
    "# 2. Ejecutar generaci√≥n con m√©tricas\n",
    "print(\"üöÄ INICIANDO GENERACI√ìN CRUD AUTOMATIZADA...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metrics_callback = CRUDGenerationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a8d55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_config.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9e4639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3788136/4071791889.py:5: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"fields\": [f.dict() for f in sample_config.fields],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'resource_name': 'product',\n",
       " 'class_name': 'Product',\n",
       " 'fields': [{'name': 'name',\n",
       "   'type': 'str',\n",
       "   'description': 'Nombre del producto',\n",
       "   'constraints': {'min_length': 1, 'max_length': 100}},\n",
       "  {'name': 'price',\n",
       "   'type': 'float',\n",
       "   'description': 'Precio en USD',\n",
       "   'constraints': {'ge': 0, 'le': 999999}},\n",
       "  {'name': 'category',\n",
       "   'type': 'str',\n",
       "   'description': 'Categor√≠a',\n",
       "   'constraints': None},\n",
       "  {'name': 'stock',\n",
       "   'type': 'int',\n",
       "   'description': 'Cantidad en inventario',\n",
       "   'constraints': {'ge': 0}}],\n",
       " 'auth_required': True,\n",
       " 'cache_enabled': True,\n",
       " 'soft_delete': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparar input para el pipeline\n",
    "pipeline_input = {\n",
    "    \"resource_name\": sample_config.resource_name,\n",
    "    \"class_name\": sample_config.class_name,\n",
    "    \"fields\": [f.dict() for f in sample_config.fields],\n",
    "    \"auth_required\": sample_config.auth_required,\n",
    "    \"cache_enabled\": sample_config.cache_enabled,\n",
    "    \"soft_delete\": sample_config.soft_delete\n",
    "}\n",
    "\n",
    "pipeline_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c1330cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generaci√≥n Completa en 446.1253263950348\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el pipeline\n",
    "start_generation = time.time()\n",
    "generated_components = crud_pipeline.invoke(pipeline_input)\n",
    "generation_time = time.time() - start_generation\n",
    "\n",
    "print(f\"Generaci√≥n Completa en {generation_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "227c9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratedComponents(modelo_pydantic='from __future__ import annotations\\n\\nfrom datetime import datetime, timezone\\nfrom decimal import Decimal, ROUND_HALF_UP, InvalidOperation\\nfrom typing import Annotated, Optional\\nfrom uuid import UUID\\n\\nfrom pydantic import (\\n    BaseModel,\\n    ConfigDict,\\n    Field,\\n    StringConstraints,\\n    StrictInt,\\n    field_validator,\\n    model_validator,\\n)\\n\\n\\nNameStr = Annotated[\\n    str,\\n    StringConstraints(\\n        min_length=1,\\n        max_length=100,\\n        strip_whitespace=True,\\n    ),\\n]\\n\\nCategoryStr = Annotated[\\n    str,\\n    StringConstraints(\\n        strip_whitespace=True,\\n    ),\\n]\\n\\n\\nclass ProductBase(BaseModel):\\n    \"\"\"\\n    Modelo base del recurso Product.\\n\\n    Incluye validaciones y normalizaci√≥n:\\n    - name: recorta y colapsa espacios m√∫ltiples, no permite caracteres de control.\\n    - price: convierte a Decimal, redondea a 2 decimales (ROUND_HALF_UP), y valida rango.\\n    - category: recorta y colapsa espacios m√∫ltiples, no permite vac√≠o.\\n    - stock: entero estricto, no negativo.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"name\": \"Camiseta B√°sica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(from_attributes=True)\\n\\n    name: NameStr = Field(\\n        ...,\\n        description=\"Nombre del producto\",\\n        examples=[\"Camiseta B√°sica\"],\\n    )\\n    price: Decimal = Field(\\n        ...,\\n        ge=Decimal(\"0\"),\\n        le=Decimal(\"999999.99\"),\\n        description=\"Precio en USD\",\\n        examples=[19.99, \"149.90\"],\\n    )\\n    category: CategoryStr = Field(\\n        ...,\\n        description=\"Categor√≠a\",\\n        examples=[\"Ropa\"],\\n    )\\n    stock: StrictInt = Field(\\n        ...,\\n        ge=0,\\n        description=\"Cantidad en inventario\",\\n        examples=[150],\\n    )\\n\\n    @field_validator(\"name\")\\n    @classmethod\\n    def validate_name(cls, v: str) -> str:\\n        # Colapsar espacios y sanitizar caracteres de control\\n        compact = \" \".join(v.split())\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"El nombre contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"category\")\\n    @classmethod\\n    def validate_category(cls, v: str) -> str:\\n        # Colapsar espacios\\n        compact = \" \".join(v.split())\\n        if compact == \"\":\\n            raise ValueError(\"La categor√≠a no puede estar vac√≠a.\")\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"La categor√≠a contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"price\", mode=\"before\")\\n    @classmethod\\n    def coerce_price(cls, v) -> Decimal:\\n        # Acepta str/float/int y los convierte de forma segura a Decimal\\n        if isinstance(v, Decimal):\\n            return v\\n        if isinstance(v, (int, float)):\\n            # Convertir float mediante str para evitar errores binarios\\n            v = str(v)\\n        if isinstance(v, str):\\n            s = v.strip().replace(\",\", \".\")\\n            try:\\n                return Decimal(s)\\n            except InvalidOperation:\\n                raise ValueError(\"Formato de precio inv√°lido.\")\\n        raise TypeError(\"Tipo de dato de precio no soportado.\")\\n\\n    @field_validator(\"price\")\\n    @classmethod\\n    def normalize_and_validate_price(cls, v: Decimal) -> Decimal:\\n        # Redondeo a 2 decimales con HALF_UP\\n        quantized = v.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\\n        # Validar rango expl√≠citamente\\n        if quantized < Decimal(\"0\") or quantized > Decimal(\"999999.99\"):\\n            raise ValueError(\"El precio debe estar entre 0 y 999,999.99 USD.\")\\n        return quantized\\n\\n\\nclass ProductCreate(ProductBase):\\n    \"\"\"\\n    Modelo de entrada (creaci√≥n) para Product.\\n\\n    Notas:\\n    - Los metadatos de auditor√≠a (created_by) y control de versiones/ETag\\n      son gestionados por el servidor, no se env√≠an en el cuerpo de creaci√≥n.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"name\": \"Camiseta B√°sica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(\\n        from_attributes=True,\\n        json_schema_extra={\\n            \"examples\": [\\n                {\\n                    \"name\": \"Camiseta B√°sica\",\\n                    \"price\": 19.99,\\n                    \"category\": \"Ropa\",\\n                    \"stock\": 150,\\n                },\\n                {\\n                    \"name\": \"Laptop Pro 14‚Äù\",\\n                    \"price\": \"1499.00\",\\n                    \"category\": \"Electr√≥nica\",\\n                    \"stock\": 25,\\n                },\\n            ]\\n        },\\n    )\\n\\n\\nclass ProductUpdate(BaseModel):\\n    \"\"\"\\n    Modelo de entrada (actualizaci√≥n parcial) para Product.\\n\\n    Reglas:\\n    - Al menos un campo de negocio (name, price, category, stock) debe enviarse.\\n    - Se requiere \\'version\\' para control de concurrencia optimista.\\n    - \\'price\\' se normaliza a 2 decimales con ROUND_HALF_UP.\\n    - Las cadenas se recortan y colapsan espacios.\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"price\": 17.49,\\n      \"stock\": 200,\\n      \"version\": 3\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(from_attributes=True)\\n\\n    name: Optional[NameStr] = Field(None, description=\"Nombre del producto\")\\n    price: Optional[Decimal] = Field(\\n        None,\\n        ge=Decimal(\"0\"),\\n        le=Decimal(\"999999.99\"),\\n        description=\"Precio en USD\",\\n    )\\n    category: Optional[CategoryStr] = Field(None, description=\"Categor√≠a\")\\n    stock: Optional[StrictInt] = Field(None, ge=0, description=\"Cantidad en inventario\")\\n\\n    # Control de concurrencia (√∫til para ETag/If-Match y caches)\\n    version: StrictInt = Field(\\n        ...,\\n        ge=1,\\n        description=\"Versi√≥n del recurso para control de concurrencia optimista\",\\n        examples=[3],\\n    )\\n\\n    @field_validator(\"name\")\\n    @classmethod\\n    def validate_name(cls, v: Optional[str]) -> Optional[str]:\\n        if v is None:\\n            return v\\n        compact = \" \".join(v.split())\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"El nombre contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"category\")\\n    @classmethod\\n    def validate_category(cls, v: Optional[str]) -> Optional[str]:\\n        if v is None:\\n            return v\\n        compact = \" \".join(v.split())\\n        if compact == \"\":\\n            raise ValueError(\"La categor√≠a no puede estar vac√≠a.\")\\n        if any(ord(ch) < 32 or ord(ch) == 127 for ch in compact):\\n            raise ValueError(\"La categor√≠a contiene caracteres de control no permitidos.\")\\n        return compact\\n\\n    @field_validator(\"price\", mode=\"before\")\\n    @classmethod\\n    def coerce_price(cls, v) -> Optional[Decimal]:\\n        if v is None:\\n            return v\\n        if isinstance(v, Decimal):\\n            return v\\n        if isinstance(v, (int, float)):\\n            v = str(v)\\n        if isinstance(v, str):\\n            s = v.strip().replace(\",\", \".\")\\n            try:\\n                return Decimal(s)\\n            except InvalidOperation:\\n                raise ValueError(\"Formato de precio inv√°lido.\")\\n        raise TypeError(\"Tipo de dato de precio no soportado.\")\\n\\n    @field_validator(\"price\")\\n    @classmethod\\n    def normalize_and_validate_price(cls, v: Optional[Decimal]) -> Optional[Decimal]:\\n        if v is None:\\n            return v\\n        quantized = v.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\\n        if quantized < Decimal(\"0\") or quantized > Decimal(\"999999.99\"):\\n            raise ValueError(\"El precio debe estar entre 0 y 999,999.99 USD.\")\\n        return quantized\\n\\n    @model_validator(mode=\"after\")\\n    def ensure_any_business_field_present(self):\\n        if (\\n            self.name is None\\n            and self.price is None\\n            and self.category is None\\n            and self.stock is None\\n        ):\\n            raise ValueError(\\n                \"Debe especificarse al menos uno de los campos: name, price, category, stock.\"\\n            )\\n        return self\\n\\n\\nclass ProductOut(ProductBase):\\n    \"\"\"\\n    Modelo de salida (lectura) para Product.\\n\\n    Incluye:\\n    - id: UUID del recurso.\\n    - created_at / updated_at: timestamps con zona horaria.\\n    - Auditor√≠a (auth=True): created_by / updated_by (UUIDs de usuario).\\n    - soft_delete=True: is_deleted, deleted_at, deleted_reason.\\n    - cache=True: version (concurrencia) y etag (caching HTTP).\\n\\n    Ejemplo\\n    -------\\n    {\\n      \"id\": \"5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a\",\\n      \"name\": \"Camiseta B√°sica\",\\n      \"price\": 19.99,\\n      \"category\": \"Ropa\",\\n      \"stock\": 150,\\n      \"version\": 3,\\n      \"etag\": \"W/\\\\\"product-5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a-v3\\\\\"\",\\n      \"created_at\": \"2024-09-01T10:15:30+00:00\",\\n      \"updated_at\": \"2024-09-10T09:00:00+00:00\",\\n      \"created_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n      \"updated_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n      \"is_deleted\": false,\\n      \"deleted_at\": null,\\n      \"deleted_reason\": null\\n    }\\n    \"\"\"\\n\\n    model_config = ConfigDict(\\n        from_attributes=True,\\n        json_schema_extra={\\n            \"examples\": [\\n                {\\n                    \"id\": \"5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a\",\\n                    \"name\": \"Camiseta B√°sica\",\\n                    \"price\": 19.99,\\n                    \"category\": \"Ropa\",\\n                    \"stock\": 150,\\n                    \"version\": 3,\\n                    \"etag\": \\'W/\"product-5e9c1e5b-0d0c-4c2b-8f0f-2b6a7a0f9f1a-v3\"\\',\\n                    \"created_at\": \"2024-09-01T10:15:30+00:00\",\\n                    \"updated_at\": \"2024-09-10T09:00:00+00:00\",\\n                    \"created_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n                    \"updated_by\": \"b7f1ca2c-6b1f-4a63-bf12-2a63a4058d2b\",\\n                    \"is_deleted\": False,\\n                    \"deleted_at\": None,\\n                    \"deleted_reason\": None,\\n                }\\n            ]\\n        },\\n    )\\n\\n    id: UUID = Field(..., description=\"Identificador √∫nico del producto\")\\n    version: StrictInt = Field(\\n        ...,\\n        ge=1,\\n        description=\"Versi√≥n del recurso para control de concurrencia/caching\",\\n    )\\n    etag: str = Field(\\n        ...,\\n        description=\\'Entidad para caching HTTP. Ej: W/\"product-<id>-v<version>\"\\',\\n    )\\n\\n    created_at: datetime = Field(\\n        ...,\\n        description=\"Fecha de creaci√≥n (timezone-aware, ISO 8601)\",\\n    )\\n    updated_at: datetime = Field(\\n        ...,\\n        description=\"Fecha de √∫ltima actualizaci√≥n (timezone-aware, ISO 8601)\",\\n    )\\n    created_by: Optional[UUID] = Field(\\n        None, description=\"Usuario que cre√≥ el recurso (auditor√≠a)\"\\n    )\\n    updated_by: Optional[UUID] = Field(\\n        None, description=\"Usuario que actualiz√≥ el recurso (auditor√≠a)\"\\n    )\\n\\n    is_deleted: bool = Field(\\n        False, description=\"Indicador de eliminaci√≥n l√≥gica (soft delete)\"\\n    )\\n    deleted_at: Optional[datetime] = Field(\\n        None, description=\"Fecha de eliminaci√≥n l√≥gica (si aplica)\"\\n    )\\n    deleted_reason: Optional[str] = Field(\\n        None, description=\"Motivo de la eliminaci√≥n l√≥gica (si aplica)\"\\n    )\\n\\n    @field_validator(\"created_at\", \"updated_at\", \"deleted_at\")\\n    @classmethod\\n    def ensure_timezone_aware(cls, v: Optional[datetime]) -> Optional[datetime]:\\n        if v is None:\\n            return v\\n        if v.tzinfo is None or v.tzinfo.utcoffset(v) is None:\\n            raise ValueError(\"Los timestamps deben incluir zona horaria (timezone-aware).\")\\n        return v\\n\\n    @field_validator(\"etag\")\\n    @classmethod\\n    def validate_etag(cls, v: str) -> str:\\n        if not v or not v.strip():\\n            raise ValueError(\"ETag no puede estar vac√≠o.\")\\n        return v.strip()\\n\\n    @model_validator(mode=\"after\")\\n    def validate_soft_delete_state(self):\\n        if self.is_deleted:\\n            if self.deleted_at is None:\\n                raise ValueError(\"deleted_at es requerido cuando is_deleted es true.\")\\n        else:\\n            if self.deleted_at is not None or self.deleted_reason is not None:\\n                raise ValueError(\\n                    \"deleted_at y deleted_reason deben ser null cuando is_deleted es false.\"\\n                )\\n        return self', router_fastapi='A continuaci√≥n tienes un router FastAPI de nivel empresarial para el recurso Product, alineado con tus modelos Pydantic y la configuraci√≥n (auth_required=true, cache_enabled=true, soft_delete=true). Incluye:\\n\\n- Endpoints CRUD completos (GET list, GET by id, POST, PUT, PATCH, DELETE soft), y extras restore y hard delete.\\n- Paginaci√≥n, filtrado y ordenamiento.\\n- ETag/If-None-Match/If-Match (caching y concurrencia optimista).\\n- Manejo de errores consistente con payload estructurado.\\n- Validaci√≥n de permisos y autenticaci√≥n v√≠a dependencias.\\n- Logging estructurado.\\n- Documentaci√≥n OpenAPI rica y ejemplos.\\n\\nCopia/pega en tu proyecto y reemplaza la implementaci√≥n del repositorio por tu capa de datos (SQLAlchemy, etc.).\\n\\n\\nfrom __future__ import annotations\\n\\nimport hashlib\\nimport logging\\nfrom datetime import datetime, timezone\\nfrom typing import Annotated, Iterable, Optional\\nfrom uuid import UUID, uuid4\\n\\nfrom fastapi import (\\n    APIRouter,\\n    Depends,\\n    HTTPException,\\n    Path,\\n    Query,\\n    Body,\\n    Request,\\n    Response,\\n    status,\\n)\\nfrom pydantic import BaseModel, Field, StrictInt\\n\\n# Importa tus modelos tal cual los definiste\\n# from app.models.product import ProductCreate, ProductUpdate, ProductOut\\n# Para este snippet asumimos que ya est√°n en el scope:\\n# ProductCreate, ProductUpdate, ProductOut\\n\\n# ==============================================================================\\n# Configuraci√≥n y constantes del recurso\\n# ==============================================================================\\n\\nRESOURCE_NAME = \"product\"\\nROUTE_PREFIX = \"/products\"\\nTAG = \"Products\"\\nMAX_PAGE_SIZE = 100\\nDEFAULT_PAGE_SIZE = 20\\nDEFAULT_SORT = \"-created_at\"\\nALLOWED_SORT_FIELDS = {\"name\", \"price\", \"category\", \"stock\", \"created_at\", \"updated_at\"}\\n\\nlogger = logging.getLogger(f\"api.{RESOURCE_NAME}\")\\nlogger.setLevel(logging.INFO)\\n\\n\\n# ==============================================================================\\n# Autenticaci√≥n y permisos (dependencias)\\n# ==============================================================================\\n\\nclass User(BaseModel):\\n    id: UUID\\n    # Scopes de ejemplo:\\n    # - product:read\\n    # - product:read:deleted\\n    # - product:create\\n    # - product:update\\n    # - product:delete\\n    # - product:restore\\n    # - product:hard_delete\\n    scopes: set[str] = Field(default_factory=set)\\n\\n\\ndef get_current_user(request: Request) -> User:\\n    \"\"\"\\n    Placeholder de autenticaci√≥n. En producci√≥n integra:\\n    - OAuth2/OIDC (Access Token), o\\n    - JWT firmado, o\\n    - Capa SSO corporativa.\\n    \"\"\"\\n    user: Optional[User] = getattr(request.state, \"user\", None)\\n    if user is None:\\n        # Para entornos de desarrollo, puedes inyectar un usuario por header:\\n        debug_user = request.headers.get(\"X-Debug-User\")\\n        if debug_user == \"admin\":\\n            return User(id=uuid4(), scopes={\\n                \"product:read\", \"product:read:deleted\", \"product:create\",\\n                \"product:update\", \"product:delete\", \"product:restore\",\\n                \"product:hard_delete\",\\n            })\\n        if debug_user == \"reader\":\\n            return User(id=uuid4(), scopes={\"product:read\"})\\n        raise HTTPException(\\n            status_code=status.HTTP_401_UNAUTHORIZED,\\n            detail={\"code\": \"auth_required\", \"message\": \"Autenticaci√≥n requerida\"},\\n        )\\n    return user\\n\\n\\ndef require_scopes(*required_scopes: str):\\n    def _dep(user: User = Depends(get_current_user)) -> User:\\n        missing = [s for s in required_scopes if s not in user.scopes]\\n        if missing:\\n            raise HTTPException(\\n                status_code=status.HTTP_403_FORBIDDEN,\\n                detail={\\n                    \"code\": \"insufficient_permissions\",\\n                    \"message\": \"Permisos insuficientes\",\\n                    \"required\": required_scopes,\\n                },\\n            )\\n        return user\\n    return _dep\\n\\n\\n# ==============================================================================\\n# Repositorio/Servicio (interfaz)\\n# ==============================================================================\\n\\nclass ProductRecord(BaseModel):\\n    id: UUID\\n    name: str\\n    price: float  # se normaliza a Decimal en los modelos Pydantic de salida\\n    category: str\\n    stock: int\\n    version: StrictInt\\n    created_at: datetime\\n    updated_at: datetime\\n    created_by: Optional[UUID] = None\\n    updated_by: Optional[UUID] = None\\n    is_deleted: bool = False\\n    deleted_at: Optional[datetime] = None\\n    deleted_reason: Optional[str] = None\\n\\n    @property\\n    def etag(self) -> str:\\n        return f\\'W/\"{RESOURCE_NAME}-{self.id}-v{self.version}\"\\'\\n\\n\\nclass ListResult(BaseModel):\\n    items: list[ProductRecord]\\n    total: int\\n    # Para caching de colecci√≥n\\n    max_updated_at: Optional[datetime] = None\\n    version_sum: int = 0\\n\\n\\nclass ProductRepositoryProtocol:\\n    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord: ...\\n    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]: ...\\n    async def list(\\n        self,\\n        *,\\n        page: int,\\n        size: int,\\n        filters: dict,\\n        sort: list[tuple[str, str]],\\n        include_deleted: bool,\\n    ) -> ListResult: ...\\n    async def replace(\\n        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]: ...\\n    async def patch(\\n        self, product_id: UUID, data: ProductUpdate, by: UUID\\n    ) -> Optional[ProductRecord]: ...\\n    async def soft_delete(\\n        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\\n    ) -> bool: ...\\n    async def restore(\\n        self, product_id: UUID, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]: ...\\n    async def hard_delete(self, product_id: UUID) -> bool: ...\\n\\n\\n# ==============================================================================\\n# Dependencia del repositorio (inyecta tu implementaci√≥n real)\\n# ==============================================================================\\n\\nasync def get_repository() -> ProductRepositoryProtocol:\\n    \"\"\"\\n    Inyecta aqu√≠ tu implementaci√≥n real (SQLAlchemy/AsyncSession).\\n    Puedes usar un contenedor o wiring con FastAPI.\\n    \"\"\"\\n    raise NotImplementedError(\"Inyecta la implementaci√≥n concreta del repositorio\")\\n\\n\\n# ==============================================================================\\n# Utilidades: ordenamiento, filtros, paginaci√≥n, ETag de colecci√≥n\\n# ==============================================================================\\n\\ndef parse_sort(sort: Optional[str]) -> list[tuple[str, str]]:\\n    if not sort:\\n        sort = DEFAULT_SORT\\n    tokens = [t.strip() for t in sort.split(\",\") if t.strip()]\\n    out: list[tuple[str, str]] = []\\n    for t in tokens:\\n        direction = \"asc\"\\n        field = t\\n        if t.startswith(\"-\"):\\n            direction = \"desc\"\\n            field = t[1:]\\n        elif t.startswith(\"+\"):\\n            field = t[1:]\\n        if field not in ALLOWED_SORT_FIELDS:\\n            raise HTTPException(\\n                status_code=status.HTTP_400_BAD_REQUEST,\\n                detail={\\n                    \"code\": \"invalid_sort\",\\n                    \"message\": f\"Campo de ordenamiento no permitido: {field}\",\\n                    \"allowed\": sorted(ALLOWED_SORT_FIELDS),\\n                },\\n            )\\n        out.append((field, direction))\\n    return out\\n\\n\\ndef collection_etag(result: ListResult, fingerprint: str) -> str:\\n    \"\"\"\\n    ETag d√©bil para la colecci√≥n:\\n    Hash de total, max_updated_at, version_sum y un fingerprint de par√°metros.\\n    \"\"\"\\n    max_ts = (\\n        result.max_updated_at.astimezone(timezone.utc).isoformat()\\n        if result.max_updated_at\\n        else \"none\"\\n    )\\n    payload = f\"{RESOURCE_NAME}:{result.total}:{max_ts}:{result.version_sum}:{fingerprint}\"\\n    h = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:16]\\n    return f\\'W/\"{RESOURCE_NAME}-collection-{h}\"\\'\\n\\n\\ndef paginated_links(base_path: str, page: int, size: int, total: int, qs: str = \"\") -> str:\\n    pages = (total + size - 1) // size if total > 0 else 1\\n    links: list[str] = []\\n    def url(p: int) -> str:\\n        return f\\'{base_path}?page={p}&size={size}{qs}\\'\\n    links.append(f\\'<{url(1)}>; rel=\"first\"\\')\\n    links.append(f\\'<{url(pages)}>; rel=\"last\"\\')\\n    if page > 1:\\n        links.append(f\\'<{url(page - 1)}>; rel=\"prev\"\\')\\n    if page < pages:\\n        links.append(f\\'<{url(page + 1)}>; rel=\"next\"\\')\\n    return \", \".join(links)\\n\\n\\ndef http_error(status_code: int, code: str, message: str, **extra):\\n    raise HTTPException(status_code=status_code, detail={\"code\": code, \"message\": message, **extra})\\n\\n\\n# ==============================================================================\\n# Router\\n# ==============================================================================\\n\\nrouter = APIRouter(prefix=ROUTE_PREFIX, tags=[TAG])\\n\\n\\n# -----------------------------\\n# GET /products (listado)\\n# -----------------------------\\n@router.get(\\n    \"\",\\n    summary=\"Listar productos\",\\n    response_model=dict,\\n    responses={\\n        200: {\"description\": \"Listado paginado de productos\"},\\n        304: {\"description\": \"No modificado (ETag coincide)\"},\\n        400: {\"description\": \"Solicitud inv√°lida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n    },\\n)\\nasync def list_products(\\n    request: Request,\\n    response: Response,\\n    page: Annotated[int, Query(ge=1)] = 1,\\n    size: Annotated[int, Query(ge=1, le=MAX_PAGE_SIZE)] = DEFAULT_PAGE_SIZE,\\n    search: Annotated[Optional[str], Query(description=\"B√∫squeda en nombre/categor√≠a\")] = None,\\n    name: Optional[str] = Query(None, description=\"Filtro exacto por nombre\"),\\n    category: Optional[str] = Query(None, description=\"Filtro exacto por categor√≠a\"),\\n    price_min: Optional[float] = Query(None, ge=0),\\n    price_max: Optional[float] = Query(None, ge=0),\\n    stock_min: Optional[int] = Query(None, ge=0),\\n    stock_max: Optional[int] = Query(None, ge=0),\\n    sort: Optional[str] = Query(DEFAULT_SORT, description=\"Ej: -created_at,+price\"),\\n    include_deleted: bool = Query(False, description=\"Incluir eliminados (requiere permiso)\"),\\n    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:read\")),\\n):\\n    if include_deleted and \"product:read:deleted\" not in user.scopes:\\n        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\\n\\n    order = parse_sort(sort)\\n\\n    filters = {\\n        \"search\": search,\\n        \"name\": name,\\n        \"category\": category,\\n        \"price_min\": price_min,\\n        \"price_max\": price_max,\\n        \"stock_min\": stock_min,\\n        \"stock_max\": stock_max,\\n    }\\n\\n    # Fingerprint de par√°metros para el ETag de colecci√≥n\\n    fp = f\"p={page}|s={size}|sort={order}|incdel={include_deleted}|f={filters}\"\\n\\n    result = await repo.list(\\n        page=page,\\n        size=size,\\n        filters=filters,\\n        sort=order,\\n        include_deleted=include_deleted,\\n    )\\n\\n    etag = collection_etag(result, fp)\\n    if if_none_match and if_none_match.strip() == etag:\\n        response.headers[\"ETag\"] = etag\\n        response.status_code = status.HTTP_304_NOT_MODIFIED\\n        return\\n\\n    # Paginated response envelope\\n    items_out = [\\n        ProductOut(\\n            id=it.id,\\n            name=it.name,\\n            price=it.price,\\n            category=it.category,\\n            stock=it.stock,\\n            version=it.version,\\n            etag=it.etag,\\n            created_at=it.created_at,\\n            updated_at=it.updated_at,\\n            created_by=it.created_by,\\n            updated_by=it.updated_by,\\n            is_deleted=it.is_deleted,\\n            deleted_at=it.deleted_at,\\n            deleted_reason=it.deleted_reason,\\n        )\\n        for it in result.items\\n    ]\\n\\n    response.headers[\"X-Total-Count\"] = str(result.total)\\n    # Link header con navegaci√≥n\\n    # Conserva query string de filtros\\n    raw_qs = \"\"\\n    qparts = []\\n    if search is not None:\\n        qparts.append(f\"&search={search}\")\\n    if name is not None:\\n        qparts.append(f\"&name={name}\")\\n    if category is not None:\\n        qparts.append(f\"&category={category}\")\\n    if price_min is not None:\\n        qparts.append(f\"&price_min={price_min}\")\\n    if price_max is not None:\\n        qparts.append(f\"&price_max={price_max}\")\\n    if stock_min is not None:\\n        qparts.append(f\"&stock_min={stock_min}\")\\n    if stock_max is not None:\\n        qparts.append(f\"&stock_max={stock_max}\")\\n    if sort is not None:\\n        qparts.append(f\"&sort={sort}\")\\n    if include_deleted:\\n        qparts.append(f\"&include_deleted=true\")\\n    raw_qs = \"\".join(qparts)\\n    response.headers[\"Link\"] = paginated_links(ROUTE_PREFIX, page, size, result.total, raw_qs)\\n    response.headers[\"ETag\"] = etag\\n    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\\n\\n    logger.info(\\n        \"product_list\",\\n        extra={\\n            \"event\": \"product_list\",\\n            \"user_id\": str(user.id),\\n            \"page\": page,\\n            \"size\": size,\\n            \"total\": result.total,\\n            \"filters\": filters,\\n            \"sort\": order,\\n        },\\n    )\\n\\n    pages = (result.total + size - 1) // size if result.total > 0 else 1\\n    return {\\n        \"items\": items_out,\\n        \"page\": page,\\n        \"size\": size,\\n        \"total\": result.total,\\n        \"pages\": pages,\\n    }\\n\\n\\n# -----------------------------\\n# GET /products/{id}\\n# -----------------------------\\nfrom fastapi import Header  # placed here to avoid confusion in snippet scope\\n\\n@router.get(\\n    \"/{product_id}\",\\n    summary=\"Obtener producto por ID\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Producto encontrado\"},\\n        304: {\"description\": \"No modificado (ETag coincide)\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n    },\\n)\\nasync def get_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    include_deleted: bool = Query(False, description=\"Incluir eliminado\"),\\n    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:read\")),\\n):\\n    if include_deleted and \"product:read:deleted\" not in user.scopes:\\n        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\\n\\n    record = await repo.get(product_id, include_deleted=include_deleted)\\n    if not record or (record.is_deleted and not include_deleted):\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    if if_none_match and if_none_match.strip() == record.etag:\\n        response.headers[\"ETag\"] = record.etag\\n        response.status_code = status.HTTP_304_NOT_MODIFIED\\n        return\\n\\n    response.headers[\"ETag\"] = record.etag\\n    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\\n\\n    return ProductOut(\\n        id=record.id,\\n        name=record.name,\\n        price=record.price,\\n        category=record.category,\\n        stock=record.stock,\\n        version=record.version,\\n        etag=record.etag,\\n        created_at=record.created_at,\\n        updated_at=record.updated_at,\\n        created_by=record.created_by,\\n        updated_by=record.updated_by,\\n        is_deleted=record.is_deleted,\\n        deleted_at=record.deleted_at,\\n        deleted_reason=record.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# POST /products (crear)\\n# -----------------------------\\n@router.post(\\n    \"\",\\n    summary=\"Crear producto\",\\n    status_code=status.HTTP_201_CREATED,\\n    response_model=ProductOut,\\n    responses={\\n        201: {\"description\": \"Creado\"},\\n        400: {\"description\": \"Solicitud inv√°lida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        409: {\"description\": \"Conflicto\"},\\n    },\\n)\\nasync def create_product(\\n    response: Response,\\n    payload: ProductCreate = Body(...),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:create\")),\\n):\\n    created = await repo.create(payload, by=user.id)\\n\\n    response.headers[\"Location\"] = f\"{ROUTE_PREFIX}/{created.id}\"\\n    response.headers[\"ETag\"] = created.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_created\",\\n        extra={\"event\": \"product_created\", \"user_id\": str(user.id), \"product_id\": str(created.id)},\\n    )\\n\\n    return ProductOut(\\n        id=created.id,\\n        name=created.name,\\n        price=created.price,\\n        category=created.category,\\n        stock=created.stock,\\n        version=created.version,\\n        etag=created.etag,\\n        created_at=created.created_at,\\n        updated_at=created.updated_at,\\n        created_by=created.created_by,\\n        updated_by=created.updated_by,\\n        is_deleted=created.is_deleted,\\n        deleted_at=created.deleted_at,\\n        deleted_reason=created.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# PUT /products/{id} (reemplazo total)\\n# Requiere If-Match con el ETag actual para concurrencia.\\n# -----------------------------\\n@router.put(\\n    \"/{product_id}\",\\n    summary=\"Reemplazar producto (PUT)\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Actualizado\"},\\n        400: {\"description\": \"Solicitud inv√°lida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def replace_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    payload: ProductCreate = Body(...),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:update\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PUT\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto est√° eliminado l√≥gicamente\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    updated = await repo.replace(product_id, payload, by=user.id, expected_version=current.version)\\n\\n    if not updated:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible reemplazar el recurso (conflicto de versi√≥n)\")\\n\\n    response.headers[\"ETag\"] = updated.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_replaced\",\\n        extra={\"event\": \"product_replaced\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=updated.id,\\n        name=updated.name,\\n        price=updated.price,\\n        category=updated.category,\\n        stock=updated.stock,\\n        version=updated.version,\\n        etag=updated.etag,\\n        created_at=updated.created_at,\\n        updated_at=updated.updated_at,\\n        created_by=updated.created_by,\\n        updated_by=updated.updated_by,\\n        is_deleted=updated.is_deleted,\\n        deleted_at=updated.deleted_at,\\n        deleted_reason=updated.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# PATCH /products/{id} (parcial)\\n# Requiere version en payload y If-Match en header.\\n# -----------------------------\\n@router.patch(\\n    \"/{product_id}\",\\n    summary=\"Actualizar parcialmente producto (PATCH)\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Actualizado\"},\\n        400: {\"description\": \"Solicitud inv√°lida\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        409: {\"description\": \"Conflicto de versi√≥n\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def patch_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    payload: ProductUpdate = Body(...),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:update\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PATCH\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto est√° eliminado l√≥gicamente\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    # Validaci√≥n adicional de versi√≥n (optimista)\\n    if payload.version != current.version:\\n        http_error(\\n            status.HTTP_409_CONFLICT,\\n            \"version_conflict\",\\n            f\"Versi√≥n desactualizada. Actual: {current.version}, recibida: {payload.version}\",\\n        )\\n\\n    updated = await repo.patch(product_id, payload, by=user.id)\\n    if not updated:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible actualizar el recurso\")\\n\\n    response.headers[\"ETag\"] = updated.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_patched\",\\n        extra={\"event\": \"product_patched\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=updated.id,\\n        name=updated.name,\\n        price=updated.price,\\n        category=updated.category,\\n        stock=updated.stock,\\n        version=updated.version,\\n        etag=updated.etag,\\n        created_at=updated.created_at,\\n        updated_at=updated.updated_at,\\n        created_by=updated.created_by,\\n        updated_by=updated.updated_by,\\n        is_deleted=updated.is_deleted,\\n        deleted_at=updated.deleted_at,\\n        deleted_reason=updated.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# DELETE /products/{id} (soft delete)\\n# -----------------------------\\n@router.delete(\\n    \"/{product_id}\",\\n    summary=\"Eliminar producto (soft delete)\",\\n    status_code=status.HTTP_204_NO_CONTENT,\\n    responses={\\n        204: {\"description\": \"Eliminado l√≥gicamente\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def delete_product(\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    reason: Optional[str] = Query(None, description=\"Motivo de eliminaci√≥n\"),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:delete\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para DELETE\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    ok = await repo.soft_delete(product_id, by=user.id, reason=reason, expected_version=current.version)\\n    if not ok:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible eliminar el recurso (conflicto de versi√≥n)\")\\n\\n    logger.info(\\n        \"product_soft_deleted\",\\n        extra={\"event\": \"product_soft_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id), \"reason\": reason},\\n    )\\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\\n\\n\\n# -----------------------------\\n# POST /products/{id}/restore (restaurar soft delete)\\n# -----------------------------\\n@router.post(\\n    \"/{product_id}/restore\",\\n    summary=\"Restaurar producto eliminado\",\\n    response_model=ProductOut,\\n    responses={\\n        200: {\"description\": \"Restaurado\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n        409: {\"description\": \"Conflicto\"},\\n        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\\n    },\\n)\\nasync def restore_product(\\n    response: Response,\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:restore\")),\\n):\\n    if not if_match:\\n        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para restaurar\")\\n\\n    current = await repo.get(product_id, include_deleted=True)\\n    if not current:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n    if not current.is_deleted:\\n        http_error(status.HTTP_409_CONFLICT, \"not_deleted\", \"El producto no est√° eliminado\")\\n\\n    if if_match.strip() != current.etag:\\n        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\\n\\n    restored = await repo.restore(product_id, by=user.id, expected_version=current.version)\\n    if not restored:\\n        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible restaurar el recurso\")\\n\\n    response.headers[\"ETag\"] = restored.etag\\n    response.headers[\"Cache-Control\"] = \"no-cache\"\\n\\n    logger.info(\\n        \"product_restored\",\\n        extra={\"event\": \"product_restored\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n\\n    return ProductOut(\\n        id=restored.id,\\n        name=restored.name,\\n        price=restored.price,\\n        category=restored.category,\\n        stock=restored.stock,\\n        version=restored.version,\\n        etag=restored.etag,\\n        created_at=restored.created_at,\\n        updated_at=restored.updated_at,\\n        created_by=restored.created_by,\\n        updated_by=restored.updated_by,\\n        is_deleted=restored.is_deleted,\\n        deleted_at=restored.deleted_at,\\n        deleted_reason=restored.deleted_reason,\\n    )\\n\\n\\n# -----------------------------\\n# DELETE /products/{id}/hard (eliminaci√≥n definitiva)\\n# -----------------------------\\n@router.delete(\\n    \"/{product_id}/hard\",\\n    summary=\"[ADMIN] Eliminaci√≥n definitiva (hard delete)\",\\n    status_code=status.HTTP_204_NO_CONTENT,\\n    responses={\\n        204: {\"description\": \"Eliminado definitivamente\"},\\n        401: {\"description\": \"No autorizado\"},\\n        403: {\"description\": \"Prohibido\"},\\n        404: {\"description\": \"No encontrado\"},\\n    },\\n)\\nasync def hard_delete_product(\\n    product_id: UUID = Path(..., description=\"ID del producto\"),\\n    repo: ProductRepositoryProtocol = Depends(get_repository),\\n    user: User = Depends(require_scopes(\"product:hard_delete\")),\\n):\\n    ok = await repo.hard_delete(product_id)\\n    if not ok:\\n        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\\n\\n    logger.warning(\\n        \"product_hard_deleted\",\\n        extra={\"event\": \"product_hard_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\\n    )\\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\\n\\n\\n# ==============================================================================\\n# Notas para la implementaci√≥n del repositorio\\n# ==============================================================================\\n\\n# - create:\\n#   - version = 1\\n#   - created_at = updated_at = datetime.now(timezone.utc)\\n#   - created_by = updated_by = user_id\\n#   - is_deleted = False\\n# - replace:\\n#   - Validar expected_version (si no coincide => conflicto)\\n#   - Actualizar todos los campos de negocio; version += 1; updated_at = now; updated_by = user_id\\n# - patch:\\n#   - Validar que el recurso no est√© eliminado\\n#   - Validar que payload.version coincida con current.version\\n#   - Aplicar cambios parciales; version += 1; updated_at = now; updated_by\\n# - soft_delete:\\n#   - Validar expected_version\\n#   - Si ya is_deleted == True => idempotente (retornar True)\\n#   - Marcar is_deleted=True, deleted_at=now, deleted_reason=reason, version += 1\\n# - restore:\\n#   - Validar expected_version\\n#   - Si no is_deleted => conflicto\\n#   - Revertir is_deleted, limpiar deleted_at/reason, version += 1\\n# - list:\\n#   - Aplicar filtros:\\n#       - search: LIKE sobre name/category\\n#       - price_min/max, stock_min/max\\n#   - Excluir eliminados por defecto; incluir si include_deleted=True\\n#   - Ordenamiento m√∫ltiple\\n#   - Retornar total, items page/size\\n#   - max_updated_at = MAX(updated_at) del result set\\n#   - version_sum = SUM(version) del result set (para ETag colecci√≥n)\\n# - get:\\n#   - Permitir include_deleted=True para operaciones administrativas\\n\\n# ==============================================================================\\n# Fin del router\\n# ==============================================================================\\n\\nExplicaci√≥n breve de concurrencia y cache:\\n- GET con If-None-Match: si el ETag coincide con el estado actual, se retorna 304 sin cuerpo.\\n- PUT/PATCH/DELETE/RESTORE requieren If-Match. Si no coincide, 412 Precondition Failed.\\n- PATCH tambi√©n requiere version en el cuerpo (control optimista adicional).\\n- ETag por recurso: W/\"product-<id>-v<version>\" (coincide con tu ProductOut).\\n- ETag de colecci√≥n: hash d√©bil del total, max_updated_at, suma de versiones y fingerprint de par√°metros.\\n\\nSeguridad y permisos:\\n- require_scopes valida permisos granulares.\\n- Ajusta los scopes seg√∫n tu modelo de seguridad real.\\n\\nLogging:\\n- Eventos clave con logger.info/logger.warning y campos estructurados en extra. Integra con tu stack (ELK/Datadog).\\n\\nDocumentaci√≥n:\\n- Los endpoints incluyen summaries, responses y modelos. Puedes extender con OpenAPI callbacks o ejemplos adicionales si lo requieres.', tests_pytest='A continuaci√≥n tienes una suite de tests pytest integral para tu router de Products en FastAPI. Incluye:\\n\\n- Fixtures y un repositorio en memoria que implementa ProductRepositoryProtocol (mocks).\\n- Tests unitarios por endpoint (CRUD + extras).\\n- Tests E2E de flujo completo.\\n- Tests de seguridad/autorizaci√≥n y validaciones.\\n- Tests de ETag/If-None-Match/If-Match (caching y concurrencia).\\n- Tests de paginaci√≥n/filtrado/ordenamiento.\\n- Tests de casos borde y manejo de errores.\\n- Tests de performance b√°sicos.\\n\\nAjusta los imports del router y modelos seg√∫n tu estructura real (marcados con TODO en el c√≥digo).\\n\\nEstructura sugerida:\\n- tests/conftest.py\\n- tests/test_products_unit.py\\n- tests/test_products_integration.py\\n- tests/test_products_security.py\\n- tests/test_products_performance.py\\n\\nComandos:\\n- Ejecutar: pytest -q\\n- Cobertura: pytest --maxfail=1 --disable-warnings --cov=. --cov-report=term-missing\\n\\ntests/conftest.py\\n```python\\nimport asyncio\\nfrom datetime import datetime, timezone\\nfrom decimal import Decimal\\nfrom typing import Optional, Iterable\\nfrom uuid import UUID, uuid4\\n\\nimport pytest\\nfrom fastapi import FastAPI\\nfrom fastapi.testclient import TestClient\\n\\n# TODO: Ajusta estos imports a tu proyecto real:\\n# from app.api.products import router, get_repository, ProductRecord, ListResult, ProductRepositoryProtocol, User\\n# from app.models.product import ProductCreate, ProductUpdate, ProductOut\\n\\n# Fallback de ejemplo si usas un m√≥dulo distinto:\\ntry:\\n    from app.api.products import (\\n        router,\\n        get_repository,\\n        ProductRecord,\\n        ListResult,\\n        ProductRepositoryProtocol,\\n        User,\\n    )\\n    from app.models.product import ProductCreate, ProductUpdate, ProductOut\\nexcept Exception:\\n    # Si el import falla, intenta con un m√≥dulo alterno. AJ√öSTALO a tu proyecto.\\n    from products_router import (\\n        router,\\n        get_repository,\\n        ProductRecord,\\n        ListResult,\\n        ProductRepositoryProtocol,\\n        User,\\n    )\\n    from product_models import ProductCreate, ProductUpdate, ProductOut  # noqa\\n\\n\\nclass InMemoryProductRepo(ProductRepositoryProtocol):\\n    def __init__(self):\\n        self._items: dict[UUID, ProductRecord] = {}\\n\\n    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord:\\n        now = datetime.now(timezone.utc)\\n        pid = uuid4()\\n        rec = ProductRecord(\\n            id=pid,\\n            name=data.name,\\n            price=float(Decimal(data.price)),\\n            category=data.category,\\n            stock=int(data.stock),\\n            version=1,\\n            created_at=now,\\n            updated_at=now,\\n            created_by=by,\\n            updated_by=by,\\n            is_deleted=False,\\n            deleted_at=None,\\n            deleted_reason=None,\\n        )\\n        self._items[pid] = rec\\n        return rec\\n\\n    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        return rec\\n\\n    async def list(\\n        self,\\n        *,\\n        page: int,\\n        size: int,\\n        filters: dict,\\n        sort: list[tuple[str, str]],\\n        include_deleted: bool,\\n    ) -> ListResult:\\n        def apply_filters(items: Iterable[ProductRecord]) -> list[ProductRecord]:\\n            out = []\\n            search = (filters.get(\"search\") or \"\").strip().lower() or None\\n            name_exact = filters.get(\"name\")\\n            category_exact = filters.get(\"category\")\\n            price_min = filters.get(\"price_min\")\\n            price_max = filters.get(\"price_max\")\\n            stock_min = filters.get(\"stock_min\")\\n            stock_max = filters.get(\"stock_max\")\\n\\n            for it in items:\\n                if not include_deleted and it.is_deleted:\\n                    continue\\n                if search:\\n                    if search not in it.name.lower() and search not in it.category.lower():\\n                        continue\\n                if name_exact is not None and it.name != name_exact:\\n                    continue\\n                if category_exact is not None and it.category != category_exact:\\n                    continue\\n                if price_min is not None and float(it.price) < float(price_min):\\n                    continue\\n                if price_max is not None and float(it.price) > float(price_max):\\n                    continue\\n                if stock_min is not None and it.stock < int(stock_min):\\n                    continue\\n                if stock_max is not None and it.stock > int(stock_max):\\n                    continue\\n                out.append(it)\\n            return out\\n\\n        filtered = apply_filters(self._items.values())\\n\\n        # Ordenamiento m√∫ltiple\\n        def sort_key(it: ProductRecord, field: str):\\n            return getattr(it, field)\\n\\n        for field, direction in reversed(sort):\\n            reverse = direction == \"desc\"\\n            filtered.sort(key=lambda x, f=field: sort_key(x, f), reverse=reverse)\\n\\n        total = len(filtered)\\n        start = (page - 1) * size\\n        end = start + size\\n        page_items = filtered[start:end]\\n\\n        max_updated_at = max((it.updated_at for it in page_items), default=None)\\n        version_sum = sum((it.version for it in page_items), start=0)\\n\\n        return ListResult(items=page_items, total=total, max_updated_at=max_updated_at, version_sum=version_sum)\\n\\n    async def replace(\\n        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if expected_version is not None and rec.version != expected_version:\\n            return None\\n        if rec.is_deleted:\\n            # El router ya valida esto; devolvemos None para simular conflicto\\n            return None\\n        now = datetime.now(timezone.utc)\\n        rec.name = data.name\\n        rec.price = float(Decimal(data.price))\\n        rec.category = data.category\\n        rec.stock = int(data.stock)\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def patch(self, product_id: UUID, data: ProductUpdate, by: UUID) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if rec.is_deleted:\\n            return None\\n        now = datetime.now(timezone.utc)\\n        if data.name is not None:\\n            rec.name = data.name\\n        if data.price is not None:\\n            rec.price = float(Decimal(data.price))\\n        if data.category is not None:\\n            rec.category = data.category\\n        if data.stock is not None:\\n            rec.stock = int(data.stock)\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def soft_delete(\\n        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\\n    ) -> bool:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return False\\n        if rec.is_deleted:\\n            return True  # idempotente\\n        if expected_version is not None and rec.version != expected_version:\\n            return False\\n        now = datetime.now(timezone.utc)\\n        rec.is_deleted = True\\n        rec.deleted_at = now\\n        rec.deleted_reason = reason\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return True\\n\\n    async def restore(\\n        self, product_id: UUID, by: UUID, expected_version: Optional[int]\\n    ) -> Optional[ProductRecord]:\\n        rec = self._items.get(product_id)\\n        if rec is None:\\n            return None\\n        if expected_version is not None and rec.version != expected_version:\\n            return None\\n        if not rec.is_deleted:\\n            return None\\n        now = datetime.now(timezone.utc)\\n        rec.is_deleted = False\\n        rec.deleted_at = None\\n        rec.deleted_reason = None\\n        rec.version += 1\\n        rec.updated_at = now\\n        rec.updated_by = by\\n        self._items[product_id] = rec\\n        return rec\\n\\n    async def hard_delete(self, product_id: UUID) -> bool:\\n        return self._items.pop(product_id, None) is not None\\n\\n\\n@pytest.fixture()\\ndef repo() -> InMemoryProductRepo:\\n    return InMemoryProductRepo()\\n\\n\\n@pytest.fixture()\\ndef app(repo: InMemoryProductRepo) -> FastAPI:\\n    app = FastAPI()\\n    app.include_router(router)\\n\\n    async def override_repo():\\n        return repo\\n\\n    app.dependency_overrides[get_repository] = override_repo\\n    return app\\n\\n\\n@pytest.fixture()\\ndef client(app: FastAPI) -> TestClient:\\n    return TestClient(app)\\n\\n\\n@pytest.fixture()\\ndef admin_headers():\\n    # Usa autenticaci√≥n debug integrada en el router\\n    return {\"X-Debug-User\": \"admin\"}\\n\\n\\n@pytest.fixture()\\ndef reader_headers():\\n    return {\"X-Debug-User\": \"reader\"}\\n\\n\\nasync def _create_product_async(client: TestClient, headers, payload: dict) -> dict:\\n    res = client.post(\"/products\", json=payload, headers=headers)\\n    assert res.status_code == 201, res.text\\n    return res.json()\\n\\n\\n@pytest.fixture()\\ndef sample_payload():\\n    return {\"name\": \"Camiseta B√°sica\", \"price\": 19.99, \"category\": \"Ropa\", \"stock\": 150}\\n\\n\\n@pytest.fixture()\\ndef another_payload():\\n    return {\"name\": \"Laptop Pro 14‚Äù\", \"price\": \"1499.00\", \"category\": \"Electr√≥nica\", \"stock\": 25}\\n\\n\\n@pytest.fixture()\\ndef many_products(client: TestClient, admin_headers):\\n    # Crea un conjunto de productos para pruebas de lista/paginaci√≥n/filtrado\\n    items = []\\n    for i in range(35):\\n        payload = {\\n            \"name\": f\"Item {i}\",\\n            \"price\": float(10 + i),\\n            \"category\": \"CatA\" if i % 2 == 0 else \"CatB\",\\n            \"stock\": i * 3,\\n        }\\n        res = client.post(\"/products\", json=payload, headers=admin_headers)\\n        assert res.status_code == 201, res.text\\n        items.append(res.json())\\n    return items\\n```\\n\\ntests/test_products_unit.py\\n```python\\nfrom time import sleep\\n\\nimport pytest\\n\\n\\ndef test_create_product(client, admin_headers, sample_payload):\\n    res = client.post(\"/products\", json=sample_payload, headers=admin_headers)\\n    assert res.status_code == 201, res.text\\n    body = res.json()\\n    assert body[\"id\"]\\n    assert body[\"name\"] == \"Camiseta B√°sica\"\\n    assert body[\"price\"] == 19.99\\n    assert body[\"version\"] == 1\\n    assert \"etag\" in res.headers\\n    assert res.headers[\"Cache-Control\"] == \"no-cache\"\\n    assert res.headers[\"Location\"].endswith(f\\'/products/{body[\"id\"]}\\')\\n\\n\\ndef test_get_product_by_id_and_etag_304(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    # GET normal\\n    res = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res.status_code == 200\\n    etag = res.headers.get(\"ETag\")\\n    assert etag\\n\\n    # GET con If-None-Match -> 304\\n    res2 = client.get(f\"/products/{pid}\", headers={**admin_headers, \"If-None-Match\": etag})\\n    assert res2.status_code == 304\\n    assert res2.headers.get(\"ETag\") == etag\\n\\n\\ndef test_list_products_pagination_filter_sort_and_etag(client, admin_headers, many_products):\\n    # P√°gina 1\\n    res = client.get(\"/products?page=1&size=20&sort=-created_at\", headers=admin_headers)\\n    assert res.status_code == 200\\n    etag1 = res.headers.get(\"ETag\")\\n    assert etag1\\n    assert res.headers.get(\"X-Total-Count\") == \"35\"\\n    assert \\'rel=\"next\"\\' in res.headers.get(\"Link\", \"\")\\n    body = res.json()\\n    assert body[\"page\"] == 1 and body[\"size\"] == 20 and body[\"total\"] == 35 and body[\"pages\"] == 2\\n    assert len(body[\"items\"]) == 20\\n\\n    # If-None-Match -> 304\\n    res_304 = client.get(\\n        \"/products?page=1&size=20&sort=-created_at\",\\n        headers={**admin_headers, \"If-None-Match\": etag1},\\n    )\\n    assert res_304.status_code == 304\\n\\n    # Filtro por categor√≠a y rango de precio\\n    res2 = client.get(\"/products?category=CatA&price_min=20&price_max=30\", headers=admin_headers)\\n    assert res2.status_code == 200\\n    items = res2.json()[\"items\"]\\n    assert all(it[\"category\"] == \"CatA\" for it in items)\\n    assert all(20 <= float(it[\"price\"]) <= 30 for it in items)\\n\\n    # Ordenamiento y validaci√≥n de sort inv√°lido\\n    res3 = client.get(\"/products?sort=+name,-price\", headers=admin_headers)\\n    assert res3.status_code == 200\\n    res_bad = client.get(\"/products?sort=-invalid_field\", headers=admin_headers)\\n    assert res_bad.status_code == 400\\n    assert res_bad.json()[\"detail\"][\"code\"] == \"invalid_sort\"\\n\\n\\ndef test_patch_requires_if_match_and_version(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    # Missing If-Match -> 428\\n    res = client.patch(f\"/products/{pid}\", json={\"price\": 17.49, \"version\": 1}, headers=admin_headers)\\n    assert res.status_code == 428\\n\\n    # Get current ETag\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    etag = res_get.headers[\"ETag\"]\\n\\n    # Version conflict -> 409\\n    res_conflict = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"price\": 17.49, \"version\": 999},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_conflict.status_code == 409\\n    assert res_conflict.json()[\"detail\"][\"code\"] in (\"version_conflict\", \"conflict\")\\n\\n    # Correct patch\\n    res_ok = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"price\": 17.49, \"version\": created[\"version\"]},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_ok.status_code == 200\\n    assert float(res_ok.json()[\"price\"]) == 17.49\\n    assert res_ok.headers[\"ETag\"] != etag  # ETag cambi√≥\\n\\n\\ndef test_put_requires_if_match_and_replaces(client, admin_headers, sample_payload, another_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n\\n    # Missing If-Match -> 428\\n    res_428 = client.put(f\"/products/{pid}\", json=another_payload, headers=admin_headers)\\n    assert res_428.status_code == 428\\n\\n    # Wrong If-Match -> 412\\n    res_412 = client.put(\\n        f\"/products/{pid}\", json=another_payload, headers={**admin_headers, \"If-Match\": \\'W/\"wrong\"\\'}\\n    )\\n    assert res_412.status_code == 412\\n\\n    # Correct replace\\n    res_ok = client.put(\\n        f\"/products/{pid}\", json=another_payload, headers={**admin_headers, \"If-Match\": etag}\\n    )\\n    assert res_ok.status_code == 200\\n    body = res_ok.json()\\n    assert body[\"name\"] == another_payload[\"name\"]\\n    assert float(body[\"price\"]) == float(another_payload[\"price\"])\\n\\n\\ndef test_delete_soft_and_restore_flow(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n\\n    # Soft delete requires If-Match\\n    res_428 = client.delete(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_428.status_code == 428\\n\\n    # Wrong ETag -> 412\\n    res_412 = client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": \\'W/\"bad\"\\'})\\n    assert res_412.status_code == 412\\n\\n    # Correct soft delete\\n    res_del = client.delete(\\n        f\"/products/{pid}?reason=sin stock\", headers={**admin_headers, \"If-Match\": etag}\\n    )\\n    assert res_del.status_code == 204\\n\\n    # Get sin include_deleted -> 404\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_get.status_code == 404\\n\\n    # Get con include_deleted -> 200 y is_deleted True\\n    res_get2 = client.get(f\"/products/{pid}?include_deleted=true\", headers=admin_headers)\\n    assert res_get2.status_code == 200\\n    assert res_get2.json()[\"is_deleted\"] is True\\n    etag_deleted = res_get2.headers[\"ETag\"]\\n\\n    # Restore requires If-Match\\n    res_r_428 = client.post(f\"/products/{pid}/restore\", headers=admin_headers)\\n    assert res_r_428.status_code == 428\\n\\n    # Restore ok\\n    res_restore = client.post(\\n        f\"/products/{pid}/restore\", headers={**admin_headers, \"If-Match\": etag_deleted}\\n    )\\n    assert res_restore.status_code == 200\\n    assert res_restore.json()[\"is_deleted\"] is False\\n\\n\\ndef test_hard_delete(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    res_hd = client.delete(f\"/products/{pid}/hard\", headers=admin_headers)\\n    assert res_hd.status_code == 204\\n\\n    res_get = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_get.status_code == 404\\n\\n\\ndef test_list_collection_etag_changes_on_update(client, admin_headers, many_products):\\n    res1 = client.get(\"/products?page=1&size=10\", headers=admin_headers)\\n    assert res1.status_code == 200\\n    etag1 = res1.headers[\"ETag\"]\\n    first_id = res1.json()[\"items\"][0][\"id\"]\\n\\n    etag_item = client.get(f\"/products/{first_id}\", headers=admin_headers).headers[\"ETag\"]\\n    # PATCH cambia version_sum y max_updated_at de la p√°gina\\n    res_patch = client.patch(\\n        f\"/products/{first_id}\",\\n        json={\"stock\": 999, \"version\": 1},\\n        headers={**admin_headers, \"If-Match\": etag_item},\\n    )\\n    assert res_patch.status_code == 200\\n\\n    res2 = client.get(\"/products?page=1&size=10\", headers=admin_headers)\\n    assert res2.status_code == 200\\n    etag2 = res2.headers[\"ETag\"]\\n    assert etag1 != etag2\\n\\n\\ndef test_validation_errors_422(client, admin_headers):\\n    # price inv√°lido\\n    bad_payload = {\"name\": \"X\", \"price\": \"abc\", \"category\": \"C\", \"stock\": 1}\\n    res = client.post(\"/products\", json=bad_payload, headers=admin_headers)\\n    assert res.status_code == 422\\n\\n    # name con control chars\\n    bad_payload2 = {\"name\": \"Bad\\\\x07Name\", \"price\": 10, \"category\": \"C\", \"stock\": 1}\\n    res2 = client.post(\"/products\", json=bad_payload2, headers=admin_headers)\\n    assert res2.status_code == 422\\n\\n    # PATCH sin campos de negocio\\n    res3 = client.post(\"/products\", json={\"name\": \"Ok\", \"price\": 1, \"category\": \"C\", \"stock\": 1}, headers=admin_headers)\\n    pid = res3.json()[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n    bad_patch = {\"version\": 1}\\n    res4 = client.patch(f\"/products/{pid}\", json=bad_patch, headers={**admin_headers, \"If-Match\": etag})\\n    assert res4.status_code == 422\\n```\\n\\ntests/test_products_integration.py\\n```python\\ndef test_e2e_flow_crud_soft_restore_hard(client, admin_headers):\\n    # Crear\\n    payload = {\"name\": \"C√°mara 4K\", \"price\": \"499.90\", \"category\": \"Electr√≥nica\", \"stock\": 10}\\n    res_c = client.post(\"/products\", json=payload, headers=admin_headers)\\n    assert res_c.status_code == 201\\n    p = res_c.json()\\n    pid = p[\"id\"]\\n\\n    # Listar y verificar aparece\\n    res_l = client.get(\"/products\", headers=admin_headers)\\n    assert res_l.status_code == 200\\n    assert any(it[\"id\"] == pid for it in res_l.json()[\"items\"])\\n\\n    # Obtener y cache 304\\n    res_g = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_g.status_code == 200\\n    etag = res_g.headers[\"ETag\"]\\n    res_304 = client.get(f\"/products/{pid}\", headers={**admin_headers, \"If-None-Match\": etag})\\n    assert res_304.status_code == 304\\n\\n    # PATCH stock\\n    res_p = client.patch(\\n        f\"/products/{pid}\",\\n        json={\"stock\": 15, \"version\": 1},\\n        headers={**admin_headers, \"If-Match\": etag},\\n    )\\n    assert res_p.status_code == 200\\n    etag2 = res_p.headers[\"ETag\"]\\n\\n    # PUT reemplazo total\\n    new_payload = {\"name\": \"C√°mara Pro\", \"price\": 599.99, \"category\": \"Electr√≥nica\", \"stock\": 5}\\n    res_put = client.put(\\n        f\"/products/{pid}\",\\n        json=new_payload,\\n        headers={**admin_headers, \"If-Match\": etag2},\\n    )\\n    assert res_put.status_code == 200\\n    etag3 = res_put.headers[\"ETag\"]\\n\\n    # Soft delete\\n    res_d = client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": etag3})\\n    assert res_d.status_code == 204\\n\\n    # Restore\\n    etag_del = client.get(f\"/products/{pid}?include_deleted=true\", headers=admin_headers).headers[\"ETag\"]\\n    res_r = client.post(f\"/products/{pid}/restore\", headers={**admin_headers, \"If-Match\": etag_del})\\n    assert res_r.status_code == 200\\n\\n    # Hard delete\\n    res_hd = client.delete(f\"/products/{pid}/hard\", headers=admin_headers)\\n    assert res_hd.status_code == 204\\n\\n    # Get -> 404\\n    res_g2 = client.get(f\"/products/{pid}\", headers=admin_headers)\\n    assert res_g2.status_code == 404\\n```\\n\\ntests/test_products_security.py\\n```python\\ndef test_auth_required(client):\\n    # Sin header -> 401\\n    res = client.get(\"/products\")\\n    assert res.status_code == 401\\n    assert res.json()[\"detail\"][\"code\"] == \"auth_required\"\\n\\n\\ndef test_reader_can_read_but_not_write(client, reader_headers):\\n    # List -> 200\\n    res = client.get(\"/products\", headers=reader_headers)\\n    assert res.status_code == 200\\n\\n    # POST -> 403\\n    payload = {\"name\": \"ReadOnly\", \"price\": 1, \"category\": \"X\", \"stock\": 0}\\n    res_post = client.post(\"/products\", json=payload, headers=reader_headers)\\n    assert res_post.status_code == 403\\n    assert res_post.json()[\"detail\"][\"code\"] == \"insufficient_permissions\"\\n\\n\\ndef test_include_deleted_requires_scope(client, admin_headers, reader_headers):\\n    # Crear y eliminar con admin\\n    p = client.post(\\n        \"/products\", json={\"name\": \"Del\", \"price\": 1, \"category\": \"X\", \"stock\": 0}, headers=admin_headers\\n    ).json()\\n    pid = p[\"id\"]\\n    etag = client.get(f\"/products/{pid}\", headers=admin_headers).headers[\"ETag\"]\\n    client.delete(f\"/products/{pid}\", headers={**admin_headers, \"If-Match\": etag})\\n\\n    # Reader intenta include_deleted -> 403\\n    res = client.get(f\"/products/{pid}?include_deleted=true\", headers=reader_headers)\\n    assert res.status_code == 403\\n    assert res.json()[\"detail\"][\"code\"] == \"insufficient_permissions\"\\n```\\n\\ntests/test_products_performance.py\\n```python\\nimport time\\n\\n\\ndef test_basic_performance_get_list(client, admin_headers, many_products):\\n    # Warm-up\\n    client.get(\"/products\", headers=admin_headers)\\n\\n    start = time.perf_counter()\\n    N = 50\\n    for _ in range(N):\\n        res = client.get(\"/products?page=1&size=20&sort=-created_at\", headers=admin_headers)\\n        assert res.status_code == 200\\n    elapsed = time.perf_counter() - start\\n    avg_ms = (elapsed / N) * 1000\\n    # Umbral b√°sico y relajado para CI\\n    assert avg_ms < 50.0, f\"Promedio {avg_ms:.2f}ms demasiado alto\"\\n\\n\\ndef test_basic_performance_get_by_id(client, admin_headers, sample_payload):\\n    created = client.post(\"/products\", json=sample_payload, headers=admin_headers).json()\\n    pid = created[\"id\"]\\n\\n    # Warm-up\\n    client.get(f\"/products/{pid}\", headers=admin_headers)\\n\\n    start = time.perf_counter()\\n    N = 100\\n    for _ in range(N):\\n        res = client.get(f\"/products/{pid}\", headers=admin_headers)\\n        assert res.status_code == 200\\n    elapsed = time.perf_counter() - start\\n    avg_ms = (elapsed / N) * 1000\\n    assert avg_ms < 30.0, f\"Promedio {avg_ms:.2f}ms demasiado alto\"\\n```\\n\\nCobertura esperada y notas:\\n- Estos tests ejercitan:\\n  - Autenticaci√≥n: 401, 403 y scopes espec√≠ficos.\\n  - Validaciones de payload: 422, normalizaci√≥n de price/name/category.\\n  - Filtros: search/category/price_min/price_max/stock_min/stock_max.\\n  - Ordenamiento: campos v√°lidos e inv√°lidos (400).\\n  - Paginaci√≥n: headers X-Total-Count y Link.\\n  - Caching: ETag en recursos y colecci√≥n; 304 con If-None-Match.\\n  - Concurrencia optimista: If-Match requerido (428), mismatch (412), version_conflict (409).\\n  - Soft delete/restore/hard delete y estados 404/409 correspondientes.\\n  - Performance b√°sica con umbrales relajados.\\n\\nConsejos:\\n- Ajusta los imports a tu m√≥dulo real.\\n- Si cambias el c√°lculo de ETag de colecci√≥n o los headers, actualiza las aserciones.\\n- Ejecuta con cobertura: pytest --cov=. --cov-report=term-missing y apunta a ‚â•90%. Si alguno de tus handlers personalizados de errores modifica c√≥digos/formatos, adapta los asserts.', alembic_migration='\"\"\"\\nAlembic migration: products table + √≠ndices y constraints\\n- price: NUMERIC(8,2) [0 .. 999999.99]\\n- validaci√≥n de soft delete\\n- √≠ndices parciales para not deleted\\n- trigram para b√∫squedas por nombre/categor√≠a (pg_trgm)\\n- trigger updated_at\\n\\nRequiere permisos para CREATE EXTENSION (pgcrypto, pg_trgm). Si tu PG gestionado no lo permite,\\n- quita las l√≠neas CREATE EXTENSION y genera UUID en la app.\\n\"\"\"\\nfrom alembic import op\\nimport sqlalchemy as sa\\nfrom sqlalchemy.dialects import postgresql\\n\\n# Revisiones\\nrevision = \\'d9b8a3e51c1e\\'\\ndown_revision = None\\nbranch_labels = None\\ndepends_on = None\\n\\ndef upgrade() -> None:\\n    # Extensiones necesarias\\n    op.execute(\"CREATE EXTENSION IF NOT EXISTS pgcrypto;\")\\n    op.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm;\")\\n\\n    # Tabla products\\n    op.create_table(\\n        \\'products\\',\\n        sa.Column(\\'id\\', postgresql.UUID(as_uuid=True), primary_key=True, nullable=False, server_default=sa.text(\\'gen_random_uuid()\\')),\\n        sa.Column(\\'name\\', sa.String(length=100), nullable=False),\\n        sa.Column(\\'price\\', sa.Numeric(8, 2), nullable=False),\\n        sa.Column(\\'category\\', sa.Text(), nullable=False),\\n        sa.Column(\\'stock\\', sa.Integer(), nullable=False),\\n        sa.Column(\\'version\\', sa.Integer(), nullable=False, server_default=\\'1\\'),\\n        sa.Column(\\'created_at\\', sa.TIMESTAMP(timezone=True), nullable=False, server_default=sa.text(\"timezone(\\'utc\\', now())\")),\\n        sa.Column(\\'updated_at\\', sa.TIMESTAMP(timezone=True), nullable=False, server_default=sa.text(\"timezone(\\'utc\\', now())\")),\\n        sa.Column(\\'created_by\\', postgresql.UUID(as_uuid=True), nullable=True),\\n        sa.Column(\\'updated_by\\', postgresql.UUID(as_uuid=True), nullable=True),\\n        sa.Column(\\'is_deleted\\', sa.Boolean(), nullable=False, server_default=sa.text(\\'false\\')),\\n        sa.Column(\\'deleted_at\\', sa.TIMESTAMP(timezone=True), nullable=True),\\n        sa.Column(\\'deleted_reason\\', sa.Text(), nullable=True),\\n        sa.CheckConstraint(\"char_length(btrim(name)) >= 1\", name=\"ck_products_name_min_length\"),\\n        sa.CheckConstraint(\"price >= 0::numeric AND price <= 999999.99\", name=\"ck_products_price_range\"),\\n        sa.CheckConstraint(\"char_length(btrim(category)) >= 1\", name=\"ck_products_category_not_empty\"),\\n        sa.CheckConstraint(\"stock >= 0\", name=\"ck_products_stock_non_negative\"),\\n        sa.CheckConstraint(\"version >= 1\", name=\"ck_products_version_min\"),\\n        sa.CheckConstraint(\\n            \"(NOT is_deleted AND deleted_at IS NULL AND deleted_reason IS NULL) OR (is_deleted AND deleted_at IS NOT NULL)\",\\n            name=\"ck_products_soft_delete_consistency\",\\n        ),\\n    )\\n\\n    # √çndices BTREE parciales (not deleted)\\n    op.create_index(\\n        \\'ix_products_category_not_deleted\\',\\n        \\'products\\',\\n        [\\'category\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\n        \\'ix_products_updated_at_not_deleted\\',\\n        \\'products\\',\\n        [\\'updated_at\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\n        \\'ix_products_stock_not_deleted\\',\\n        \\'products\\',\\n        [\\'stock\\'],\\n        unique=False,\\n        postgresql_where=sa.text(\\'is_deleted = false\\'),\\n    )\\n    op.create_index(\\'ix_products_version\\', \\'products\\', [\\'version\\'], unique=False)\\n\\n    # √çndices GIN con trigram para b√∫squedas ILIKE por nombre/categor√≠a\\n    op.execute(\"\"\"\\n        CREATE INDEX IF NOT EXISTS ix_products_name_trgm\\n        ON products USING gin (lower(name) gin_trgm_ops);\\n    \"\"\")\\n    op.execute(\"\"\"\\n        CREATE INDEX IF NOT EXISTS ix_products_category_trgm\\n        ON products USING gin (lower(category) gin_trgm_ops);\\n    \"\"\")\\n\\n    # Trigger para mantener updated_at en UTC\\n    op.execute(\\n        \"\"\"\\n        CREATE OR REPLACE FUNCTION set_updated_at()\\n        RETURNS trigger AS $$\\n        BEGIN\\n            NEW.updated_at = timezone(\\'utc\\', now());\\n            RETURN NEW;\\n        END;\\n        $$ LANGUAGE plpgsql;\\n        \"\"\"\\n    )\\n    op.execute(\\n        \"\"\"\\n        CREATE TRIGGER trg_products_set_updated_at\\n        BEFORE UPDATE ON products\\n        FOR EACH ROW\\n        EXECUTE PROCEDURE set_updated_at();\\n        \"\"\"\\n    )\\n\\n\\ndef downgrade() -> None:\\n    op.execute(\"DROP TRIGGER IF EXISTS trg_products_set_updated_at ON products;\")\\n    op.execute(\"DROP FUNCTION IF EXISTS set_updated_at();\")\\n    op.execute(\"DROP INDEX IF EXISTS ix_products_category_trgm;\")\\n    op.execute(\"DROP INDEX IF EXISTS ix_products_name_trgm;\")\\n    op.drop_index(\\'ix_products_version\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_stock_not_deleted\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_updated_at_not_deleted\\', table_name=\\'products\\')\\n    op.drop_index(\\'ix_products_category_not_deleted\\', table_name=\\'products\\')\\n    op.drop_table(\\'products\\')\\n    op.execute(\"DROP EXTENSION IF EXISTS pg_trgm;\")\\n    op.execute(\"DROP EXTENSION IF EXISTS pgcrypto;\")\\n', dockerfile='# syntax=docker/dockerfile:1\\n\\n# Imagen multi-stage optimizada para producci√≥n (FastAPI/SQLAlchemy/Alembic)\\nARG PYTHON_VERSION=3.12-slim\\n\\nFROM python:${PYTHON_VERSION} AS builder\\nENV PIP_DISABLE_PIP_VERSION_CHECK=1 \\\\\\n    PIP_NO_CACHE_DIR=1 \\\\\\n    PYTHONDONTWRITEBYTECODE=1\\n\\n# Dependencias de compilaci√≥n (psycopg/libpq)\\nRUN apt-get update && apt-get install -y --no-install-recommends \\\\\\n    build-essential gcc libpq-dev \\\\\\n  && rm -rf /var/lib/apt/lists/*\\n\\nWORKDIR /app\\n\\n# Copiar requirements (usa requirements.txt o constraints.txt)\\nCOPY requirements.txt /app/requirements.txt\\n\\n# Crear venv y compilar ruedas offline\\nRUN python -m venv /opt/venv \\\\\\n  && . /opt/venv/bin/activate \\\\\\n  && pip install --upgrade pip wheel \\\\\\n  && pip wheel --wheel-dir=/wheels -r /app/requirements.txt\\n\\n\\nFROM python:${PYTHON_VERSION} AS runtime\\nENV PYTHONDONTWRITEBYTECODE=1 \\\\\\n    PYTHONUNBUFFERED=1 \\\\\\n    PIP_DISABLE_PIP_VERSION_CHECK=1 \\\\\\n    PATH=\"/opt/venv/bin:$PATH\" \\\\\\n    TZ=UTC\\n\\n# Dependencias de runtime m√≠nimas\\nRUN apt-get update && apt-get install -y --no-install-recommends \\\\\\n    libpq5 ca-certificates curl \\\\\\n  && rm -rf /var/lib/apt/lists/*\\n\\nWORKDIR /app\\n\\n# Instalar dependencias desde ruedas offline\\nCOPY --from=builder /opt/venv /opt/venv\\nCOPY --from=builder /wheels /wheels\\nCOPY requirements.txt /app/requirements.txt\\nRUN pip install --no-index --find-links=/wheels -r /app/requirements.txt \\\\\\n  && rm -rf /wheels\\n\\n# Copiar c√≥digo de la aplicaci√≥n\\nCOPY . /app\\n\\n# Crear usuario no root\\nRUN addgroup --system app && adduser --system --ingroup app app \\\\\\n  && chown -R app:app /app\\nUSER app\\n\\nEXPOSE 8000\\n\\n# Configuraci√≥n por defecto de Gunicorn\\nENV RUN_DB_MIGRATIONS=false \\\\\\n    GUNICORN_WORKERS=2 \\\\\\n    GUNICORN_THREADS=8 \\\\\\n    GUNICORN_TIMEOUT=60\\n\\n# Entrypoint: opcionalmente ejecuta migraciones Alembic y arranca Gunicorn\\n# Variables esperadas: DATABASE_URL (SQLAlchemy, ej: postgresql+psycopg://user:pass@db:5432/app)\\nCMD [\"/bin/sh\", \"-c\", \"if [ \\\\\"$RUN_DB_MIGRATIONS\\\\\" = \\\\\"true\\\\\" ]; then alembic upgrade head; fi; exec gunicorn -k uvicorn.workers.UvicornWorker -w ${GUNICORN_WORKERS} --threads ${GUNICORN_THREADS} --timeout ${GUNICORN_TIMEOUT} -b 0.0.0.0:8000 app.main:app\"]\\n')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a71709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä AN√ÅLISIS DE COMPONENTES GENERADOS\n",
      "============================================================\n",
      "\n",
      "üîç MODELO:\n",
      "  ‚Ä¢ Lines: 387\n",
      "  ‚Ä¢ Classes: 4\n",
      "  ‚Ä¢ Validations: 19\n",
      "  ‚Ä¢ Validators: 0\n",
      "\n",
      "üîç ROUTER:\n",
      "  ‚Ä¢ Lines: 838\n",
      "  ‚Ä¢ Endpoints: 0\n",
      "  ‚Ä¢ Error Handling: 5\n",
      "  ‚Ä¢ Documentation: 8\n",
      "\n",
      "üîç TESTS:\n",
      "  ‚Ä¢ Lines: 674\n",
      "  ‚Ä¢ Test Functions: 15\n",
      "  ‚Ä¢ Assertions: 78\n",
      "  ‚Ä¢ Fixtures: 8\n"
     ]
    }
   ],
   "source": [
    "# 3. An√°lisis de los componentes generados\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä AN√ÅLISIS DE COMPONENTES GENERADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "components_analysis = {\n",
    "    \"modelo\": {\n",
    "        \"lines\": generated_components.modelo_pydantic.count('\\n'),\n",
    "        \"classes\": generated_components.modelo_pydantic.count('class '),\n",
    "        \"validations\": generated_components.modelo_pydantic.count('Field('),\n",
    "        \"validators\": generated_components.modelo_pydantic.count('@validator')\n",
    "    },\n",
    "    \"router\": {\n",
    "        \"lines\": generated_components.router_fastapi.count('\\n'),\n",
    "        \"endpoints\": len([x for x in ['@app.get', '@app.post', '@app.put', '@app.delete'] \n",
    "                        if x in generated_components.router_fastapi]),\n",
    "        \"error_handling\": generated_components.router_fastapi.count('HTTPException'),\n",
    "        \"documentation\": generated_components.router_fastapi.count('summary=')\n",
    "    },\n",
    "    \"tests\": {\n",
    "        \"lines\": generated_components.tests_pytest.count('\\n'),\n",
    "        \"test_functions\": generated_components.tests_pytest.count('def test_'),\n",
    "        \"assertions\": generated_components.tests_pytest.count('assert '),\n",
    "        \"fixtures\": generated_components.tests_pytest.count('@pytest.fixture')\n",
    "    }\n",
    "}\n",
    "\n",
    "for component, analysis in components_analysis.items():\n",
    "    print(f\"\\nüîç {component.upper()}:\")\n",
    "    for metric, value in analysis.items():\n",
    "        print(f\"  ‚Ä¢ {metric.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca3ddc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A continuaci√≥n tienes un router FastAPI de nivel empresarial para el recurso Product, alineado con tus modelos Pydantic y la configuraci√≥n (auth_required=true, cache_enabled=true, soft_delete=true). Incluye:\n",
      "\n",
      "- Endpoints CRUD completos (GET list, GET by id, POST, PUT, PATCH, DELETE soft), y extras restore y hard delete.\n",
      "- Paginaci√≥n, filtrado y ordenamiento.\n",
      "- ETag/If-None-Match/If-Match (caching y concurrencia optimista).\n",
      "- Manejo de errores consistente con payload estructurado.\n",
      "- Validaci√≥n de permisos y autenticaci√≥n v√≠a dependencias.\n",
      "- Logging estructurado.\n",
      "- Documentaci√≥n OpenAPI rica y ejemplos.\n",
      "\n",
      "Copia/pega en tu proyecto y reemplaza la implementaci√≥n del repositorio por tu capa de datos (SQLAlchemy, etc.).\n",
      "\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "import hashlib\n",
      "import logging\n",
      "from datetime import datetime, timezone\n",
      "from typing import Annotated, Iterable, Optional\n",
      "from uuid import UUID, uuid4\n",
      "\n",
      "from fastapi import (\n",
      "    APIRouter,\n",
      "    Depends,\n",
      "    HTTPException,\n",
      "    Path,\n",
      "    Query,\n",
      "    Body,\n",
      "    Request,\n",
      "    Response,\n",
      "    status,\n",
      ")\n",
      "from pydantic import BaseModel, Field, StrictInt\n",
      "\n",
      "# Importa tus modelos tal cual los definiste\n",
      "# from app.models.product import ProductCreate, ProductUpdate, ProductOut\n",
      "# Para este snippet asumimos que ya est√°n en el scope:\n",
      "# ProductCreate, ProductUpdate, ProductOut\n",
      "\n",
      "# ==============================================================================\n",
      "# Configuraci√≥n y constantes del recurso\n",
      "# ==============================================================================\n",
      "\n",
      "RESOURCE_NAME = \"product\"\n",
      "ROUTE_PREFIX = \"/products\"\n",
      "TAG = \"Products\"\n",
      "MAX_PAGE_SIZE = 100\n",
      "DEFAULT_PAGE_SIZE = 20\n",
      "DEFAULT_SORT = \"-created_at\"\n",
      "ALLOWED_SORT_FIELDS = {\"name\", \"price\", \"category\", \"stock\", \"created_at\", \"updated_at\"}\n",
      "\n",
      "logger = logging.getLogger(f\"api.{RESOURCE_NAME}\")\n",
      "logger.setLevel(logging.INFO)\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Autenticaci√≥n y permisos (dependencias)\n",
      "# ==============================================================================\n",
      "\n",
      "class User(BaseModel):\n",
      "    id: UUID\n",
      "    # Scopes de ejemplo:\n",
      "    # - product:read\n",
      "    # - product:read:deleted\n",
      "    # - product:create\n",
      "    # - product:update\n",
      "    # - product:delete\n",
      "    # - product:restore\n",
      "    # - product:hard_delete\n",
      "    scopes: set[str] = Field(default_factory=set)\n",
      "\n",
      "\n",
      "def get_current_user(request: Request) -> User:\n",
      "    \"\"\"\n",
      "    Placeholder de autenticaci√≥n. En producci√≥n integra:\n",
      "    - OAuth2/OIDC (Access Token), o\n",
      "    - JWT firmado, o\n",
      "    - Capa SSO corporativa.\n",
      "    \"\"\"\n",
      "    user: Optional[User] = getattr(request.state, \"user\", None)\n",
      "    if user is None:\n",
      "        # Para entornos de desarrollo, puedes inyectar un usuario por header:\n",
      "        debug_user = request.headers.get(\"X-Debug-User\")\n",
      "        if debug_user == \"admin\":\n",
      "            return User(id=uuid4(), scopes={\n",
      "                \"product:read\", \"product:read:deleted\", \"product:create\",\n",
      "                \"product:update\", \"product:delete\", \"product:restore\",\n",
      "                \"product:hard_delete\",\n",
      "            })\n",
      "        if debug_user == \"reader\":\n",
      "            return User(id=uuid4(), scopes={\"product:read\"})\n",
      "        raise HTTPException(\n",
      "            status_code=status.HTTP_401_UNAUTHORIZED,\n",
      "            detail={\"code\": \"auth_required\", \"message\": \"Autenticaci√≥n requerida\"},\n",
      "        )\n",
      "    return user\n",
      "\n",
      "\n",
      "def require_scopes(*required_scopes: str):\n",
      "    def _dep(user: User = Depends(get_current_user)) -> User:\n",
      "        missing = [s for s in required_scopes if s not in user.scopes]\n",
      "        if missing:\n",
      "            raise HTTPException(\n",
      "                status_code=status.HTTP_403_FORBIDDEN,\n",
      "                detail={\n",
      "                    \"code\": \"insufficient_permissions\",\n",
      "                    \"message\": \"Permisos insuficientes\",\n",
      "                    \"required\": required_scopes,\n",
      "                },\n",
      "            )\n",
      "        return user\n",
      "    return _dep\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Repositorio/Servicio (interfaz)\n",
      "# ==============================================================================\n",
      "\n",
      "class ProductRecord(BaseModel):\n",
      "    id: UUID\n",
      "    name: str\n",
      "    price: float  # se normaliza a Decimal en los modelos Pydantic de salida\n",
      "    category: str\n",
      "    stock: int\n",
      "    version: StrictInt\n",
      "    created_at: datetime\n",
      "    updated_at: datetime\n",
      "    created_by: Optional[UUID] = None\n",
      "    updated_by: Optional[UUID] = None\n",
      "    is_deleted: bool = False\n",
      "    deleted_at: Optional[datetime] = None\n",
      "    deleted_reason: Optional[str] = None\n",
      "\n",
      "    @property\n",
      "    def etag(self) -> str:\n",
      "        return f'W/\"{RESOURCE_NAME}-{self.id}-v{self.version}\"'\n",
      "\n",
      "\n",
      "class ListResult(BaseModel):\n",
      "    items: list[ProductRecord]\n",
      "    total: int\n",
      "    # Para caching de colecci√≥n\n",
      "    max_updated_at: Optional[datetime] = None\n",
      "    version_sum: int = 0\n",
      "\n",
      "\n",
      "class ProductRepositoryProtocol:\n",
      "    async def create(self, data: ProductCreate, by: UUID) -> ProductRecord: ...\n",
      "    async def get(self, product_id: UUID, include_deleted: bool = False) -> Optional[ProductRecord]: ...\n",
      "    async def list(\n",
      "        self,\n",
      "        *,\n",
      "        page: int,\n",
      "        size: int,\n",
      "        filters: dict,\n",
      "        sort: list[tuple[str, str]],\n",
      "        include_deleted: bool,\n",
      "    ) -> ListResult: ...\n",
      "    async def replace(\n",
      "        self, product_id: UUID, data: ProductCreate, by: UUID, expected_version: Optional[int]\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def patch(\n",
      "        self, product_id: UUID, data: ProductUpdate, by: UUID\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def soft_delete(\n",
      "        self, product_id: UUID, by: UUID, reason: Optional[str], expected_version: Optional[int]\n",
      "    ) -> bool: ...\n",
      "    async def restore(\n",
      "        self, product_id: UUID, by: UUID, expected_version: Optional[int]\n",
      "    ) -> Optional[ProductRecord]: ...\n",
      "    async def hard_delete(self, product_id: UUID) -> bool: ...\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Dependencia del repositorio (inyecta tu implementaci√≥n real)\n",
      "# ==============================================================================\n",
      "\n",
      "async def get_repository() -> ProductRepositoryProtocol:\n",
      "    \"\"\"\n",
      "    Inyecta aqu√≠ tu implementaci√≥n real (SQLAlchemy/AsyncSession).\n",
      "    Puedes usar un contenedor o wiring con FastAPI.\n",
      "    \"\"\"\n",
      "    raise NotImplementedError(\"Inyecta la implementaci√≥n concreta del repositorio\")\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Utilidades: ordenamiento, filtros, paginaci√≥n, ETag de colecci√≥n\n",
      "# ==============================================================================\n",
      "\n",
      "def parse_sort(sort: Optional[str]) -> list[tuple[str, str]]:\n",
      "    if not sort:\n",
      "        sort = DEFAULT_SORT\n",
      "    tokens = [t.strip() for t in sort.split(\",\") if t.strip()]\n",
      "    out: list[tuple[str, str]] = []\n",
      "    for t in tokens:\n",
      "        direction = \"asc\"\n",
      "        field = t\n",
      "        if t.startswith(\"-\"):\n",
      "            direction = \"desc\"\n",
      "            field = t[1:]\n",
      "        elif t.startswith(\"+\"):\n",
      "            field = t[1:]\n",
      "        if field not in ALLOWED_SORT_FIELDS:\n",
      "            raise HTTPException(\n",
      "                status_code=status.HTTP_400_BAD_REQUEST,\n",
      "                detail={\n",
      "                    \"code\": \"invalid_sort\",\n",
      "                    \"message\": f\"Campo de ordenamiento no permitido: {field}\",\n",
      "                    \"allowed\": sorted(ALLOWED_SORT_FIELDS),\n",
      "                },\n",
      "            )\n",
      "        out.append((field, direction))\n",
      "    return out\n",
      "\n",
      "\n",
      "def collection_etag(result: ListResult, fingerprint: str) -> str:\n",
      "    \"\"\"\n",
      "    ETag d√©bil para la colecci√≥n:\n",
      "    Hash de total, max_updated_at, version_sum y un fingerprint de par√°metros.\n",
      "    \"\"\"\n",
      "    max_ts = (\n",
      "        result.max_updated_at.astimezone(timezone.utc).isoformat()\n",
      "        if result.max_updated_at\n",
      "        else \"none\"\n",
      "    )\n",
      "    payload = f\"{RESOURCE_NAME}:{result.total}:{max_ts}:{result.version_sum}:{fingerprint}\"\n",
      "    h = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()[:16]\n",
      "    return f'W/\"{RESOURCE_NAME}-collection-{h}\"'\n",
      "\n",
      "\n",
      "def paginated_links(base_path: str, page: int, size: int, total: int, qs: str = \"\") -> str:\n",
      "    pages = (total + size - 1) // size if total > 0 else 1\n",
      "    links: list[str] = []\n",
      "    def url(p: int) -> str:\n",
      "        return f'{base_path}?page={p}&size={size}{qs}'\n",
      "    links.append(f'<{url(1)}>; rel=\"first\"')\n",
      "    links.append(f'<{url(pages)}>; rel=\"last\"')\n",
      "    if page > 1:\n",
      "        links.append(f'<{url(page - 1)}>; rel=\"prev\"')\n",
      "    if page < pages:\n",
      "        links.append(f'<{url(page + 1)}>; rel=\"next\"')\n",
      "    return \", \".join(links)\n",
      "\n",
      "\n",
      "def http_error(status_code: int, code: str, message: str, **extra):\n",
      "    raise HTTPException(status_code=status_code, detail={\"code\": code, \"message\": message, **extra})\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Router\n",
      "# ==============================================================================\n",
      "\n",
      "router = APIRouter(prefix=ROUTE_PREFIX, tags=[TAG])\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# GET /products (listado)\n",
      "# -----------------------------\n",
      "@router.get(\n",
      "    \"\",\n",
      "    summary=\"Listar productos\",\n",
      "    response_model=dict,\n",
      "    responses={\n",
      "        200: {\"description\": \"Listado paginado de productos\"},\n",
      "        304: {\"description\": \"No modificado (ETag coincide)\"},\n",
      "        400: {\"description\": \"Solicitud inv√°lida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "    },\n",
      ")\n",
      "async def list_products(\n",
      "    request: Request,\n",
      "    response: Response,\n",
      "    page: Annotated[int, Query(ge=1)] = 1,\n",
      "    size: Annotated[int, Query(ge=1, le=MAX_PAGE_SIZE)] = DEFAULT_PAGE_SIZE,\n",
      "    search: Annotated[Optional[str], Query(description=\"B√∫squeda en nombre/categor√≠a\")] = None,\n",
      "    name: Optional[str] = Query(None, description=\"Filtro exacto por nombre\"),\n",
      "    category: Optional[str] = Query(None, description=\"Filtro exacto por categor√≠a\"),\n",
      "    price_min: Optional[float] = Query(None, ge=0),\n",
      "    price_max: Optional[float] = Query(None, ge=0),\n",
      "    stock_min: Optional[int] = Query(None, ge=0),\n",
      "    stock_max: Optional[int] = Query(None, ge=0),\n",
      "    sort: Optional[str] = Query(DEFAULT_SORT, description=\"Ej: -created_at,+price\"),\n",
      "    include_deleted: bool = Query(False, description=\"Incluir eliminados (requiere permiso)\"),\n",
      "    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:read\")),\n",
      "):\n",
      "    if include_deleted and \"product:read:deleted\" not in user.scopes:\n",
      "        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\n",
      "\n",
      "    order = parse_sort(sort)\n",
      "\n",
      "    filters = {\n",
      "        \"search\": search,\n",
      "        \"name\": name,\n",
      "        \"category\": category,\n",
      "        \"price_min\": price_min,\n",
      "        \"price_max\": price_max,\n",
      "        \"stock_min\": stock_min,\n",
      "        \"stock_max\": stock_max,\n",
      "    }\n",
      "\n",
      "    # Fingerprint de par√°metros para el ETag de colecci√≥n\n",
      "    fp = f\"p={page}|s={size}|sort={order}|incdel={include_deleted}|f={filters}\"\n",
      "\n",
      "    result = await repo.list(\n",
      "        page=page,\n",
      "        size=size,\n",
      "        filters=filters,\n",
      "        sort=order,\n",
      "        include_deleted=include_deleted,\n",
      "    )\n",
      "\n",
      "    etag = collection_etag(result, fp)\n",
      "    if if_none_match and if_none_match.strip() == etag:\n",
      "        response.headers[\"ETag\"] = etag\n",
      "        response.status_code = status.HTTP_304_NOT_MODIFIED\n",
      "        return\n",
      "\n",
      "    # Paginated response envelope\n",
      "    items_out = [\n",
      "        ProductOut(\n",
      "            id=it.id,\n",
      "            name=it.name,\n",
      "            price=it.price,\n",
      "            category=it.category,\n",
      "            stock=it.stock,\n",
      "            version=it.version,\n",
      "            etag=it.etag,\n",
      "            created_at=it.created_at,\n",
      "            updated_at=it.updated_at,\n",
      "            created_by=it.created_by,\n",
      "            updated_by=it.updated_by,\n",
      "            is_deleted=it.is_deleted,\n",
      "            deleted_at=it.deleted_at,\n",
      "            deleted_reason=it.deleted_reason,\n",
      "        )\n",
      "        for it in result.items\n",
      "    ]\n",
      "\n",
      "    response.headers[\"X-Total-Count\"] = str(result.total)\n",
      "    # Link header con navegaci√≥n\n",
      "    # Conserva query string de filtros\n",
      "    raw_qs = \"\"\n",
      "    qparts = []\n",
      "    if search is not None:\n",
      "        qparts.append(f\"&search={search}\")\n",
      "    if name is not None:\n",
      "        qparts.append(f\"&name={name}\")\n",
      "    if category is not None:\n",
      "        qparts.append(f\"&category={category}\")\n",
      "    if price_min is not None:\n",
      "        qparts.append(f\"&price_min={price_min}\")\n",
      "    if price_max is not None:\n",
      "        qparts.append(f\"&price_max={price_max}\")\n",
      "    if stock_min is not None:\n",
      "        qparts.append(f\"&stock_min={stock_min}\")\n",
      "    if stock_max is not None:\n",
      "        qparts.append(f\"&stock_max={stock_max}\")\n",
      "    if sort is not None:\n",
      "        qparts.append(f\"&sort={sort}\")\n",
      "    if include_deleted:\n",
      "        qparts.append(f\"&include_deleted=true\")\n",
      "    raw_qs = \"\".join(qparts)\n",
      "    response.headers[\"Link\"] = paginated_links(ROUTE_PREFIX, page, size, result.total, raw_qs)\n",
      "    response.headers[\"ETag\"] = etag\n",
      "    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_list\",\n",
      "        extra={\n",
      "            \"event\": \"product_list\",\n",
      "            \"user_id\": str(user.id),\n",
      "            \"page\": page,\n",
      "            \"size\": size,\n",
      "            \"total\": result.total,\n",
      "            \"filters\": filters,\n",
      "            \"sort\": order,\n",
      "        },\n",
      "    )\n",
      "\n",
      "    pages = (result.total + size - 1) // size if result.total > 0 else 1\n",
      "    return {\n",
      "        \"items\": items_out,\n",
      "        \"page\": page,\n",
      "        \"size\": size,\n",
      "        \"total\": result.total,\n",
      "        \"pages\": pages,\n",
      "    }\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# GET /products/{id}\n",
      "# -----------------------------\n",
      "from fastapi import Header  # placed here to avoid confusion in snippet scope\n",
      "\n",
      "@router.get(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Obtener producto por ID\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Producto encontrado\"},\n",
      "        304: {\"description\": \"No modificado (ETag coincide)\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "    },\n",
      ")\n",
      "async def get_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    include_deleted: bool = Query(False, description=\"Incluir eliminado\"),\n",
      "    if_none_match: Optional[str] = Header(default=None, alias=\"If-None-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:read\")),\n",
      "):\n",
      "    if include_deleted and \"product:read:deleted\" not in user.scopes:\n",
      "        http_error(status.HTTP_403_FORBIDDEN, \"insufficient_permissions\", \"Permiso para leer eliminados requerido\")\n",
      "\n",
      "    record = await repo.get(product_id, include_deleted=include_deleted)\n",
      "    if not record or (record.is_deleted and not include_deleted):\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    if if_none_match and if_none_match.strip() == record.etag:\n",
      "        response.headers[\"ETag\"] = record.etag\n",
      "        response.status_code = status.HTTP_304_NOT_MODIFIED\n",
      "        return\n",
      "\n",
      "    response.headers[\"ETag\"] = record.etag\n",
      "    response.headers[\"Cache-Control\"] = \"private, must-revalidate\"\n",
      "\n",
      "    return ProductOut(\n",
      "        id=record.id,\n",
      "        name=record.name,\n",
      "        price=record.price,\n",
      "        category=record.category,\n",
      "        stock=record.stock,\n",
      "        version=record.version,\n",
      "        etag=record.etag,\n",
      "        created_at=record.created_at,\n",
      "        updated_at=record.updated_at,\n",
      "        created_by=record.created_by,\n",
      "        updated_by=record.updated_by,\n",
      "        is_deleted=record.is_deleted,\n",
      "        deleted_at=record.deleted_at,\n",
      "        deleted_reason=record.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# POST /products (crear)\n",
      "# -----------------------------\n",
      "@router.post(\n",
      "    \"\",\n",
      "    summary=\"Crear producto\",\n",
      "    status_code=status.HTTP_201_CREATED,\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        201: {\"description\": \"Creado\"},\n",
      "        400: {\"description\": \"Solicitud inv√°lida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        409: {\"description\": \"Conflicto\"},\n",
      "    },\n",
      ")\n",
      "async def create_product(\n",
      "    response: Response,\n",
      "    payload: ProductCreate = Body(...),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:create\")),\n",
      "):\n",
      "    created = await repo.create(payload, by=user.id)\n",
      "\n",
      "    response.headers[\"Location\"] = f\"{ROUTE_PREFIX}/{created.id}\"\n",
      "    response.headers[\"ETag\"] = created.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_created\",\n",
      "        extra={\"event\": \"product_created\", \"user_id\": str(user.id), \"product_id\": str(created.id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=created.id,\n",
      "        name=created.name,\n",
      "        price=created.price,\n",
      "        category=created.category,\n",
      "        stock=created.stock,\n",
      "        version=created.version,\n",
      "        etag=created.etag,\n",
      "        created_at=created.created_at,\n",
      "        updated_at=created.updated_at,\n",
      "        created_by=created.created_by,\n",
      "        updated_by=created.updated_by,\n",
      "        is_deleted=created.is_deleted,\n",
      "        deleted_at=created.deleted_at,\n",
      "        deleted_reason=created.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# PUT /products/{id} (reemplazo total)\n",
      "# Requiere If-Match con el ETag actual para concurrencia.\n",
      "# -----------------------------\n",
      "@router.put(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Reemplazar producto (PUT)\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Actualizado\"},\n",
      "        400: {\"description\": \"Solicitud inv√°lida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def replace_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    payload: ProductCreate = Body(...),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:update\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PUT\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto est√° eliminado l√≥gicamente\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    updated = await repo.replace(product_id, payload, by=user.id, expected_version=current.version)\n",
      "\n",
      "    if not updated:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible reemplazar el recurso (conflicto de versi√≥n)\")\n",
      "\n",
      "    response.headers[\"ETag\"] = updated.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_replaced\",\n",
      "        extra={\"event\": \"product_replaced\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=updated.id,\n",
      "        name=updated.name,\n",
      "        price=updated.price,\n",
      "        category=updated.category,\n",
      "        stock=updated.stock,\n",
      "        version=updated.version,\n",
      "        etag=updated.etag,\n",
      "        created_at=updated.created_at,\n",
      "        updated_at=updated.updated_at,\n",
      "        created_by=updated.created_by,\n",
      "        updated_by=updated.updated_by,\n",
      "        is_deleted=updated.is_deleted,\n",
      "        deleted_at=updated.deleted_at,\n",
      "        deleted_reason=updated.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# PATCH /products/{id} (parcial)\n",
      "# Requiere version en payload y If-Match en header.\n",
      "# -----------------------------\n",
      "@router.patch(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Actualizar parcialmente producto (PATCH)\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Actualizado\"},\n",
      "        400: {\"description\": \"Solicitud inv√°lida\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        409: {\"description\": \"Conflicto de versi√≥n\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def patch_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    payload: ProductUpdate = Body(...),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:update\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para PATCH\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"deleted_resource\", \"El producto est√° eliminado l√≥gicamente\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    # Validaci√≥n adicional de versi√≥n (optimista)\n",
      "    if payload.version != current.version:\n",
      "        http_error(\n",
      "            status.HTTP_409_CONFLICT,\n",
      "            \"version_conflict\",\n",
      "            f\"Versi√≥n desactualizada. Actual: {current.version}, recibida: {payload.version}\",\n",
      "        )\n",
      "\n",
      "    updated = await repo.patch(product_id, payload, by=user.id)\n",
      "    if not updated:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible actualizar el recurso\")\n",
      "\n",
      "    response.headers[\"ETag\"] = updated.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_patched\",\n",
      "        extra={\"event\": \"product_patched\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=updated.id,\n",
      "        name=updated.name,\n",
      "        price=updated.price,\n",
      "        category=updated.category,\n",
      "        stock=updated.stock,\n",
      "        version=updated.version,\n",
      "        etag=updated.etag,\n",
      "        created_at=updated.created_at,\n",
      "        updated_at=updated.updated_at,\n",
      "        created_by=updated.created_by,\n",
      "        updated_by=updated.updated_by,\n",
      "        is_deleted=updated.is_deleted,\n",
      "        deleted_at=updated.deleted_at,\n",
      "        deleted_reason=updated.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# DELETE /products/{id} (soft delete)\n",
      "# -----------------------------\n",
      "@router.delete(\n",
      "    \"/{product_id}\",\n",
      "    summary=\"Eliminar producto (soft delete)\",\n",
      "    status_code=status.HTTP_204_NO_CONTENT,\n",
      "    responses={\n",
      "        204: {\"description\": \"Eliminado l√≥gicamente\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def delete_product(\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    reason: Optional[str] = Query(None, description=\"Motivo de eliminaci√≥n\"),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:delete\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para DELETE\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    ok = await repo.soft_delete(product_id, by=user.id, reason=reason, expected_version=current.version)\n",
      "    if not ok:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible eliminar el recurso (conflicto de versi√≥n)\")\n",
      "\n",
      "    logger.info(\n",
      "        \"product_soft_deleted\",\n",
      "        extra={\"event\": \"product_soft_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id), \"reason\": reason},\n",
      "    )\n",
      "    return Response(status_code=status.HTTP_204_NO_CONTENT)\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# POST /products/{id}/restore (restaurar soft delete)\n",
      "# -----------------------------\n",
      "@router.post(\n",
      "    \"/{product_id}/restore\",\n",
      "    summary=\"Restaurar producto eliminado\",\n",
      "    response_model=ProductOut,\n",
      "    responses={\n",
      "        200: {\"description\": \"Restaurado\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "        409: {\"description\": \"Conflicto\"},\n",
      "        412: {\"description\": \"Precondition Failed (If-Match no coincide)\"},\n",
      "    },\n",
      ")\n",
      "async def restore_product(\n",
      "    response: Response,\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    if_match: Optional[str] = Header(default=None, alias=\"If-Match\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:restore\")),\n",
      "):\n",
      "    if not if_match:\n",
      "        http_error(status.HTTP_428_PRECONDITION_REQUIRED, \"precondition_required\", \"Se requiere If-Match para restaurar\")\n",
      "\n",
      "    current = await repo.get(product_id, include_deleted=True)\n",
      "    if not current:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "    if not current.is_deleted:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"not_deleted\", \"El producto no est√° eliminado\")\n",
      "\n",
      "    if if_match.strip() != current.etag:\n",
      "        http_error(status.HTTP_412_PRECONDITION_FAILED, \"etag_mismatch\", \"If-Match no coincide con el ETag actual\")\n",
      "\n",
      "    restored = await repo.restore(product_id, by=user.id, expected_version=current.version)\n",
      "    if not restored:\n",
      "        http_error(status.HTTP_409_CONFLICT, \"conflict\", \"No fue posible restaurar el recurso\")\n",
      "\n",
      "    response.headers[\"ETag\"] = restored.etag\n",
      "    response.headers[\"Cache-Control\"] = \"no-cache\"\n",
      "\n",
      "    logger.info(\n",
      "        \"product_restored\",\n",
      "        extra={\"event\": \"product_restored\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "\n",
      "    return ProductOut(\n",
      "        id=restored.id,\n",
      "        name=restored.name,\n",
      "        price=restored.price,\n",
      "        category=restored.category,\n",
      "        stock=restored.stock,\n",
      "        version=restored.version,\n",
      "        etag=restored.etag,\n",
      "        created_at=restored.created_at,\n",
      "        updated_at=restored.updated_at,\n",
      "        created_by=restored.created_by,\n",
      "        updated_by=restored.updated_by,\n",
      "        is_deleted=restored.is_deleted,\n",
      "        deleted_at=restored.deleted_at,\n",
      "        deleted_reason=restored.deleted_reason,\n",
      "    )\n",
      "\n",
      "\n",
      "# -----------------------------\n",
      "# DELETE /products/{id}/hard (eliminaci√≥n definitiva)\n",
      "# -----------------------------\n",
      "@router.delete(\n",
      "    \"/{product_id}/hard\",\n",
      "    summary=\"[ADMIN] Eliminaci√≥n definitiva (hard delete)\",\n",
      "    status_code=status.HTTP_204_NO_CONTENT,\n",
      "    responses={\n",
      "        204: {\"description\": \"Eliminado definitivamente\"},\n",
      "        401: {\"description\": \"No autorizado\"},\n",
      "        403: {\"description\": \"Prohibido\"},\n",
      "        404: {\"description\": \"No encontrado\"},\n",
      "    },\n",
      ")\n",
      "async def hard_delete_product(\n",
      "    product_id: UUID = Path(..., description=\"ID del producto\"),\n",
      "    repo: ProductRepositoryProtocol = Depends(get_repository),\n",
      "    user: User = Depends(require_scopes(\"product:hard_delete\")),\n",
      "):\n",
      "    ok = await repo.hard_delete(product_id)\n",
      "    if not ok:\n",
      "        http_error(status.HTTP_404_NOT_FOUND, \"not_found\", \"Producto no encontrado\")\n",
      "\n",
      "    logger.warning(\n",
      "        \"product_hard_deleted\",\n",
      "        extra={\"event\": \"product_hard_deleted\", \"user_id\": str(user.id), \"product_id\": str(product_id)},\n",
      "    )\n",
      "    return Response(status_code=status.HTTP_204_NO_CONTENT)\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# Notas para la implementaci√≥n del repositorio\n",
      "# ==============================================================================\n",
      "\n",
      "# - create:\n",
      "#   - version = 1\n",
      "#   - created_at = updated_at = datetime.now(timezone.utc)\n",
      "#   - created_by = updated_by = user_id\n",
      "#   - is_deleted = False\n",
      "# - replace:\n",
      "#   - Validar expected_version (si no coincide => conflicto)\n",
      "#   - Actualizar todos los campos de negocio; version += 1; updated_at = now; updated_by = user_id\n",
      "# - patch:\n",
      "#   - Validar que el recurso no est√© eliminado\n",
      "#   - Validar que payload.version coincida con current.version\n",
      "#   - Aplicar cambios parciales; version += 1; updated_at = now; updated_by\n",
      "# - soft_delete:\n",
      "#   - Validar expected_version\n",
      "#   - Si ya is_deleted == True => idempotente (retornar True)\n",
      "#   - Marcar is_deleted=True, deleted_at=now, deleted_reason=reason, version += 1\n",
      "# - restore:\n",
      "#   - Validar expected_version\n",
      "#   - Si no is_deleted => conflicto\n",
      "#   - Revertir is_deleted, limpiar deleted_at/reason, version += 1\n",
      "# - list:\n",
      "#   - Aplicar filtros:\n",
      "#       - search: LIKE sobre name/category\n",
      "#       - price_min/max, stock_min/max\n",
      "#   - Excluir eliminados por defecto; incluir si include_deleted=True\n",
      "#   - Ordenamiento m√∫ltiple\n",
      "#   - Retornar total, items page/size\n",
      "#   - max_updated_at = MAX(updated_at) del result set\n",
      "#   - version_sum = SUM(version) del result set (para ETag colecci√≥n)\n",
      "# - get:\n",
      "#   - Permitir include_deleted=True para operaciones administrativas\n",
      "\n",
      "# ==============================================================================\n",
      "# Fin del router\n",
      "# ==============================================================================\n",
      "\n",
      "Explicaci√≥n breve de concurrencia y cache:\n",
      "- GET con If-None-Match: si el ETag coincide con el estado actual, se retorna 304 sin cuerpo.\n",
      "- PUT/PATCH/DELETE/RESTORE requieren If-Match. Si no coincide, 412 Precondition Failed.\n",
      "- PATCH tambi√©n requiere version en el cuerpo (control optimista adicional).\n",
      "- ETag por recurso: W/\"product-<id>-v<version>\" (coincide con tu ProductOut).\n",
      "- ETag de colecci√≥n: hash d√©bil del total, max_updated_at, suma de versiones y fingerprint de par√°metros.\n",
      "\n",
      "Seguridad y permisos:\n",
      "- require_scopes valida permisos granulares.\n",
      "- Ajusta los scopes seg√∫n tu modelo de seguridad real.\n",
      "\n",
      "Logging:\n",
      "- Eventos clave con logger.info/logger.warning y campos estructurados en extra. Integra con tu stack (ELK/Datadog).\n",
      "\n",
      "Documentaci√≥n:\n",
      "- Los endpoints incluyen summaries, responses y modelos. Puedes extender con OpenAPI callbacks o ejemplos adicionales si lo requieres.\n"
     ]
    }
   ],
   "source": [
    "print(generated_components.router_fastapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d511b7e",
   "metadata": {},
   "source": [
    "### 4.6 Persistencia de Artefactos\n",
    "Escribe a carpeta `generated_product_api/` solo archivos con contenido.\n",
    "- `models.py`\n",
    "- `routes.py`\n",
    "- `test_api.py`\n",
    "- `Dockerfile`\n",
    "- `migration.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50765fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Archivos generados en: generated_product_api\n",
      "üìÅ Total archivos: 5\n"
     ]
    }
   ],
   "source": [
    "# 4. Guardar componentes generados\n",
    "output_dir = Path(f\"generated_{sample_config.resource_name}_api\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "files_created = {\n",
    "    \"models.py\": generated_components.modelo_pydantic,\n",
    "    \"routes.py\": generated_components.router_fastapi,\n",
    "    \"test_api.py\": generated_components.tests_pytest,\n",
    "    \"Dockerfile\": generated_components.dockerfile,\n",
    "    \"migration.py\": generated_components.alembic_migration\n",
    "}\n",
    "\n",
    "for filename, content in files_created.items():\n",
    "    if content.strip():  # Solo crear archivos con contenido\n",
    "        file_path = output_dir / filename\n",
    "        file_path.write_text(content)\n",
    "\n",
    "print(f\"\\nüíæ Archivos generados en: {output_dir}\")\n",
    "print(f\"üìÅ Total archivos: {len([f for f in files_created.values() if f.strip()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f013136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9733348",
   "metadata": {},
   "source": [
    "Si ven√≠as de:\n",
    "- Prompt Engineering b√°sico ‚Üí ahora formalizas prompts como componentes reutilizables.\n",
    "- FastAPI manual ‚Üí ahora generas scaffolding consistente.\n",
    "- DevOps / Infra ‚Üí introduces IaC-like patterns para artefactos de backend.\n",
    "\n",
    "Idea principal para recordar: **\"Estandariza y paraleliza lo generable; reserva tu tiempo humano para lo verdaderamente diferencial.\"**\n",
    "\n",
    "Checklist mental (READY):\n",
    "- ¬øTengo config declarativa? ‚úÖ\n",
    "- ¬øPrompts con criterios expl√≠citos? ‚úÖ\n",
    "- ¬øControl de dependencias y orden? ‚úÖ\n",
    "- ¬øM√©tricas de eficiencia? ‚úÖ\n",
    "- ¬øArtefactos persistidos y reutilizables? ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f2d5f",
   "metadata": {},
   "source": [
    "Si ven√≠as de:\n",
    "- Prompt Engineering b√°sico ‚Üí ahora formalizas prompts como componentes reutilizables.\n",
    "- FastAPI manual ‚Üí ahora generas scaffolding consistente.\n",
    "- DevOps / Infra ‚Üí introduces IaC-like patterns para artefactos de backend.\n",
    "\n",
    "Idea principal para recordar: **\"Estandariza y paraleliza lo generable; reserva tu tiempo humano para lo verdaderamente diferencial.\"**\n",
    "\n",
    "Checklist mental (READY):\n",
    "- ¬øTengo config declarativa? ‚úÖ\n",
    "- ¬øPrompts con criterios expl√≠citos? ‚úÖ\n",
    "- ¬øControl de dependencias y orden? ‚úÖ\n",
    "- ¬øM√©tricas de eficiencia? ‚úÖ\n",
    "- ¬øArtefactos persistidos y reutilizables? ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891ae20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d76946",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce640bde",
   "metadata": {},
   "source": [
    "## Parte 1: Pipeline de Refactoring Inteligente\n",
    "\n",
    "Implementaremos un sistema que analiza c√≥digo existente y propone mejoras autom√°ticas basadas en m√©tricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a89ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# PIPELINE DE REFACTORING INTELIGENTE\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c15b57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefactoringAnalysis(BaseModel):\n",
    "    \"\"\"An√°lisis integral para refactoring\"\"\"\n",
    "    code_issues: List[str] = Field(description=\"Lista de problemas detectados en el c√≥digo\")\n",
    "    refactoring_priority: str = Field(description=\"Alta/Media/Baja prioridad de refactoring\")\n",
    "    improvement_suggestions: List[str] = Field(description=\"Sugerencias espec√≠ficas de mejora\")\n",
    "    estimated_effort: str = Field(description=\"Estimaci√≥n de esfuerzo: Bajo/Medio/Alto\")\n",
    "    maintainability_score: int = Field(description=\"Puntuaci√≥n de mantenibilidad (1-10)\")\n",
    "\n",
    "class RefactoredCode(BaseModel):\n",
    "    \"\"\"C√≥digo refactorizado con mejoras\"\"\"\n",
    "    improved_code: str = Field(description=\"C√≥digo mejorado y refactorizado\")\n",
    "    changes_summary: List[str] = Field(description=\"Resumen de cambios realizados\")\n",
    "    performance_improvements: List[str] = Field(description=\"Mejoras de rendimiento aplicadas\")\n",
    "    code_style_fixes: List[str] = Field(description=\"Correcciones de estilo de c√≥digo\")\n",
    "\n",
    "# Parsers\n",
    "analysis_parser = PydanticOutputParser(pydantic_object=RefactoringAnalysis)\n",
    "refactoring_parser = PydanticOutputParser(pydantic_object=RefactoredCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "172a677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Pipeline de refactoring inteligente creado\n",
      "  ‚Ä¢ An√°lisis t√©cnico autom√°tico\n",
      "  ‚Ä¢ Refactoring basado en m√©tricas\n",
      "  ‚Ä¢ Optimizaci√≥n de c√≥digo paralela\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de an√°lisis y refactoring\n",
    "def create_refactoring_pipeline():\n",
    "    \"\"\"Crear pipeline inteligente de refactoring\"\"\"\n",
    "    \n",
    "    # An√°lisis t√©cnico\n",
    "    technical_analysis = RunnableLambda(\n",
    "        lambda x: f\"\"\"\n",
    "        Analiza el siguiente c√≥digo y proporciona un an√°lisis t√©cnico detallado:\n",
    "\n",
    "        C√ìDIGO:\n",
    "        {x['code']}\n",
    "\n",
    "        M√âTRICAS DETECTADAS:\n",
    "        {x['metrics']}\n",
    "\n",
    "        PATRONES DETECTADOS:\n",
    "        {x['patterns']}\n",
    "\n",
    "        Proporciona un an√°lisis integral considerando:\n",
    "        1. Problemas de complejidad y mantenibilidad\n",
    "        2. Anti-patrones detectados\n",
    "        3. Oportunidades de mejora\n",
    "        4. Priorizaci√≥n de refactoring\n",
    "\n",
    "        {analysis_parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "    ) | model | analysis_parser\n",
    "\n",
    "    # Refactoring inteligente\n",
    "    intelligent_refactoring = RunnableLambda(\n",
    "        lambda x: f\"\"\"\n",
    "        Refactoriza el siguiente c√≥digo bas√°ndote en el an√°lisis t√©cnico:\n",
    "\n",
    "        C√ìDIGO ORIGINAL:\n",
    "        {x['code']}\n",
    "\n",
    "        AN√ÅLISIS T√âCNICO:\n",
    "        {x['analysis']}\n",
    "\n",
    "        DIRECTRICES DE REFACTORING:\n",
    "        1. Reducir complejidad ciclom√°tica manteniendo funcionalidad\n",
    "        2. Aplicar principios SOLID y clean code\n",
    "        3. Mejorar legibilidad y mantenibilidad\n",
    "        4. Optimizar rendimiento donde sea posible\n",
    "        5. Mantener compatibilidad con APIs existentes\n",
    "        6. Agregar documentaci√≥n y tipado donde falte\n",
    "\n",
    "        IMPORTANTE: El c√≥digo debe seguir mejores pr√°cticas de FastAPI y Pydantic.\n",
    "\n",
    "        {refactoring_parser.get_format_instructions()}\n",
    "        \"\"\"\n",
    "    ) | model | refactoring_parser\n",
    "\n",
    "    # Pipeline paralelo\n",
    "    refactoring_pipeline = RunnableParallel({\n",
    "        \"analysis\": technical_analysis,\n",
    "        \"code\": RunnableLambda(lambda x: x[\"code\"]),\n",
    "        \"metrics\": RunnableLambda(lambda x: x[\"metrics\"]),\n",
    "        \"patterns\": RunnableLambda(lambda x: x[\"patterns\"])\n",
    "    }) | RunnableLambda(\n",
    "        lambda x: {\n",
    "            \"code\": x[\"code\"],\n",
    "            \"analysis\": x[\"analysis\"],\n",
    "            \"metrics\": x[\"metrics\"],\n",
    "            \"patterns\": x[\"patterns\"]\n",
    "        }\n",
    "    ) | RunnableParallel({\n",
    "        \"original\": RunnableLambda(lambda x: x),\n",
    "        \"refactored\": intelligent_refactoring\n",
    "    })\n",
    "\n",
    "    return refactoring_pipeline\n",
    "\n",
    "# Crear pipeline\n",
    "refactoring_system = create_refactoring_pipeline()\n",
    "\n",
    "print(\"üöÄ Pipeline de refactoring inteligente creado\")\n",
    "print(\"  ‚Ä¢ An√°lisis t√©cnico autom√°tico\")\n",
    "print(\"  ‚Ä¢ Refactoring basado en m√©tricas\")\n",
    "print(\"  ‚Ä¢ Optimizaci√≥n de c√≥digo paralela\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f03d3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  analysis: RunnableLambda(lambda x: f\"\\nAnaliza el siguiente c√≥digo y proporciona un an√°lisis t√©cnico detallado:\\n\\nC√ìDIGO:\\n{x['code']}\\n\\nM√âTRICAS DETECTADAS:\\n{x['metrics']}\\n\\nPATRONES DETECTADOS:\\n{x['patterns']}\\n\\nProporciona un an√°lisis integral considerando:\\n1. Problemas de complejidad y mantenibilidad\\n2. Anti-patrones detectados\\n3. Oportunidades de mejora\\n4. Priorizaci√≥n de refactoring\\n\\n{analysis_parser.get_format_instructions()}\\n\")\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | PydanticOutputParser(pydantic_object=<class '__main__.RefactoringAnalysis'>),\n",
       "  code: RunnableLambda(...),\n",
       "  metrics: RunnableLambda(...),\n",
       "  patterns: RunnableLambda(...)\n",
       "}\n",
       "| RunnableLambda(lambda x: {'code': x['code'], 'analysis': x['analysis'], 'metrics': x['metrics'], 'patterns': x['patterns']})\n",
       "| {\n",
       "    original: RunnableLambda(...),\n",
       "    refactored: RunnableLambda(lambda x: f\"\\nRefactoriza el siguiente c√≥digo bas√°ndote en el an√°lisis t√©cnico:\\n\\nC√ìDIGO ORIGINAL:\\n{x['code']}\\n\\nAN√ÅLISIS T√âCNICO:\\n{x['analysis']}\\n\\nDIRECTRICES DE REFACTORING:\\n1. Reducir complejidad ciclom√°tica manteniendo funcionalidad\\n2. Aplicar principios SOLID y clean code\\n3. Mejorar legibilidad y mantenibilidad\\n4. Optimizar rendimiento donde sea posible\\n5. Mantener compatibilidad con APIs existentes\\n6. Agregar documentaci√≥n y tipado donde falte\\n\\nIMPORTANTE: El c√≥digo debe seguir mejores pr√°cticas de FastAPI y Pydantic.\\n\\n{refactoring_parser.get_format_instructions()}\\n\")\n",
       "                | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1cf5d384a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1e939c3bf0>, root_client=<openai.OpenAI object at 0x7f1cf5e21760>, root_async_client=<openai.AsyncOpenAI object at 0x7f1cf5ce0b00>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "                | PydanticOutputParser(pydantic_object=<class '__main__.RefactoredCode'>)\n",
       "  }"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refactoring_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a6ae5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã C√≥digo legacy de ejemplo cargado\n",
      "Problemas visibles:\n",
      "  ‚Ä¢ Funci√≥n muy larga y compleja\n",
      "  ‚Ä¢ L√≥gica de negocio anidada\n",
      "  ‚Ä¢ TODOs sin resolver\n",
      "  ‚Ä¢ Uso excesivo de print\n",
      "  ‚Ä¢ Falta de validaciones\n"
     ]
    }
   ],
   "source": [
    "# DEMOSTRACI√ìN: Refactoring inteligente de c√≥digo legacy\n",
    "import time\n",
    "\n",
    "# C√≥digo de ejemplo con problemas detectables\n",
    "sample_legacy_code = '''\n",
    "def process_user_data(data):\n",
    "    print(\"Processing user data...\")\n",
    "    result = []\n",
    "    \n",
    "    # TODO: Add input validation\n",
    "    for item in data:\n",
    "        print(f\"Processing item: {item}\")\n",
    "        \n",
    "        if item[\"age\"] > 18 and item[\"status\"] == \"active\":\n",
    "            processed = {}\n",
    "            processed[\"id\"] = item[\"id\"]\n",
    "            processed[\"name\"] = item[\"name\"] \n",
    "            processed[\"email\"] = item[\"email\"]\n",
    "            processed[\"age\"] = item[\"age\"]\n",
    "            processed[\"processed_at\"] = time.time()\n",
    "            \n",
    "            # Complex business logic\n",
    "            if item[\"subscription\"] == \"premium\":\n",
    "                if item[\"region\"] == \"US\":\n",
    "                    processed[\"discount\"] = 0.1\n",
    "                    if item[\"loyalty_years\"] > 5:\n",
    "                        processed[\"discount\"] = 0.15\n",
    "                        if item[\"referrals\"] > 10:\n",
    "                            processed[\"discount\"] = 0.2\n",
    "                elif item[\"region\"] == \"EU\":\n",
    "                    processed[\"discount\"] = 0.08\n",
    "                    if item[\"loyalty_years\"] > 3:\n",
    "                        processed[\"discount\"] = 0.12\n",
    "                else:\n",
    "                    processed[\"discount\"] = 0.05\n",
    "            else:\n",
    "                processed[\"discount\"] = 0.0\n",
    "            \n",
    "            result.append(processed)\n",
    "            print(f\"Processed user: {processed['name']}\")\n",
    "    \n",
    "    print(f\"Total processed: {len(result)}\")\n",
    "    return result\n",
    "'''\n",
    "\n",
    "print(\"üìã C√≥digo legacy de ejemplo cargado\")\n",
    "print(\"Problemas visibles:\")\n",
    "print(\"  ‚Ä¢ Funci√≥n muy larga y compleja\")\n",
    "print(\"  ‚Ä¢ L√≥gica de negocio anidada\")\n",
    "print(\"  ‚Ä¢ TODOs sin resolver\")\n",
    "print(\"  ‚Ä¢ Uso excesivo de print\")\n",
    "print(\"  ‚Ä¢ Falta de validaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5df69ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones de an√°lisis de c√≥digo agregadas:\n"
     ]
    }
   ],
   "source": [
    "# FUNCIONES DE AN√ÅLISIS DE C√ìDIGO (faltantes)\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "def analyze_code_complexity(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analizar complejidad del c√≥digo usando AST\"\"\"\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        \n",
    "        complexity_score = 0\n",
    "        functions = []\n",
    "        issues = []\n",
    "        \n",
    "        # Analizar nodos del AST\n",
    "        for node in ast.walk(tree):\n",
    "            # Contar estructuras de control (aumentan complejidad)\n",
    "            if isinstance(node, (ast.If, ast.For, ast.While, ast.With)):\n",
    "                complexity_score += 1\n",
    "            # Contar funciones\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                functions.append(node.name)\n",
    "                # Calcular complejidad de la funci√≥n\n",
    "                func_complexity = sum(1 for n in ast.walk(node) \n",
    "                                    if isinstance(n, (ast.If, ast.For, ast.While, ast.With)))\n",
    "                if func_complexity > 5:\n",
    "                    issues.append(f\"Funci√≥n '{node.name}' muy compleja ({func_complexity} puntos)\")\n",
    "        \n",
    "        # M√©tricas b√°sicas\n",
    "        lines = len([line for line in code.split('\\n') if line.strip()])\n",
    "        code_lines = len([line for line in code.split('\\n') \n",
    "                         if line.strip() and not line.strip().startswith('#')])\n",
    "        \n",
    "        # Calcular √≠ndice de mantenibilidad (escala 0-100)\n",
    "        maintainability_index = max(0, 100 - complexity_score * 2 - (code_lines / 10))\n",
    "        \n",
    "        # Detectar problemas adicionales\n",
    "        if 'TODO' in code:\n",
    "            issues.append(\"TODOs pendientes en el c√≥digo\")\n",
    "        if code.count('print(') > 3:\n",
    "            issues.append(\"Uso excesivo de print statements\")\n",
    "        if len(functions) == 0:\n",
    "            issues.append(\"No hay funciones definidas\")\n",
    "        \n",
    "        return {\n",
    "            \"complexity_score\": complexity_score,\n",
    "            \"average_complexity\": complexity_score / max(len(functions), 1),\n",
    "            \"maintainability_index\": maintainability_index,\n",
    "            \"code_lines\": code_lines,\n",
    "            \"total_lines\": lines,\n",
    "            \"functions_count\": len(functions),\n",
    "            \"complex_functions\": [f for f in functions if f in [issue.split(\"'\")[1] for issue in issues if \"muy compleja\" in issue]],\n",
    "            \"issues\": issues\n",
    "        }\n",
    "        \n",
    "    except SyntaxError as e:\n",
    "        return {\n",
    "            \"complexity_score\": 100,  # C√≥digo con errores de sintaxis = alta complejidad\n",
    "            \"average_complexity\": 100,\n",
    "            \"maintainability_index\": 0,\n",
    "            \"code_lines\": 0,\n",
    "            \"total_lines\": len(code.split('\\n')),\n",
    "            \"functions_count\": 0,\n",
    "            \"complex_functions\": [],\n",
    "            \"issues\": [f\"Error de sintaxis: {str(e)}\"]\n",
    "        }\n",
    "\n",
    "def analyze_code_patterns(code: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Analizar patrones y anti-patrones en el c√≥digo\"\"\"\n",
    "    good_patterns = []\n",
    "    anti_patterns = []\n",
    "    suggestions = []\n",
    "    \n",
    "    # Detectar patrones positivos\n",
    "    if 'def ' in code:\n",
    "        good_patterns.append(\"Funciones definidas (modularidad)\")\n",
    "    if '\"\"\"' in code or \"'''\" in code:\n",
    "        good_patterns.append(\"Documentaci√≥n con docstrings\")\n",
    "    if 'try:' in code and 'except' in code:\n",
    "        good_patterns.append(\"Manejo de errores implementado\")\n",
    "    if 'class ' in code:\n",
    "        good_patterns.append(\"Uso de clases (OOP)\")\n",
    "    if 'import ' in code:\n",
    "        good_patterns.append(\"Imports organizados\")\n",
    "    \n",
    "    # Detectar anti-patrones\n",
    "    if code.count('if ') > 5 and 'elif' not in code:\n",
    "        anti_patterns.append(\"M√∫ltiples if anidados (considerar elif)\")\n",
    "    if 'print(' in code and code.count('print(') > 2:\n",
    "        anti_patterns.append(\"Uso excesivo de print (usar logging)\")\n",
    "    if 'TODO' in code:\n",
    "        anti_patterns.append(\"TODOs sin resolver\")\n",
    "    if len([line for line in code.split('\\n') if len(line) > 100]) > 0:\n",
    "        anti_patterns.append(\"L√≠neas muy largas (>100 caracteres)\")\n",
    "    \n",
    "    # Contar niveles de indentaci√≥n\n",
    "    max_indent = max([len(line) - len(line.lstrip()) for line in code.split('\\n')] + [0])\n",
    "    if max_indent > 16:  # >4 niveles de indentaci√≥n\n",
    "        anti_patterns.append(f\"Anidamiento profundo ({max_indent//4} niveles)\")\n",
    "    \n",
    "    # Generar sugerencias\n",
    "    if 'TODO' in code:\n",
    "        suggestions.append(\"Resolver TODOs pendientes\")\n",
    "    if anti_patterns:\n",
    "        suggestions.append(\"Refactorizar para reducir complejidad\")\n",
    "    if 'print(' in code:\n",
    "        suggestions.append(\"Reemplazar prints con logging estructurado\")\n",
    "    if max_indent > 12:\n",
    "        suggestions.append(\"Extraer funciones para reducir anidamiento\")\n",
    "    if code.count('def ') == 0:\n",
    "        suggestions.append(\"Dividir c√≥digo en funciones reutilizables\")\n",
    "    \n",
    "    return {\n",
    "        \"good_patterns\": good_patterns,\n",
    "        \"anti_patterns\": anti_patterns,\n",
    "        \"suggestions\": suggestions,\n",
    "        \"complexity_indicators\": {\n",
    "            \"max_indentation\": max_indent,\n",
    "            \"function_count\": code.count('def '),\n",
    "            \"print_statements\": code.count('print('),\n",
    "            \"todo_count\": code.count('TODO')\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Funciones de an√°lisis de c√≥digo agregadas:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f24b88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Iniciando an√°lisis autom√°tico del c√≥digo legacy...\n",
      "\n",
      "üìä AN√ÅLISIS DE COMPLEJIDAD:\n",
      "  ‚Ä¢ Complejidad m√°xima: 8\n",
      "  ‚Ä¢ Complejidad promedio: 8.0\n",
      "  ‚Ä¢ √çndice mantenibilidad: 80.9\n",
      "  ‚Ä¢ L√≠neas de c√≥digo: 31\n",
      "  ‚Ä¢ Funciones complejas: ['process_user_data']\n",
      "  ‚ö†Ô∏è  PROBLEMAS DETECTADOS:\n",
      "      - Funci√≥n 'process_user_data' muy compleja (8 puntos)\n",
      "      - TODOs pendientes en el c√≥digo\n",
      "      - Uso excesivo de print statements\n",
      "\n",
      "üîç AN√ÅLISIS DE PATRONES:\n",
      "  ‚úÖ Patrones positivos:\n",
      "      - Funciones definidas (modularidad)\n",
      "  ‚ùå Anti-patrones detectados:\n",
      "      - Uso excesivo de print (usar logging)\n",
      "      - TODOs sin resolver\n",
      "      - Anidamiento profundo (7 niveles)\n",
      "  üí° Sugerencias de mejora:\n",
      "      - Resolver TODOs pendientes\n",
      "      - Refactorizar para reducir complejidad\n",
      "      - Reemplazar prints con logging estructurado\n",
      "      - Extraer funciones para reducir anidamiento\n",
      "\n",
      "‚úÖ An√°lisis completo - Datos preparados para refactoring\n"
     ]
    }
   ],
   "source": [
    "# AN√ÅLISIS AUTOM√ÅTICO DEL C√ìDIGO LEGACY\n",
    "import asyncio\n",
    "\n",
    "async def analyze_legacy_code():\n",
    "    \"\"\"Ejecutar an√°lisis completo del c√≥digo legacy\"\"\"\n",
    "    print(\"üîç Iniciando an√°lisis autom√°tico del c√≥digo legacy...\")\n",
    "    \n",
    "    # 1. An√°lisis de complejidad\n",
    "    complexity_analysis = analyze_code_complexity(sample_legacy_code)\n",
    "    print(f\"\\nüìä AN√ÅLISIS DE COMPLEJIDAD:\")\n",
    "    print(f\"  ‚Ä¢ Complejidad m√°xima: {complexity_analysis.get('complexity_score', 'N/A')}\")\n",
    "    print(f\"  ‚Ä¢ Complejidad promedio: {complexity_analysis.get('average_complexity', 'N/A'):.1f}\")\n",
    "    print(f\"  ‚Ä¢ √çndice mantenibilidad: {complexity_analysis.get('maintainability_index', 'N/A'):.1f}\")\n",
    "    print(f\"  ‚Ä¢ L√≠neas de c√≥digo: {complexity_analysis.get('code_lines', 'N/A')}\")\n",
    "    print(f\"  ‚Ä¢ Funciones complejas: {complexity_analysis.get('complex_functions', [])}\")\n",
    "    \n",
    "    if complexity_analysis.get('issues'):\n",
    "        print(f\"  ‚ö†Ô∏è  PROBLEMAS DETECTADOS:\")\n",
    "        for issue in complexity_analysis['issues']:\n",
    "            print(f\"      - {issue}\")\n",
    "    \n",
    "    # 2. An√°lisis de patrones\n",
    "    pattern_analysis = analyze_code_patterns(sample_legacy_code)\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE PATRONES:\")\n",
    "    \n",
    "    if pattern_analysis['good_patterns']:\n",
    "        print(f\"  ‚úÖ Patrones positivos:\")\n",
    "        for pattern in pattern_analysis['good_patterns']:\n",
    "            print(f\"      - {pattern}\")\n",
    "    \n",
    "    if pattern_analysis['anti_patterns']:\n",
    "        print(f\"  ‚ùå Anti-patrones detectados:\")\n",
    "        for anti_pattern in pattern_analysis['anti_patterns']:\n",
    "            print(f\"      - {anti_pattern}\")\n",
    "    \n",
    "    if pattern_analysis['suggestions']:\n",
    "        print(f\"  üí° Sugerencias de mejora:\")\n",
    "        for suggestion in pattern_analysis['suggestions']:\n",
    "            print(f\"      - {suggestion}\")\n",
    "    \n",
    "    # 3. Preparar datos para pipeline\n",
    "    analysis_data = {\n",
    "        \"code\": sample_legacy_code,\n",
    "        \"metrics\": complexity_analysis,\n",
    "        \"patterns\": pattern_analysis\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ An√°lisis completo - Datos preparados para refactoring\")\n",
    "    return analysis_data\n",
    "\n",
    "# Ejecutar an√°lisis\n",
    "legacy_analysis = await analyze_legacy_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59ea935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de refactoring...\n"
     ]
    }
   ],
   "source": [
    "# EJECUCI√ìN DEL REFACTORING INTELIGENTE\n",
    "async def execute_intelligent_refactoring():\n",
    "    \"\"\"Ejecutar el pipeline completo de refactoring\"\"\"\n",
    "    print(\"üöÄ Ejecutando pipeline de refactoring inteligente...\")\n",
    "    \n",
    "\n",
    "    # Ejecutar pipeline con an√°lisis previo\n",
    "    refactoring_result = await refactoring_system.ainvoke(legacy_analysis)\n",
    "    \n",
    "    # Mostrar an√°lisis t√©cnico\n",
    "    analysis = refactoring_result['original']['analysis']\n",
    "    print(f\"\\nüìã AN√ÅLISIS T√âCNICO:\")\n",
    "    print(f\"  ‚Ä¢ Prioridad de refactoring: {analysis.refactoring_priority}\")\n",
    "    print(f\"  ‚Ä¢ Esfuerzo estimado: {analysis.estimated_effort}\")\n",
    "    print(f\"  ‚Ä¢ Puntuaci√≥n mantenibilidad: {analysis.maintainability_score}/10\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:\")\n",
    "    for issue in analysis.code_issues:\n",
    "        print(f\"    - {issue}\")\n",
    "    \n",
    "    print(f\"\\nüí° SUGERENCIAS DE MEJORA:\")\n",
    "    for suggestion in analysis.improvement_suggestions:\n",
    "        print(f\"    - {suggestion}\")\n",
    "    \n",
    "    # Mostrar c√≥digo refactorizado\n",
    "    refactored = refactoring_result['refactored']\n",
    "    print(f\"\\n‚ú® C√ìDIGO REFACTORIZADO:\")\n",
    "    print(\"=\"*60)\n",
    "    print(refactored.improved_code)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìù RESUMEN DE CAMBIOS:\")\n",
    "    for change in refactored.changes_summary:\n",
    "        print(f\"    ‚úì {change}\")\n",
    "    \n",
    "    if refactored.performance_improvements:\n",
    "        print(f\"\\n‚ö° MEJORAS DE RENDIMIENTO:\")\n",
    "        for improvement in refactored.performance_improvements:\n",
    "            print(f\"    ‚ö° {improvement}\")\n",
    "    \n",
    "    if refactored.code_style_fixes:\n",
    "        print(f\"\\nüé® CORRECCIONES DE ESTILO:\")\n",
    "        for fix in refactored.code_style_fixes:\n",
    "            print(f\"    üé® {fix}\")\n",
    "    \n",
    "    return refactoring_result\n",
    "    \n",
    "\n",
    "# Ejecutar refactoring\n",
    "print(\"Iniciando proceso de refactoring...\")\n",
    "refactoring_results = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c40415f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ejecutando pipeline de refactoring inteligente...\n",
      "\n",
      "üìã AN√ÅLISIS T√âCNICO:\n",
      "  ‚Ä¢ Prioridad de refactoring: Alta\n",
      "  ‚Ä¢ Esfuerzo estimado: Medio\n",
      "  ‚Ä¢ Puntuaci√≥n mantenibilidad: 7/10\n",
      "\n",
      "‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:\n",
      "    - Condicionales anidadas profundas en la l√≥gica de descuentos (hasta 7 niveles)\n",
      "    - TODO de validaci√≥n de entrada sin resolver (riesgo de KeyError/TypeError)\n",
      "    - Uso de print para registro de eventos (acopla E/S con l√≥gica, dificulta observabilidad)\n",
      "    - Fuga potencial de PII en logs (name/email)\n",
      "    - Import faltante de 'time' (NameError en tiempo de ejecuci√≥n)\n",
      "    - Falta de tipado y docstring (disminuye legibilidad y herramientas est√°ticas)\n",
      "    - Valores m√°gicos y cadenas hardcodeadas (umbrales, regiones, estados)\n",
      "    - Uso de time.time() sin zona horaria (marca de tiempo no trazable/ambigua)\n",
      "    - Funci√≥n con m√∫ltiples responsabilidades (procesa datos y reporta progreso)\n",
      "    - Duplicaci√≥n de asignaciones en el dict 'processed' (verbosidad y riesgo de errores)\n",
      "    - Sin manejo de errores ni validaci√≥n de tipos (p.ej., age no num√©rico)\n",
      "    - Reglas de negocio codificadas y fr√°giles (dif√≠cil de extender/probar)\n",
      "    - Condici√≥n de edad estricta (> 18) podr√≠a ser inconsistente con requisitos (¬ø>= 18?)\n",
      "    - Falta de pruebas unitarias para la l√≥gica de descuentos y filtros\n",
      "\n",
      "üí° SUGERENCIAS DE MEJORA:\n",
      "    - Introducir validaci√≥n de entrada (pydantic/marshmallow o validaciones manuales) para tipos y presencia de claves requeridas\n",
      "    - Reemplazar print por logging estructurado (logging stdlib) con niveles y mascarado de PII; evitar registrar email completo\n",
      "    - Extraer la l√≥gica de descuentos a una funci√≥n dedicada (compute_discount) y preferir un enfoque data-driven (tablas/reglas) sobre if-else anidados\n",
      "    - Aplicar guard clauses (continue tempranos) para reducir anidamiento en el bucle\n",
      "    - Definir constantes/enums para estados, regiones, y umbrales; eliminar valores m√°gicos\n",
      "    - Usar timestamps con zona horaria y formato ISO 8601 (datetime.now(timezone.utc).isoformat())\n",
      "    - A√±adir type hints y docstring; considerar dataclasses o TypedDict para esquematizar los items\n",
      "    - Separar responsabilidades: una funci√≥n pura que procese y otra que reporte/progrese (o aceptar un logger inyectable)\n",
      "    - Simplificar la construcci√≥n de 'processed' con un dict literal y minimizar accesos repetidos a item con variables locales\n",
      "    - Manejar errores expl√≠citamente (try/except controlado) y reportar entradas inv√°lidas sin abortar todo el procesamiento\n",
      "    - Cubrir con pruebas unitarias y de l√≠mites (regiones, a√±os de lealtad, referrals, borde de edad, suscripci√≥n no premium)\n",
      "    - Documentar reglas de negocio y justificar umbrales; parametrizarlos v√≠a configuraci√≥n\n",
      "    - Evaluar rendimiento y legibilidad: filtrar primero (if no cumple, continue) y luego construir el resultado\n",
      "    - Importar correctamente los m√≥dulos necesarios o migrar a datetime para coherencia temporal\n",
      "\n",
      "‚ú® C√ìDIGO REFACTORIZADO:\n",
      "============================================================\n",
      "from typing import Any, Dict, List, Sequence, Union\n",
      "from datetime import datetime, timezone\n",
      "import logging\n",
      "\n",
      "from pydantic import BaseModel, EmailStr, Field, ValidationError, field_validator\n",
      "\n",
      "# Module-level logger (injectable through logging configuration in FastAPI app)\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "# -------------------- Constants / Configuration --------------------\n",
      "STATUS_ACTIVE = \"active\"\n",
      "SUBSCRIPTION_PREMIUM = \"premium\"\n",
      "REGION_US = \"US\"\n",
      "REGION_EU = \"EU\"\n",
      "\n",
      "AGE_THRESHOLD_EXCLUSIVE = 18  # Maintain original semantics: age must be > 18\n",
      "\n",
      "# -------------------- Data Models --------------------\n",
      "class UserInput(BaseModel):\n",
      "    \"\"\"Validated input schema for user items.\n",
      "\n",
      "    Extra keys are ignored to maintain forward compatibility with upstream payloads.\n",
      "    Strings are normalized to consistent cases to simplify business rules.\n",
      "    \"\"\"\n",
      "\n",
      "    id: Union[int, str]\n",
      "    name: str = Field(min_length=1, max_length=200)\n",
      "    email: EmailStr\n",
      "    age: int = Field(ge=0, le=150)\n",
      "    status: str\n",
      "    subscription: str\n",
      "    region: str\n",
      "    loyalty_years: int = Field(default=0, ge=0, le=100)\n",
      "    referrals: int = Field(default=0, ge=0, le=100_000)\n",
      "\n",
      "    @field_validator(\"status\")\n",
      "    @classmethod\n",
      "    def _normalize_status(cls, v: str) -> str:\n",
      "        return v.strip().lower()\n",
      "\n",
      "    @field_validator(\"subscription\")\n",
      "    @classmethod\n",
      "    def _normalize_subscription(cls, v: str) -> str:\n",
      "        return v.strip().lower()\n",
      "\n",
      "    @field_validator(\"region\")\n",
      "    @classmethod\n",
      "    def _normalize_region(cls, v: str) -> str:\n",
      "        return v.strip().upper()\n",
      "\n",
      "    class Config:\n",
      "        extra = \"ignore\"\n",
      "\n",
      "\n",
      "# -------------------- Business Logic --------------------\n",
      "def compute_discount(user: UserInput) -> float:\n",
      "    \"\"\"Compute discount according to business rules.\n",
      "\n",
      "    Mirrors original logic while reducing nesting:\n",
      "      - Non-premium => 0.0\n",
      "      - Premium + US => 0.10, >5 loyalty => 0.15, and if referrals >10 => 0.20\n",
      "      - Premium + EU => 0.08, >3 loyalty => 0.12\n",
      "      - Premium + other regions => 0.05\n",
      "    \"\"\"\n",
      "    if user.subscription != SUBSCRIPTION_PREMIUM:\n",
      "        return 0.0\n",
      "\n",
      "    if user.region == REGION_US:\n",
      "        discount = 0.10\n",
      "        if user.loyalty_years > 5:\n",
      "            discount = 0.15\n",
      "            if user.referrals > 10:\n",
      "                discount = 0.20\n",
      "        return discount\n",
      "\n",
      "    if user.region == REGION_EU:\n",
      "        return 0.12 if user.loyalty_years > 3 else 0.08\n",
      "\n",
      "    return 0.05\n",
      "\n",
      "\n",
      "# -------------------- Public API --------------------\n",
      "def process_user_data(data: Sequence[Union[Dict[str, Any], UserInput]]) -> List[Dict[str, Any]]:\n",
      "    \"\"\"Process a batch of user items and return processed entries.\n",
      "\n",
      "    - Input validation with Pydantic ensures required keys and types.\n",
      "    - Filters: age must be > 18 and status must be 'active' (maintains original semantics).\n",
      "    - Computes discount via a dedicated function.\n",
      "    - Uses timezone-aware ISO 8601 timestamps.\n",
      "    - Uses structured logging without leaking PII (logs use user id only).\n",
      "\n",
      "    Args:\n",
      "        data: Sequence of dictionaries (raw payload) or validated UserInput objects.\n",
      "\n",
      "    Returns:\n",
      "        List of processed user dictionaries with keys: id, name, email, age, processed_at, discount.\n",
      "    \"\"\"\n",
      "    result: List[Dict[str, Any]] = []\n",
      "\n",
      "    try:\n",
      "        batch_size = len(data)  # type: ignore[arg-type]\n",
      "    except Exception:\n",
      "        batch_size = None\n",
      "\n",
      "    logger.info(\"Processing user data batch\", extra={\"batch_size\": batch_size})\n",
      "\n",
      "    for idx, raw in enumerate(data):\n",
      "        try:\n",
      "            user = raw if isinstance(raw, UserInput) else UserInput.model_validate(raw)\n",
      "        except ValidationError as exc:\n",
      "            logger.warning(\n",
      "                \"Skipping invalid item\",\n",
      "                extra={\"index\": idx, \"error\": exc.errors() if hasattr(exc, \"errors\") else str(exc)},\n",
      "            )\n",
      "            continue\n",
      "        except Exception as exc:  # Defensive: unforeseen input shape\n",
      "            logger.exception(\"Unexpected error validating item\", extra={\"index\": idx, \"error\": str(exc)})\n",
      "            continue\n",
      "\n",
      "        # Guard clauses for filters (maintain original semantics)\n",
      "        if not (user.age > AGE_THRESHOLD_EXCLUSIVE):\n",
      "            logger.debug(\"User filtered by age\", extra={\"index\": idx, \"user_id\": user.id, \"age\": user.age})\n",
      "            continue\n",
      "        if user.status != STATUS_ACTIVE:\n",
      "            logger.debug(\"User filtered by status\", extra={\"index\": idx, \"user_id\": user.id, \"status\": user.status})\n",
      "            continue\n",
      "\n",
      "        discount = compute_discount(user)\n",
      "\n",
      "        processed = {\n",
      "            \"id\": user.id,\n",
      "            \"name\": user.name,\n",
      "            \"email\": user.email,\n",
      "            \"age\": user.age,\n",
      "            \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
      "            \"discount\": discount,\n",
      "        }\n",
      "\n",
      "        result.append(processed)\n",
      "        logger.debug(\"Processed user\", extra={\"index\": idx, \"user_id\": user.id, \"discount\": discount})\n",
      "\n",
      "    logger.info(\"Processing completed\", extra={\"total_processed\": len(result)})\n",
      "    return result\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìù RESUMEN DE CAMBIOS:\n",
      "    ‚úì Sustituido print por logging estructurado (stdlib) con niveles y sin exponer PII; se registran ids y metadatos.\n",
      "    ‚úì A√±adida validaci√≥n de entrada con Pydantic (UserInput) incluyendo normalizaci√≥n de cadenas y l√≠mites de valores.\n",
      "    ‚úì Extra√≠da la l√≥gica de descuentos a una funci√≥n dedicada compute_discount para reducir anidamiento y facilitar pruebas.\n",
      "    ‚úì Introducidas constantes para estados, regiones y umbrales (eliminaci√≥n de valores m√°gicos).\n",
      "    ‚úì Uso de timestamp con zona horaria (UTC) y formato ISO 8601 en processed_at.\n",
      "    ‚úì Aplicados type hints completos y docstrings para mejorar legibilidad y tooling.\n",
      "    ‚úì Aplicadas guard clauses para reducir complejidad ciclom√°tica dentro del bucle.\n",
      "    ‚úì Manejo expl√≠cito de errores de validaci√≥n (se omiten entradas inv√°lidas sin interrumpir el procesamiento).\n",
      "    ‚úì Se mantiene la firma y la forma de salida de process_user_data para compatibilidad.\n",
      "    ‚úì Simplificaci√≥n de la construcci√≥n del dict resultante y acceso a campos mediante modelo validado.\n",
      "    ‚úì Se ignoran claves extra del input para mayor robustez frente a cambios futuros.\n",
      "\n",
      "‚ö° MEJORAS DE RENDIMIENTO:\n",
      "    ‚ö° Filtrado temprano por edad y estado (guard clauses) evitando c√≥mputo innecesario de descuentos.\n",
      "    ‚ö° Menor overhead de logging al usar niveles adecuados (debug para detalle por usuario, info para resumen).\n",
      "    ‚ö° Acceso a atributos tipados del modelo Pydantic en lugar de m√∫ltiples accesos a diccionario reduciendo lookups repetidos.\n",
      "    ‚ö° Normalizaci√≥n de strings en validaci√≥n (una vez) en vez de normalizar repetidamente durante la l√≥gica.\n",
      "\n",
      "üé® CORRECCIONES DE ESTILO:\n",
      "    üé® Cumplimiento PEP 8: nombres constantes en may√∫sculas, funciones y variables descriptivas.\n",
      "    üé® Eliminaci√≥n de prints y uso de logging est√°ndar.\n",
      "    üé® Documentaci√≥n mediante docstrings y tipado est√°tico en funciones y modelos.\n",
      "    üé® Separaci√≥n de responsabilidades: funci√≥n pura de c√°lculo de descuento y funci√≥n de orquestaci√≥n/procesamiento.\n",
      "    üé® Eliminaci√≥n de condicionales anidados profundos; uso de guard clauses.\n",
      "    üé® Remoci√≥n de valores m√°gicos sustituidos por constantes sem√°nticas.\n",
      "    üé® Timestamp coherente y trazable con datetime y timezone UTC.\n",
      "    üé® Validaci√≥n expl√≠cita de entrada y manejo de errores con Pydantic y excepciones controladas.\n"
     ]
    }
   ],
   "source": [
    "refactoring_results = await execute_intelligent_refactoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33fada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb783b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
